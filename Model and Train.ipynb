{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# mnist_data = np.load('archive/tn-for-unsup-ml/data/binarized_mnist.npz')\n",
    "# train_data = torch.from_numpy(mnist_data['train_data'])\n",
    "# test_data = torch.from_numpy(mnist_data['test_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from train_base import *\n",
    "statisticinfo= torch.load(\"/media/tianning/DATA/DATASET/MNIST/MNIST/statisitc_stdmean.pt\")\n",
    "statistic_std= statisticinfo['statisitc_std']\n",
    "statistic_mean=statisticinfo['statisitc_mean']\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "#     lambda x:(x-statistic_mean)/statistic_std,\n",
    "    transforms.CenterCrop(24)\n",
    "])\n",
    "DATAPATH    = '/media/tianning/DATA/DATASET/MNIST/'\n",
    "mnist_train = datasets.MNIST(DATAPATH, train=True, download=False, transform=transform)\n",
    "mnist_test  = datasets.MNIST(DATAPATH, train=False,download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "train_loader= torch.utils.data.DataLoader(dataset=mnist_train, batch_size=60000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader= torch.utils.data.DataLoader(dataset=mnist_train, batch_size=60000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image = iter(train_loader).next()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltool.visualization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4e410416a0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(torch.sum(all_image[:,0]>0,0).numpy()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Simple MPS layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     2,
     14,
     38,
     51,
     58,
     68
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class MPSLinear(nn.Module):\n",
    "    '''\n",
    "    For a naive Linear Layer(in_features,out_features,\n",
    "                             in_physics_bond = 2, out_physics_bond=2, virtual_bond_dim=2, \n",
    "                             bias=True,label_position='center',init_std=1e-10\n",
    "                                       ): \n",
    "        input  (B, in_features)\n",
    "        output (B, out_features)\n",
    "    For s simplest MPSLayer(in_features: int, out_features: int, \n",
    "                            in_physics_bond: int, out_physics_bond: int, virtual_bond_dim:int,\n",
    "                            bias: bool = True, label_position: int or str): \n",
    "        input  (B, in_features , in_physics_bond)\n",
    "        output (B, out_features,out_physics_bond)\n",
    "    '''\n",
    "    def __init__(self, in_features,out_features,\n",
    "                                       in_physics_bond = 2, out_physics_bond=1, virtual_bond_dim=2, \n",
    "                                       bias=True,label_position='center',init_std=1e-10):\n",
    "        super(MPSLinear, self).__init__()\n",
    "        if label_position is 'center':\n",
    "            label_position = in_features//2\n",
    "        assert type(label_position) is int\n",
    "        self.in_features   = in_features\n",
    "        self.out_features  = out_features\n",
    "        self.vbd           = virtual_bond_dim\n",
    "        self.ipb           = in_physics_bond\n",
    "        self.opb           = out_physics_bond\n",
    "        self.hn            = label_position\n",
    "        left_num           = self.hn\n",
    "        right_num          = in_features - left_num\n",
    "\n",
    "        bias_mat = torch.eye(self.vbd).unsqueeze(-1).repeat(1,1,self.ipb)\n",
    "        self.left_tensors = nn.Parameter(init_std * torch.randn(left_num         ,self.vbd,self.vbd, self.ipb)+ bias_mat)\n",
    "        self.rigt_tensors = nn.Parameter(init_std * torch.randn(right_num        ,self.vbd,self.vbd, self.ipb)+ bias_mat)\n",
    "        \n",
    "        bias_mat = torch.eye(self.vbd).unsqueeze(-1).repeat(1,1,self.opb)\n",
    "        self.cent_tensors = nn.Parameter(init_std * torch.randn(self.out_features,self.vbd,self.vbd, self.opb)+ bias_mat)\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_chain_contraction_fast(tensor):\n",
    "        size   = int(tensor.shape[0])\n",
    "        while size > 1:\n",
    "            half_size = size // 2\n",
    "            nice_size = 2 * half_size\n",
    "            leftover  = tensor[nice_size:]\n",
    "            tensor    = torch.einsum(\"mbik,mbkj->mbij\",tensor[0:nice_size:2], tensor[1:nice_size:2])\n",
    "            #(k/2,NB,D,D),(k/2,NB,D,D) <-> (k/2,NB,D,D)\n",
    "            tensor   = torch.cat([tensor, leftover], axis=0)\n",
    "            size     = half_size + int(size % 2 == 1)\n",
    "        return tensor.squeeze(0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_chain_contraction_memory_save(tensor):\n",
    "        size      = int(tensor.shape[0])\n",
    "        now_tensor= tensor[0]\n",
    "        for next_tensor in tensor[1:]:\n",
    "            now_tensor = torch.einsum(\"bik,bkj->bij\",now_tensor, next_tensor)\n",
    "        return now_tensor\n",
    "    \n",
    "    def get_chain_contraction(self,tensor):\n",
    "        size   = int(tensor.shape[0])\n",
    "        D      = int(tensor.shape[-1])\n",
    "        print(size)\n",
    "        print(D)\n",
    "        if D>30:\n",
    "            return self.get_chain_contraction_memory_save(tensor)\n",
    "        else:\n",
    "            return self.get_chain_contraction_fast(tensor)\n",
    "    \n",
    "    def forward(self, input_data):\n",
    "        # the input data shape is (B,L,pd)\n",
    "        # expand to convolution patch\n",
    "        embedded_data= input_data\n",
    "        left_tensors = torch.einsum('wijp,nwp->wnij',self.left_tensors,embedded_data[:,:self.hn])#i.e. (K,NB,b,b)\n",
    "        rigt_tensors = torch.einsum('wijp,nwp->wnij',self.rigt_tensors,embedded_data[:,-self.hn:])#i.e.(K,NB,b,b)\n",
    "\n",
    "        left_tensors = self.get_chain_contraction(left_tensors) #i.e. (NB,b,b)\n",
    "        rigt_tensors = self.get_chain_contraction(rigt_tensors) #i.e. (NB,b,b)\n",
    "\n",
    "        tensor  = torch.einsum('bip,oplt,bli->bot',left_tensors,self.cent_tensors,rigt_tensors)\n",
    "        # (NB,b,b) <-> (T,b,b,o) <-> (NB,b,b) ==> (NB,T,t)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     3,
     70
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensornetwork as tn\n",
    "from tensornetwork import contractors\n",
    "tn.set_default_backend(\"pytorch\")\n",
    "class MPSLinear_tn_loop(nn.Module):\n",
    "    '''\n",
    "    For s simplest MPSLayer(in_features: int, out_features: int,\n",
    "                            in_physics_bond: int, \n",
    "                            out_physics_bond: int, virtual_bond_dim:int,\n",
    "                            bias: bool = True, label_position: int or str):\n",
    "        input  (B, in_features , in_physics_bond)\n",
    "        output (B, out_features)\n",
    "    '''\n",
    "    def __init__(self, in_features,out_features,\n",
    "                       in_physics_bond = 2, out_physics_bond=1, virtual_bond_dim=2,\n",
    "                       bias=True,label_position='center',init_std=1e-10,**kargs):\n",
    "        super().__init__()\n",
    "\n",
    "        if label_position is 'center':\n",
    "            label_position = in_features//2\n",
    "        assert type(label_position) is int\n",
    "        self.in_features   = in_features\n",
    "        self.out_features  = out_features\n",
    "        self.vbd           = virtual_bond_dim\n",
    "        self.ipb           = in_physics_bond\n",
    "        self.opb           = out_physics_bond\n",
    "        self.hn            = label_position\n",
    "        \n",
    "        left_num           = self.hn\n",
    "        right_num          = in_features - left_num\n",
    "\n",
    "        bias_mat     = torch.eye(self.ipb,self.vbd)\n",
    "        left_end     = init_std * torch.randn(self.ipb,self.vbd) + bias_mat\n",
    "\n",
    "        bias_mat     = torch.eye(self.vbd, self.ipb)\n",
    "        right_end    = init_std * torch.randn(self.vbd, self.ipb)+ bias_mat\n",
    "\n",
    "        bias_mat     = torch.eye(self.vbd).unsqueeze(1).repeat(1,self.ipb,1)\n",
    "        left_tensors = init_std * torch.randn(left_num-1 ,self.vbd, self.ipb , self.vbd)+ bias_mat\n",
    "        rigt_tensors = init_std * torch.randn(right_num-1,self.vbd, self.ipb,self.vbd)+ bias_mat\n",
    "\n",
    "\n",
    "        bias_mat     = torch.eye(self.vbd).unsqueeze(1).repeat(1,self.out_features,1)\n",
    "        cent_tensors = init_std * torch.randn(self.vbd,self.out_features,self.vbd)+ bias_mat\n",
    "\n",
    "        mps_var      = [left_end] + list(left_tensors)  + [cent_tensors] + list(rigt_tensors) + [right_end]\n",
    "        self.mps_var = [nn.Parameter(v) for v in mps_var]\n",
    "        self.center  = left_num\n",
    "        for i, v in enumerate(self.mps_var):\n",
    "            self.register_parameter(f'mps{i}', param=v)\n",
    "\n",
    "    def contract_mps_with_input(self,input):\n",
    "        assert len(input) == len(self.mps_var)-1\n",
    "        mps_list_1   = self.mps_var\n",
    "        mps_nodes_1  = [tn.Node(v, name=f\"t{i}\") for i,v in enumerate(mps_list_1)]\n",
    "        mps_edges_1  = [mps_nodes_1[i][-1]^mps_nodes_1[i+1][0] for i in range(len(mps_nodes_1)-1)]\n",
    "        inp_nodes    = [tn.Node(v, name=f\"i{i}\") for i,v in enumerate(input)]\n",
    "        for i,input_node in enumerate(inp_nodes):\n",
    "            j = i if i < self.center else i+1\n",
    "            mps_physicd_edge = mps_nodes_1[j][0] if j==0 else mps_nodes_1[j][1]\n",
    "            inp_physics_edge = input_node[0]\n",
    "            tn.connect(mps_physicd_edge,inp_physics_edge,name=f\"p_{i}\")\n",
    "\n",
    "        ans = contractors.auto(mps_nodes_1+inp_nodes,\n",
    "                              output_edge_order=[mps_nodes_1[self.center][1]]).tensor\n",
    "        return ans\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        out = torch.stack([self.contract_mps_with_input(single_input) for single_input in inputs])\n",
    "        return out\n",
    "    \n",
    "class MPSLinear_tn_batch(MPSLinear_tn_loop):\n",
    "    def forward(self, inputs):\n",
    "        num        = len(self.mps_var)\n",
    "        mps_nodes  = [tn.Node(v, name=f\"t{i}\") for i,v in enumerate(self.mps_var)]\n",
    "        mps_edges  = [mps_nodes[i][-1]^mps_nodes[i+1][0] for i in range(num-1)]\n",
    "\n",
    "\n",
    "        inputs= inputs.permute(1,2,0)#(B,num,k)->(num,k,B)\n",
    "        out   = torch.diag_embed(inputs)#(num,k,B)->(num,k,B,B)\n",
    "        out   = out.permute(0,2,1,3)#(num,k,B,B)->(num,B,k,B)\n",
    "        out   = [v for v in out]\n",
    "        out[0]= torch.diagonal(out[0], dim1=0, dim2=-1).transpose(1,0)#(B,k,B) -> #(B,k)\n",
    "\n",
    "        inp_nodes=[tn.Node(v, name=f\"i{i}\") for i,v in enumerate(out)]\n",
    "        inp_edges=[inp_nodes[0][0]^inp_nodes[1][0]]+ [\n",
    "            inp_nodes[i][-1]^inp_nodes[i+1][0] for i in range(1,len(inp_nodes)-1)]\n",
    "\n",
    "        for i,input_node in enumerate(inp_nodes):\n",
    "            j = i if i < self.center else i+1\n",
    "            mps_physicd_edge = mps_nodes[j][0] if j==0 else mps_nodes[j][1]\n",
    "            inp_physics_edge = input_node[1]\n",
    "            tn.connect(mps_physicd_edge,inp_physics_edge,name=f\"p_{i}\")\n",
    "\n",
    "        ans = contractors.auto(mps_nodes+inp_nodes,output_edge_order=[inp_nodes[-1][2],mps_nodes[self.center][1]]).tensor\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = MPSLinear_tn_loop(28*28,10,in_physics_bond = 2, out_physics_bond=1, virtual_bond_dim=10,\n",
    "                  bias=False,label_position='center',init_std=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = MPSLinear_tn_batch(28*28,10,in_physics_bond = 2, out_physics_bond=1, virtual_bond_dim=10,\n",
    "                  bias=False,label_position='center',init_std=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_input = torch.randn(2,28*28,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### AMPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#from models.amps import AMPSShare\n",
    "class AMPSShare(nn.Module):\n",
    "    '''\n",
    "    This version may fast, but will cost much more memory\n",
    "    n        : the length of input tensor sequence\n",
    "    bond_dim : the virtual bond dim. The capacity of model.\n",
    "    phys_dim : the feature/class number\n",
    "    ------------------------------\n",
    "    Input:  any data/spin configurations, shape: (B, n ,phys_dim)\n",
    "    Output: prob_matrix of each sample, shape: (B, n, phys_dim), pass softmax to get probility.\n",
    "    -------------------------------\n",
    "    Weight Cost:\n",
    "        n * bond_dim * bond_dim * phys_dim\n",
    "    '''\n",
    "    def __init__(self, n=784, bond_dim=10, phys_dim=2,std=1e-8):\n",
    "        super(AMPSShare, self).__init__()\n",
    "        # Initialize AMPS model parameters, which is a (n, D, D, 2) tensor\n",
    "        self.register_buffer('bias_mat', torch.eye(bond_dim).unsqueeze(-1).repeat(1,1,phys_dim))\n",
    "        # bias_mat: which is realy important when n>>1\n",
    "        self.tensors = nn.Parameter(std * torch.randn(n, bond_dim, bond_dim, phys_dim)+self.bias_mat)\n",
    "        # Set attributes\n",
    "        self.n = n\n",
    "        self.bond_dim = bond_dim\n",
    "        self.std = std\n",
    "\n",
    "    def forward(self, embedded_data):\n",
    "\n",
    "        bs = embedded_data.shape[0]\n",
    "        # local feature map, x_j -> [x_j, 1-x_j]\n",
    "        #-> embedded_data = torch.stack([data, 1.0 - data], dim=2)  # (bs, n, 2)\n",
    "        ##logx_hat = torch.zeros_like(embedded_data)\n",
    "        ##logx_hat[:, 0, :] = F.log_softmax(self.tensors[0, 0, 0], dim=0)\n",
    "        prob_matrix = self.tensors[0, 0, 0].repeat((bs,1)).unsqueeze(1) # (bs,1,2)\n",
    "        mats = torch.einsum('lri,bi->blr', self.tensors[0] , embedded_data[:, 0, :])\n",
    "        left_vec = mats[:, 0:1, :]  # (bs,  D)\n",
    "        for idx in range(1, self.n):\n",
    "            # compute p(s_2 | s_1) and so on\n",
    "            logits = torch.einsum('br, ri->bi', left_vec.squeeze(1),self.tensors[idx,:,0,:])\n",
    "            #(bs,D) <-> (D,2) ->(bs,2)\n",
    "            prob_matrix = torch.cat([prob_matrix,logits.unsqueeze(1)], dim=1)\n",
    "            #(bs, n-2, 2) + (bs,1,2) -> (bs, n-1, 2)\n",
    "            ##logx_hat[:, idx, :] = F.log_softmax(logits, dim=1)\n",
    "            mats = torch.einsum('lri,bi->blr', self.tensors[idx, :, :, :] , embedded_data[:, idx, :])\n",
    "            #(D,D,2) <-> (bs,2) ->(bs,D,D)\n",
    "            left_vec = torch.bmm(left_vec, mats)  # (bs, 1, D)\n",
    "        # compute log prob\n",
    "        return prob_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### PEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from models.two_dim_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 16])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= torch.randn(10,6,6,16)\n",
    "model(a).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### naive contractor: face dimenstion explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# tensor = torch.randn(8,8,6,6,6,6)\n",
    "# while tensor.shape[0]>2:\n",
    "#     print(tensor.shape)\n",
    "#     lu_tensor = tensor[0::2,0::2]\n",
    "#     ld_tensor = tensor[0::2,1::2]\n",
    "#     ru_tensor = tensor[1::2,0::2]\n",
    "#     rd_tensor = tensor[1::2,1::2]\n",
    "#     tensor     = torch.einsum(\"xyabcd,xyhdij,xycefg,xyigkl->xyahbefkjl\",\n",
    "#                             lu_tensor,\n",
    "#                             ld_tensor,\n",
    "#                             ru_tensor,\n",
    "#                             rd_tensor).flatten(4,5).flatten(-4,-3).flatten(2,3).flatten(-2,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### cotengra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensornetwork.contractors.opt_einsum_paths.utils import *\n",
    "from opt_einsum.paths import greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import opt_einsum as oe\n",
    "import tensornetwork as tn\n",
    "tn.set_default_backend(\"pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import opt_einsum as oe\n",
    "import tensornetwork as tn\n",
    "tn.set_default_backend(\"pytorch\")\n",
    "    from tensornetwork.contractors.opt_einsum_paths.utils import *\n",
    "tensor = torch.randn(16,16,2,2,2,2).cuda()\n",
    "\n",
    "node_array = []\n",
    "W,H = tensor.shape[:2]\n",
    "for i in range(W):\n",
    "    node_line = []\n",
    "    for j in range(H):\n",
    "        node = tn.Node(tensor[i][j],name=f\"{i}-{j}\")\n",
    "        node_line.append(node)\n",
    "    node_array.append(node_line)\n",
    "\n",
    "for i in range(W):\n",
    "    for j in range(H):\n",
    "        if j==H-1:tn.connect(node_array[i][j][2],node_array[i  ][0  ][0],f\"{i}{j}<->{i}{0}\")\n",
    "        else:     tn.connect(node_array[i][j][2],node_array[i  ][j+1][0],f\"{i}{j}<->{i}{j+1}\")\n",
    "        if i==W-1:tn.connect(node_array[i][j][3],node_array[0  ][j  ][1],f\"{i}{j}<->{0}{j}\")\n",
    "        else:     tn.connect(node_array[i][j][3],node_array[i+1][j  ][1],f\"{i}{j}<->{i+1}{j}\")\n",
    "\n",
    "node_list = [item for sublist in node_array for item in sublist]\n",
    "nodes = node_list\n",
    "input_sets = [set(node.edges) for node in nodes]\n",
    "output_set = get_subgraph_dangling(nodes)\n",
    "size_dict = {edge: edge.dimension for edge in get_all_edges(nodes)}\n",
    "\n",
    "operands = []\n",
    "for node,edge_label in zip(node_list,input_sets):\n",
    "    operands+=[node.tensor,[edge.name for edge in edge_label]]\n",
    "\n",
    "path,info = oe.contract_path(*operands)\n",
    "\n",
    "small_cores =[node.tensor for node in node_list]\n",
    "import tqdm as tqdm\n",
    "import cotengra as ctg\n",
    "\n",
    "sf = ctg.SliceFinder(info, target_size=2**27)\n",
    "inds_to_slice, cost_of_slicing = sf.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tqdm as tqdm\n",
    "import cotengra as ctg\n",
    "\n",
    "sf = ctg.SliceFinder(info, target_size=2**27)\n",
    "inds_to_slice, cost_of_slicing = sf.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67108864\n",
      "2.9753197715379116\n"
     ]
    }
   ],
   "source": [
    "print(cost_of_slicing.size    ) # the new largest intermediate\n",
    "print(cost_of_slicing.overhead)  # theoretical 'slowdown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/262144 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 15/262144 [00:00<30:05, 145.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 30/262144 [00:00<44:00, 99.28it/s] \u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 41/262144 [00:00<47:41, 91.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 51/262144 [00:00<49:42, 87.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 60/262144 [00:00<50:56, 85.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 69/262144 [00:00<51:48, 84.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 78/262144 [00:00<52:24, 83.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 87/262144 [00:00<53:13, 82.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 96/262144 [00:01<53:42, 81.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 105/262144 [00:01<53:43, 81.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 114/262144 [00:01<53:46, 81.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 123/262144 [00:01<53:46, 81.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 132/262144 [00:01<53:47, 81.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 141/262144 [00:01<53:47, 81.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 150/262144 [00:01<53:49, 81.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 159/262144 [00:01<53:48, 81.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 168/262144 [00:01<53:57, 80.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 177/262144 [00:02<54:10, 80.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 186/262144 [00:02<54:04, 80.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 195/262144 [00:02<54:04, 80.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 204/262144 [00:02<54:00, 80.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 213/262144 [00:02<54:03, 80.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 222/262144 [00:02<54:02, 80.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 231/262144 [00:02<53:58, 80.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 240/262144 [00:02<53:56, 80.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 249/262144 [00:02<54:02, 80.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 258/262144 [00:03<54:13, 80.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 267/262144 [00:03<54:05, 80.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 276/262144 [00:03<54:01, 80.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 285/262144 [00:03<54:05, 80.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 294/262144 [00:03<54:06, 80.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 303/262144 [00:03<54:04, 80.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 312/262144 [00:03<54:07, 80.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 321/262144 [00:03<54:03, 80.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 330/262144 [00:04<54:05, 80.68it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7c7e88620acd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSlicedContractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msmall_cores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontract_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# 100%|██████████| 512/512 [00:55<00:00,  9.30it/s]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-7c7e88620acd>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSlicedContractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msmall_cores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontract_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# 100%|██████████| 512/512 [00:55<00:00,  9.30it/s]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/cotengra/slicer.py\u001b[0m in \u001b[0;36mcontract_slice\u001b[0;34m(self, i, **kwargs)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \"\"\"\n\u001b[1;32m    585\u001b[0m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sliced_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/opt_einsum/contract.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *arrays, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_contract_with_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_constants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_constants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_contract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_constants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_constants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/opt_einsum/contract.py\u001b[0m in \u001b[0;36m_contract\u001b[0;34m(self, arrays, out, backend, evaluate_constants)\u001b[0m\n\u001b[1;32m    696\u001b[0m                               \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                               \u001b[0mevaluate_constants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_constants\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m                               **self.einsum_kwargs)\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_contract_with_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_constants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/opt_einsum/contract.py\u001b[0m in \u001b[0;36m_core_contract\u001b[0;34m(operands, contraction_list, backend, evaluate_constants, **einsum_kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;31m# Contract!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0mnew_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtmp_operands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;31m# Build a new view if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/opt_einsum/sharing.py\u001b[0m in \u001b[0;36mcached_tensordot\u001b[0;34m(x, y, axes, backend)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcached_tensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'numpy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcurrently_sharing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# hash based on the (axes_x,axes_y) form of axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/opt_einsum/contract.py\u001b[0m in \u001b[0;36m_tensordot\u001b[0;34m(x, y, axes, backend)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \"\"\"\n\u001b[1;32m    373\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensordot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/opt_einsum/backends/torch.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(x, y, axes)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_TORCH_HAS_TENSORDOT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mxnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(a, b, dims)\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0mdims_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m         \u001b[0mdims_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims_b\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcartesian_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sc = sf.SlicedContractor([*small_cores])\n",
    "result = sum(sc.contract_slice(i) for i in tqdm.trange(sc.nslices))\n",
    "# 100%|██████████| 512/512 [00:55<00:00,  9.30it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import opt_einsum as oe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 8), (0, 7), (0, 7), (0, 6), (0, 5), (0, 4), (0, 3), (1, 2), (0, 1), (0, 9), (0, 8), (0, 8), (0, 7), (0, 6), (1, 5), (1, 4), (1, 3), (1, 4), (3, 13), (7, 12), (3, 11), (3, 10), (3, 9), (3, 8), (6, 7), (3, 6), (3, 5), (3, 4), (2, 6), (2, 10), (1, 11), (4, 11), (0, 13), (5, 12), (5, 12), (6, 12), (5, 12), (6, 11), (6, 11), (6, 12), (4, 12), (6, 13), (7, 14), (7, 13), (4, 12), (6, 11), (6, 11), (6, 10), (6, 10), (0, 11), (0, 11), (5, 10), (0, 9), (4, 9), (2, 9), (1, 8), (3, 7), (3, 7), (3, 9), (3, 9), (3, 10), (3, 10), (3, 9), (3, 8), (1, 7), (2, 6), (6, 7), (2, 6), (2, 5), (2, 5), (5, 17), (6, 18), (12, 21), (4, 23), (13, 22), (4, 21), (15, 23), (10, 23), (10, 22), (7, 27), (11, 27), (11, 27), (11, 26), (7, 29), (9, 29), (8, 28), (15, 29), (7, 28), (13, 29), (6, 31), (6, 30), (13, 29), (16, 29), (1, 20), (21, 26), (21, 25), (6, 24), (15, 30), (15, 29), (8, 28), (10, 27), (6, 27), (10, 26), (8, 25), (9, 24), (5, 23), (2, 21), (10, 25), (5, 24), (2, 23), (1, 33), (1, 21), (0, 31), (2, 19), (4, 21), (5, 10), (7, 9), (4, 20), (1, 19), (0, 20), (14, 15), (6, 10), (3, 9), (2, 9), (5, 15), (0, 13), (6, 9), (5, 8), (4, 13), (3, 13), (1, 8), (1, 12), (0, 6), (1, 10), (3, 9), (7, 8), (3, 7), (0, 6), (2, 5), (3, 4), (2, 3), (0, 2), (0, 1)]\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn(12,12,4,4,4,4)/2\n",
    "#tensor     = torch.randn(2,2,16,16,16,16)/10\n",
    "computer_vie_tn(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arbitary partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### generate json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from models.arbitary_shape.shapes_list import shape_24x24_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from mltool.visualization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [
     5
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "info_per_point = {}\n",
    "info_per_group = {}\n",
    "for i,line in enumerate(shape_24x24_1):\n",
    "    for j,val in enumerate(line):\n",
    "        info_per_point[(i,j)] = {'val':val}\n",
    "def search_for(pos,group=None):\n",
    "    i,j = pos\n",
    "    val = info_per_point[pos]['val']\n",
    "    if 'group' not in info_per_point[pos]:\n",
    "        if group is None:group=len(info_per_group)\n",
    "        info_per_point[pos]['group']=group\n",
    "        if group not in info_per_group:info_per_group[group]={'element':[],'neighbor':set()}\n",
    "        info_per_group[group]['element'].append((i,j))\n",
    "        for neighbor in [(i-1,j),(i+1,j),(i,j-1),(i,j+1)]:    \n",
    "            if (neighbor in info_per_point):\n",
    "                neighbor_val = info_per_point[neighbor]['val']\n",
    "                if ('group' not in info_per_point[neighbor]) and (val == neighbor_val):\n",
    "                    search_for(neighbor,group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i,line in enumerate(shape_24x24_1):\n",
    "    for j,val in enumerate(line):\n",
    "        search_for((i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "info_per_line={}\n",
    "for i,line in enumerate(shape_24x24_1):\n",
    "    for j,val in enumerate(line):\n",
    "        group_now = info_per_point[(i,j)]['group']\n",
    "        for neighbor in [(i-1,j),(i+1,j),(i,j-1),(i+1)]:\n",
    "            if neighbor in info_per_point:\n",
    "                neighbor_group = info_per_point[neighbor]['group']\n",
    "                if neighbor_group!=group_now:\n",
    "                    info_per_group[group_now]['neighbor']=info_per_group[group_now]['neighbor']|set([neighbor_group])\n",
    "                    line_tuple = [group_now,neighbor_group]\n",
    "                    line_tuple.sort() \n",
    "                    line_tuple= tuple(line_tuple)\n",
    "                    if line_tuple not in info_per_line:\n",
    "                        info_per_line[line_tuple]={\"element\":[]}\n",
    "                    linepos=[(i,j),neighbor]\n",
    "                    linepos.sort() \n",
    "                    info_per_line[line_tuple][\"element\"].append(linepos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "center = np.array([(0+23)/2,(0+23)/2]) \n",
    "for line,pool in info_per_line.items():\n",
    "    start_pos=np.array([a for a,b in pool['element']])\n",
    "    ended_pos=np.array([b for a,b in pool['element']])\n",
    "    start_pos=np.mean(start_pos,0)\n",
    "    ended_pos=np.mean(ended_pos,0)\n",
    "    centr_pos=(start_pos + ended_pos)/2\n",
    "    \n",
    "    info_per_line[line]['weight']    = np.linalg.norm(centr_pos-center)\n",
    "    info_per_line[line]['start_pos'] = list(start_pos)\n",
    "    info_per_line[line]['ended_pos'] = list(ended_pos)\n",
    "    info_per_line[line]['centr_pos'] = list(centr_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MAX_Dimension = 12\n",
    "MIN_Dimension = 3\n",
    "weight_list  = [val['weight'] for val in info_per_line.values()]\n",
    "max_distance = max(weight_list)\n",
    "min_distance = min(weight_list)\n",
    "Dimenstion_function = lambda x : np.floor((MIN_Dimension-MAX_Dimension)/(max_distance-min_distance)*(x-min_distance)+MAX_Dimension)\n",
    "\n",
    "for line,pool in info_per_line.items():\n",
    "    info_per_line[line]['D']    = Dimenstion_function(info_per_line[line]['weight'])\n",
    "\n",
    "for group in info_per_group.keys():\n",
    "    info_per_group[group]['neighbor']=list(info_per_group[group]['neighbor'])\n",
    "\n",
    "for group,info in info_per_group.items():\n",
    "    info_per_group[group]['element_idx']=np.ravel_multi_index(np.array(info['element']).transpose(),(24,24)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "arbitary_shape_state_dict={}\n",
    "arbitary_shape_state_dict['node']   =info_per_group\n",
    "arbitary_shape_state_dict['line']   =info_per_line\n",
    "arbitary_shape_state_dict['element']=info_per_point\n",
    "torch.save(arbitary_shape_state_dict,\"models/arbitary_shape/arbitary_shape_2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "heading_collapsed": true
   },
   "source": [
    "##### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "arbitary_shape_state_dict = torch.load(\"models/arbitary_shape/arbitary_shape_2.json\")\n",
    "info_per_group = arbitary_shape_state_dict['node']\n",
    "info_per_line  = arbitary_shape_state_dict['line']\n",
    "info_per_point = arbitary_shape_state_dict['element']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'element': [[(0, 5), (0, 6)],\n",
       "  [(1, 5), (1, 6)],\n",
       "  [(2, 5), (2, 6)],\n",
       "  [(3, 5), (3, 6)],\n",
       "  [(4, 5), (4, 6)],\n",
       "  [(5, 5), (5, 6)],\n",
       "  [(6, 5), (6, 6)]],\n",
       " 'weight': 10.404326023342406,\n",
       " 'start_pos': [3.0, 5.0],\n",
       " 'ended_pos': [3.0, 6.0],\n",
       " 'centr_pos': [3.0, 5.5],\n",
       " 'D': 4.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_per_line[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": [
     12
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "objects = []\n",
    "offsite = 0.5\n",
    "scalar  = 4\n",
    "for (g_l,g_r), pool in info_per_line.items():\n",
    "    start_pos=pool['start_pos']\n",
    "    ended_pos=pool['ended_pos']\n",
    "    D = pool['D']\n",
    "    x0,y0  = scalar*np.array(start_pos)\n",
    "    x1,y1  = scalar*np.array(ended_pos)\n",
    "    objects.append(go.Scatter(x=[x0,x1],y=[y0,y1],mode='lines', fill=\"toself\",\n",
    "                          text=f\"D={D}\",hoveron='points',hoverinfo='text'\n",
    "                             )\n",
    "                  )\n",
    "\n",
    "for group, pool in info_per_group.items():\n",
    "    xes,yes=np.array(pool['element']).transpose()\n",
    "    w = max(xes)-min(xes)\n",
    "    h = max(yes)-min(yes)\n",
    "    c_x = xes.mean()\n",
    "    c_y = yes.mean()\n",
    "    x0  = scalar*min(xes)-offsite\n",
    "    x1  = scalar*max(xes)+offsite\n",
    "    y0  = scalar*min(yes)-offsite\n",
    "    y1  = scalar*max(yes)+offsite\n",
    "    objects.append(go.Scatter(x=[x0,x0,x1,x1,x0],y=[y0,y1,y1,y0,y0],mode='lines',fill=\"toself\",\n",
    "                               hoveron='fills',hoverinfo='text',text=f\"G={group}\",\n",
    "                              ))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          12,
          12
         ],
         "y": [
          20,
          24
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          2,
          2
         ],
         "y": [
          28,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          2,
          2
         ],
         "y": [
          60,
          64
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          12,
          12
         ],
         "y": [
          68,
          72
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          4,
          8
         ],
         "y": [
          46,
          46
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          10,
          10
         ],
         "y": [
          28,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          10,
          10
         ],
         "y": [
          60,
          64
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          12,
          16
         ],
         "y": [
          36,
          36
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          12,
          16
         ],
         "y": [
          46,
          46
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          12,
          16
         ],
         "y": [
          56,
          56
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          20,
          20
         ],
         "y": [
          28,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          20,
          20
         ],
         "y": [
          40,
          44
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          20,
          20
         ],
         "y": [
          48,
          52
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          20,
          20
         ],
         "y": [
          60,
          64
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          4,
          4
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          14,
          14
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          20,
          20
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          26,
          26
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          32,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=8.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          38,
          38
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=8.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          46,
          46
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=8.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          54,
          54
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          60,
          60
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          66,
          66
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          72,
          72
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          78,
          78
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          88,
          88
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          48,
          48
         ],
         "y": [
          8,
          12
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          48,
          48
         ],
         "y": [
          16,
          20
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          32,
          32
         ],
         "y": [
          20,
          24
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=9.0",
         "type": "scatter",
         "x": [
          32,
          32
         ],
         "y": [
          32,
          36
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=9.0",
         "type": "scatter",
         "x": [
          32,
          32
         ],
         "y": [
          40,
          44
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=9.0",
         "type": "scatter",
         "x": [
          32,
          32
         ],
         "y": [
          48,
          52
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=9.0",
         "type": "scatter",
         "x": [
          32,
          32
         ],
         "y": [
          56,
          60
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          32,
          32
         ],
         "y": [
          68,
          72
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          48,
          48
         ],
         "y": [
          72,
          76
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          48,
          48
         ],
         "y": [
          80,
          84
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=8.0",
         "type": "scatter",
         "x": [
          36,
          40
         ],
         "y": [
          26,
          26
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=9.0",
         "type": "scatter",
         "x": [
          36,
          40
         ],
         "y": [
          32,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=10.0",
         "type": "scatter",
         "x": [
          36,
          40
         ],
         "y": [
          38,
          38
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=11.0",
         "type": "scatter",
         "x": [
          36,
          40
         ],
         "y": [
          46,
          46
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=10.0",
         "type": "scatter",
         "x": [
          36,
          40
         ],
         "y": [
          54,
          54
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=9.0",
         "type": "scatter",
         "x": [
          36,
          40
         ],
         "y": [
          60,
          60
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=8.0",
         "type": "scatter",
         "x": [
          36,
          40
         ],
         "y": [
          66,
          66
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          44,
          44
         ],
         "y": [
          20,
          24
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=9.0",
         "type": "scatter",
         "x": [
          44,
          44
         ],
         "y": [
          28,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=11.0",
         "type": "scatter",
         "x": [
          44,
          44
         ],
         "y": [
          40,
          44
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=11.0",
         "type": "scatter",
         "x": [
          44,
          44
         ],
         "y": [
          48,
          52
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=9.0",
         "type": "scatter",
         "x": [
          44,
          44
         ],
         "y": [
          60,
          64
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          44,
          44
         ],
         "y": [
          68,
          72
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=8.0",
         "type": "scatter",
         "x": [
          48,
          52
         ],
         "y": [
          26,
          26
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=9.0",
         "type": "scatter",
         "x": [
          48,
          52
         ],
         "y": [
          32,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=10.0",
         "type": "scatter",
         "x": [
          48,
          52
         ],
         "y": [
          38,
          38
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=12.0",
         "type": "scatter",
         "x": [
          48,
          52
         ],
         "y": [
          46,
          46
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=10.0",
         "type": "scatter",
         "x": [
          48,
          52
         ],
         "y": [
          54,
          54
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=9.0",
         "type": "scatter",
         "x": [
          48,
          52
         ],
         "y": [
          60,
          60
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=8.0",
         "type": "scatter",
         "x": [
          48,
          52
         ],
         "y": [
          66,
          66
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          56,
          56
         ],
         "y": [
          20,
          24
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=9.0",
         "type": "scatter",
         "x": [
          56,
          56
         ],
         "y": [
          32,
          36
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=10.0",
         "type": "scatter",
         "x": [
          56,
          56
         ],
         "y": [
          40,
          44
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=10.0",
         "type": "scatter",
         "x": [
          56,
          56
         ],
         "y": [
          48,
          52
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=9.0",
         "type": "scatter",
         "x": [
          56,
          56
         ],
         "y": [
          56,
          60
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          56,
          56
         ],
         "y": [
          68,
          72
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          60,
          64
         ],
         "y": [
          26,
          26
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=8.0",
         "type": "scatter",
         "x": [
          60,
          64
         ],
         "y": [
          32,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=9.0",
         "type": "scatter",
         "x": [
          60,
          64
         ],
         "y": [
          38,
          38
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=9.0",
         "type": "scatter",
         "x": [
          60,
          64
         ],
         "y": [
          46,
          46
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=9.0",
         "type": "scatter",
         "x": [
          60,
          64
         ],
         "y": [
          54,
          54
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=8.0",
         "type": "scatter",
         "x": [
          60,
          64
         ],
         "y": [
          60,
          60
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          60,
          64
         ],
         "y": [
          66,
          66
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          66,
          66
         ],
         "y": [
          20,
          24
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          68,
          68
         ],
         "y": [
          28,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=8.0",
         "type": "scatter",
         "x": [
          68,
          68
         ],
         "y": [
          40,
          44
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=8.0",
         "type": "scatter",
         "x": [
          68,
          68
         ],
         "y": [
          48,
          52
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          68,
          68
         ],
         "y": [
          60,
          64
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          66,
          66
         ],
         "y": [
          68,
          72
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          68,
          72
         ],
         "y": [
          4,
          4
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          68,
          72
         ],
         "y": [
          14,
          14
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          68,
          72
         ],
         "y": [
          20,
          20
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          68,
          72
         ],
         "y": [
          72,
          72
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          68,
          72
         ],
         "y": [
          78,
          78
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          68,
          72
         ],
         "y": [
          88,
          88
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          82,
          82
         ],
         "y": [
          20,
          24
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          72,
          76
         ],
         "y": [
          36,
          36
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          72,
          76
         ],
         "y": [
          46,
          46
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          72,
          76
         ],
         "y": [
          56,
          56
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          82,
          82
         ],
         "y": [
          68,
          72
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          78,
          78
         ],
         "y": [
          28,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          78,
          78
         ],
         "y": [
          60,
          64
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          80,
          84
         ],
         "y": [
          46,
          46
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          88,
          88
         ],
         "y": [
          28,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          88,
          88
         ],
         "y": [
          60,
          64
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=0",
         "type": "scatter",
         "x": [
          -0.5,
          -0.5,
          24.5,
          24.5,
          -0.5
         ],
         "y": [
          -0.5,
          20.5,
          20.5,
          -0.5,
          -0.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=1",
         "type": "scatter",
         "x": [
          -0.5,
          -0.5,
          24.5,
          24.5,
          -0.5
         ],
         "y": [
          23.5,
          28.5,
          28.5,
          23.5,
          23.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=2",
         "type": "scatter",
         "x": [
          -0.5,
          -0.5,
          4.5,
          4.5,
          -0.5
         ],
         "y": [
          31.5,
          60.5,
          60.5,
          31.5,
          31.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=3",
         "type": "scatter",
         "x": [
          -0.5,
          -0.5,
          24.5,
          24.5,
          -0.5
         ],
         "y": [
          63.5,
          68.5,
          68.5,
          63.5,
          63.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=4",
         "type": "scatter",
         "x": [
          -0.5,
          -0.5,
          24.5,
          24.5,
          -0.5
         ],
         "y": [
          71.5,
          92.5,
          92.5,
          71.5,
          71.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=5",
         "type": "scatter",
         "x": [
          7.5,
          7.5,
          12.5,
          12.5,
          7.5
         ],
         "y": [
          31.5,
          60.5,
          60.5,
          31.5,
          31.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=6",
         "type": "scatter",
         "x": [
          15.5,
          15.5,
          24.5,
          24.5,
          15.5
         ],
         "y": [
          31.5,
          40.5,
          40.5,
          31.5,
          31.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=7",
         "type": "scatter",
         "x": [
          15.5,
          15.5,
          24.5,
          24.5,
          15.5
         ],
         "y": [
          43.5,
          48.5,
          48.5,
          43.5,
          43.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=8",
         "type": "scatter",
         "x": [
          15.5,
          15.5,
          24.5,
          24.5,
          15.5
         ],
         "y": [
          51.5,
          60.5,
          60.5,
          51.5,
          51.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=9",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          68.5,
          68.5,
          27.5
         ],
         "y": [
          -0.5,
          8.5,
          8.5,
          -0.5,
          -0.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=10",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          68.5,
          68.5,
          27.5
         ],
         "y": [
          11.5,
          16.5,
          16.5,
          11.5,
          11.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=11",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          68.5,
          68.5,
          27.5
         ],
         "y": [
          19.5,
          20.5,
          20.5,
          19.5,
          19.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=12",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          36.5,
          36.5,
          27.5
         ],
         "y": [
          23.5,
          32.5,
          32.5,
          23.5,
          23.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=13",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          36.5,
          36.5,
          27.5
         ],
         "y": [
          35.5,
          40.5,
          40.5,
          35.5,
          35.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=14",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          36.5,
          36.5,
          27.5
         ],
         "y": [
          43.5,
          48.5,
          48.5,
          43.5,
          43.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=15",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          36.5,
          36.5,
          27.5
         ],
         "y": [
          51.5,
          56.5,
          56.5,
          51.5,
          51.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=16",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          36.5,
          36.5,
          27.5
         ],
         "y": [
          59.5,
          68.5,
          68.5,
          59.5,
          59.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=17",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          68.5,
          68.5,
          27.5
         ],
         "y": [
          71.5,
          72.5,
          72.5,
          71.5,
          71.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=18",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          68.5,
          68.5,
          27.5
         ],
         "y": [
          75.5,
          80.5,
          80.5,
          75.5,
          75.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=19",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          68.5,
          68.5,
          27.5
         ],
         "y": [
          83.5,
          92.5,
          92.5,
          83.5,
          83.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=20",
         "type": "scatter",
         "x": [
          39.5,
          39.5,
          48.5,
          48.5,
          39.5
         ],
         "y": [
          23.5,
          28.5,
          28.5,
          23.5,
          23.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=21",
         "type": "scatter",
         "x": [
          39.5,
          39.5,
          48.5,
          48.5,
          39.5
         ],
         "y": [
          31.5,
          40.5,
          40.5,
          31.5,
          31.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=22",
         "type": "scatter",
         "x": [
          39.5,
          39.5,
          48.5,
          48.5,
          39.5
         ],
         "y": [
          43.5,
          48.5,
          48.5,
          43.5,
          43.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=23",
         "type": "scatter",
         "x": [
          39.5,
          39.5,
          48.5,
          48.5,
          39.5
         ],
         "y": [
          51.5,
          60.5,
          60.5,
          51.5,
          51.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=24",
         "type": "scatter",
         "x": [
          39.5,
          39.5,
          48.5,
          48.5,
          39.5
         ],
         "y": [
          63.5,
          68.5,
          68.5,
          63.5,
          63.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=25",
         "type": "scatter",
         "x": [
          51.5,
          51.5,
          60.5,
          60.5,
          51.5
         ],
         "y": [
          23.5,
          32.5,
          32.5,
          23.5,
          23.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=26",
         "type": "scatter",
         "x": [
          51.5,
          51.5,
          60.5,
          60.5,
          51.5
         ],
         "y": [
          35.5,
          40.5,
          40.5,
          35.5,
          35.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=27",
         "type": "scatter",
         "x": [
          51.5,
          51.5,
          60.5,
          60.5,
          51.5
         ],
         "y": [
          43.5,
          48.5,
          48.5,
          43.5,
          43.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=28",
         "type": "scatter",
         "x": [
          51.5,
          51.5,
          60.5,
          60.5,
          51.5
         ],
         "y": [
          51.5,
          56.5,
          56.5,
          51.5,
          51.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=29",
         "type": "scatter",
         "x": [
          51.5,
          51.5,
          60.5,
          60.5,
          51.5
         ],
         "y": [
          59.5,
          68.5,
          68.5,
          59.5,
          59.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=30",
         "type": "scatter",
         "x": [
          63.5,
          63.5,
          92.5,
          92.5,
          63.5
         ],
         "y": [
          23.5,
          28.5,
          28.5,
          23.5,
          23.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=31",
         "type": "scatter",
         "x": [
          63.5,
          63.5,
          72.5,
          72.5,
          63.5
         ],
         "y": [
          31.5,
          40.5,
          40.5,
          31.5,
          31.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=32",
         "type": "scatter",
         "x": [
          63.5,
          63.5,
          72.5,
          72.5,
          63.5
         ],
         "y": [
          43.5,
          48.5,
          48.5,
          43.5,
          43.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=33",
         "type": "scatter",
         "x": [
          63.5,
          63.5,
          72.5,
          72.5,
          63.5
         ],
         "y": [
          51.5,
          60.5,
          60.5,
          51.5,
          51.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=34",
         "type": "scatter",
         "x": [
          63.5,
          63.5,
          92.5,
          92.5,
          63.5
         ],
         "y": [
          63.5,
          68.5,
          68.5,
          63.5,
          63.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=35",
         "type": "scatter",
         "x": [
          71.5,
          71.5,
          92.5,
          92.5,
          71.5
         ],
         "y": [
          -0.5,
          20.5,
          20.5,
          -0.5,
          -0.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=36",
         "type": "scatter",
         "x": [
          71.5,
          71.5,
          92.5,
          92.5,
          71.5
         ],
         "y": [
          71.5,
          92.5,
          92.5,
          71.5,
          71.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=37",
         "type": "scatter",
         "x": [
          75.5,
          75.5,
          80.5,
          80.5,
          75.5
         ],
         "y": [
          31.5,
          60.5,
          60.5,
          31.5,
          31.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=38",
         "type": "scatter",
         "x": [
          83.5,
          83.5,
          92.5,
          92.5,
          83.5
         ],
         "y": [
          31.5,
          60.5,
          60.5,
          31.5,
          31.5
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "height": 900,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 900,
        "xaxis": {
         "fixedrange": true,
         "showgrid": false,
         "showline": false,
         "showticklabels": false,
         "zeroline": false
        },
        "yaxis": {
         "scaleanchor": "x",
         "scaleratio": 1,
         "showgrid": false,
         "showline": false,
         "showticklabels": false,
         "zeroline": false
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"6eb21137-f95a-4891-a6d8-335fab353683\" class=\"plotly-graph-div\" style=\"height:900px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6eb21137-f95a-4891-a6d8-335fab353683\")) {                    Plotly.newPlot(                        \"6eb21137-f95a-4891-a6d8-335fab353683\",                        [{\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [12.0, 12.0], \"y\": [20.0, 24.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [2.0, 2.0], \"y\": [28.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [2.0, 2.0], \"y\": [60.0, 64.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [12.0, 12.0], \"y\": [68.0, 72.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [4.0, 8.0], \"y\": [46.0, 46.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [10.0, 10.0], \"y\": [28.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [10.0, 10.0], \"y\": [60.0, 64.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [12.0, 16.0], \"y\": [36.0, 36.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [12.0, 16.0], \"y\": [46.0, 46.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [12.0, 16.0], \"y\": [56.0, 56.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [20.0, 20.0], \"y\": [28.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [20.0, 20.0], \"y\": [40.0, 44.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [20.0, 20.0], \"y\": [48.0, 52.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [20.0, 20.0], \"y\": [60.0, 64.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [4.0, 4.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [14.0, 14.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [20.0, 20.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [26.0, 26.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [32.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=8.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [38.0, 38.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=8.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [46.0, 46.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=8.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [54.0, 54.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [60.0, 60.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [66.0, 66.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [72.0, 72.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [78.0, 78.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [88.0, 88.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [48.0, 48.0], \"y\": [8.0, 12.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [48.0, 48.0], \"y\": [16.0, 20.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [32.0, 32.0], \"y\": [20.0, 24.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=9.0\", \"type\": \"scatter\", \"x\": [32.0, 32.0], \"y\": [32.0, 36.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=9.0\", \"type\": \"scatter\", \"x\": [32.0, 32.0], \"y\": [40.0, 44.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=9.0\", \"type\": \"scatter\", \"x\": [32.0, 32.0], \"y\": [48.0, 52.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=9.0\", \"type\": \"scatter\", \"x\": [32.0, 32.0], \"y\": [56.0, 60.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [32.0, 32.0], \"y\": [68.0, 72.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [48.0, 48.0], \"y\": [72.0, 76.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [48.0, 48.0], \"y\": [80.0, 84.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=8.0\", \"type\": \"scatter\", \"x\": [36.0, 40.0], \"y\": [26.0, 26.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=9.0\", \"type\": \"scatter\", \"x\": [36.0, 40.0], \"y\": [32.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=10.0\", \"type\": \"scatter\", \"x\": [36.0, 40.0], \"y\": [38.0, 38.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=11.0\", \"type\": \"scatter\", \"x\": [36.0, 40.0], \"y\": [46.0, 46.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=10.0\", \"type\": \"scatter\", \"x\": [36.0, 40.0], \"y\": [54.0, 54.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=9.0\", \"type\": \"scatter\", \"x\": [36.0, 40.0], \"y\": [60.0, 60.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=8.0\", \"type\": \"scatter\", \"x\": [36.0, 40.0], \"y\": [66.0, 66.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [44.0, 44.0], \"y\": [20.0, 24.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=9.0\", \"type\": \"scatter\", \"x\": [44.0, 44.0], \"y\": [28.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=11.0\", \"type\": \"scatter\", \"x\": [44.0, 44.0], \"y\": [40.0, 44.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=11.0\", \"type\": \"scatter\", \"x\": [44.0, 44.0], \"y\": [48.0, 52.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=9.0\", \"type\": \"scatter\", \"x\": [44.0, 44.0], \"y\": [60.0, 64.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [44.0, 44.0], \"y\": [68.0, 72.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=8.0\", \"type\": \"scatter\", \"x\": [48.0, 52.0], \"y\": [26.0, 26.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=9.0\", \"type\": \"scatter\", \"x\": [48.0, 52.0], \"y\": [32.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=10.0\", \"type\": \"scatter\", \"x\": [48.0, 52.0], \"y\": [38.0, 38.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=12.0\", \"type\": \"scatter\", \"x\": [48.0, 52.0], \"y\": [46.0, 46.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=10.0\", \"type\": \"scatter\", \"x\": [48.0, 52.0], \"y\": [54.0, 54.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=9.0\", \"type\": \"scatter\", \"x\": [48.0, 52.0], \"y\": [60.0, 60.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=8.0\", \"type\": \"scatter\", \"x\": [48.0, 52.0], \"y\": [66.0, 66.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [56.0, 56.0], \"y\": [20.0, 24.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=9.0\", \"type\": \"scatter\", \"x\": [56.0, 56.0], \"y\": [32.0, 36.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=10.0\", \"type\": \"scatter\", \"x\": [56.0, 56.0], \"y\": [40.0, 44.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=10.0\", \"type\": \"scatter\", \"x\": [56.0, 56.0], \"y\": [48.0, 52.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=9.0\", \"type\": \"scatter\", \"x\": [56.0, 56.0], \"y\": [56.0, 60.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [56.0, 56.0], \"y\": [68.0, 72.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [60.0, 64.0], \"y\": [26.0, 26.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=8.0\", \"type\": \"scatter\", \"x\": [60.0, 64.0], \"y\": [32.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=9.0\", \"type\": \"scatter\", \"x\": [60.0, 64.0], \"y\": [38.0, 38.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=9.0\", \"type\": \"scatter\", \"x\": [60.0, 64.0], \"y\": [46.0, 46.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=9.0\", \"type\": \"scatter\", \"x\": [60.0, 64.0], \"y\": [54.0, 54.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=8.0\", \"type\": \"scatter\", \"x\": [60.0, 64.0], \"y\": [60.0, 60.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [60.0, 64.0], \"y\": [66.0, 66.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [66.0, 66.0], \"y\": [20.0, 24.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [68.0, 68.0], \"y\": [28.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=8.0\", \"type\": \"scatter\", \"x\": [68.0, 68.0], \"y\": [40.0, 44.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=8.0\", \"type\": \"scatter\", \"x\": [68.0, 68.0], \"y\": [48.0, 52.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [68.0, 68.0], \"y\": [60.0, 64.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [66.0, 66.0], \"y\": [68.0, 72.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [68.0, 72.0], \"y\": [4.0, 4.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [68.0, 72.0], \"y\": [14.0, 14.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [68.0, 72.0], \"y\": [20.0, 20.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [68.0, 72.0], \"y\": [72.0, 72.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [68.0, 72.0], \"y\": [78.0, 78.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [68.0, 72.0], \"y\": [88.0, 88.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [82.0, 82.0], \"y\": [20.0, 24.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [72.0, 76.0], \"y\": [36.0, 36.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [72.0, 76.0], \"y\": [46.0, 46.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [72.0, 76.0], \"y\": [56.0, 56.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [82.0, 82.0], \"y\": [68.0, 72.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [78.0, 78.0], \"y\": [28.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [78.0, 78.0], \"y\": [60.0, 64.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [80.0, 84.0], \"y\": [46.0, 46.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [88.0, 88.0], \"y\": [28.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [88.0, 88.0], \"y\": [60.0, 64.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=0\", \"type\": \"scatter\", \"x\": [-0.5, -0.5, 24.5, 24.5, -0.5], \"y\": [-0.5, 20.5, 20.5, -0.5, -0.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=1\", \"type\": \"scatter\", \"x\": [-0.5, -0.5, 24.5, 24.5, -0.5], \"y\": [23.5, 28.5, 28.5, 23.5, 23.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=2\", \"type\": \"scatter\", \"x\": [-0.5, -0.5, 4.5, 4.5, -0.5], \"y\": [31.5, 60.5, 60.5, 31.5, 31.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=3\", \"type\": \"scatter\", \"x\": [-0.5, -0.5, 24.5, 24.5, -0.5], \"y\": [63.5, 68.5, 68.5, 63.5, 63.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=4\", \"type\": \"scatter\", \"x\": [-0.5, -0.5, 24.5, 24.5, -0.5], \"y\": [71.5, 92.5, 92.5, 71.5, 71.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=5\", \"type\": \"scatter\", \"x\": [7.5, 7.5, 12.5, 12.5, 7.5], \"y\": [31.5, 60.5, 60.5, 31.5, 31.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=6\", \"type\": \"scatter\", \"x\": [15.5, 15.5, 24.5, 24.5, 15.5], \"y\": [31.5, 40.5, 40.5, 31.5, 31.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=7\", \"type\": \"scatter\", \"x\": [15.5, 15.5, 24.5, 24.5, 15.5], \"y\": [43.5, 48.5, 48.5, 43.5, 43.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=8\", \"type\": \"scatter\", \"x\": [15.5, 15.5, 24.5, 24.5, 15.5], \"y\": [51.5, 60.5, 60.5, 51.5, 51.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=9\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 68.5, 68.5, 27.5], \"y\": [-0.5, 8.5, 8.5, -0.5, -0.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=10\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 68.5, 68.5, 27.5], \"y\": [11.5, 16.5, 16.5, 11.5, 11.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=11\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 68.5, 68.5, 27.5], \"y\": [19.5, 20.5, 20.5, 19.5, 19.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=12\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 36.5, 36.5, 27.5], \"y\": [23.5, 32.5, 32.5, 23.5, 23.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=13\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 36.5, 36.5, 27.5], \"y\": [35.5, 40.5, 40.5, 35.5, 35.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=14\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 36.5, 36.5, 27.5], \"y\": [43.5, 48.5, 48.5, 43.5, 43.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=15\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 36.5, 36.5, 27.5], \"y\": [51.5, 56.5, 56.5, 51.5, 51.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=16\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 36.5, 36.5, 27.5], \"y\": [59.5, 68.5, 68.5, 59.5, 59.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=17\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 68.5, 68.5, 27.5], \"y\": [71.5, 72.5, 72.5, 71.5, 71.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=18\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 68.5, 68.5, 27.5], \"y\": [75.5, 80.5, 80.5, 75.5, 75.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=19\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 68.5, 68.5, 27.5], \"y\": [83.5, 92.5, 92.5, 83.5, 83.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=20\", \"type\": \"scatter\", \"x\": [39.5, 39.5, 48.5, 48.5, 39.5], \"y\": [23.5, 28.5, 28.5, 23.5, 23.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=21\", \"type\": \"scatter\", \"x\": [39.5, 39.5, 48.5, 48.5, 39.5], \"y\": [31.5, 40.5, 40.5, 31.5, 31.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=22\", \"type\": \"scatter\", \"x\": [39.5, 39.5, 48.5, 48.5, 39.5], \"y\": [43.5, 48.5, 48.5, 43.5, 43.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=23\", \"type\": \"scatter\", \"x\": [39.5, 39.5, 48.5, 48.5, 39.5], \"y\": [51.5, 60.5, 60.5, 51.5, 51.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=24\", \"type\": \"scatter\", \"x\": [39.5, 39.5, 48.5, 48.5, 39.5], \"y\": [63.5, 68.5, 68.5, 63.5, 63.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=25\", \"type\": \"scatter\", \"x\": [51.5, 51.5, 60.5, 60.5, 51.5], \"y\": [23.5, 32.5, 32.5, 23.5, 23.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=26\", \"type\": \"scatter\", \"x\": [51.5, 51.5, 60.5, 60.5, 51.5], \"y\": [35.5, 40.5, 40.5, 35.5, 35.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=27\", \"type\": \"scatter\", \"x\": [51.5, 51.5, 60.5, 60.5, 51.5], \"y\": [43.5, 48.5, 48.5, 43.5, 43.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=28\", \"type\": \"scatter\", \"x\": [51.5, 51.5, 60.5, 60.5, 51.5], \"y\": [51.5, 56.5, 56.5, 51.5, 51.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=29\", \"type\": \"scatter\", \"x\": [51.5, 51.5, 60.5, 60.5, 51.5], \"y\": [59.5, 68.5, 68.5, 59.5, 59.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=30\", \"type\": \"scatter\", \"x\": [63.5, 63.5, 92.5, 92.5, 63.5], \"y\": [23.5, 28.5, 28.5, 23.5, 23.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=31\", \"type\": \"scatter\", \"x\": [63.5, 63.5, 72.5, 72.5, 63.5], \"y\": [31.5, 40.5, 40.5, 31.5, 31.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=32\", \"type\": \"scatter\", \"x\": [63.5, 63.5, 72.5, 72.5, 63.5], \"y\": [43.5, 48.5, 48.5, 43.5, 43.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=33\", \"type\": \"scatter\", \"x\": [63.5, 63.5, 72.5, 72.5, 63.5], \"y\": [51.5, 60.5, 60.5, 51.5, 51.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=34\", \"type\": \"scatter\", \"x\": [63.5, 63.5, 92.5, 92.5, 63.5], \"y\": [63.5, 68.5, 68.5, 63.5, 63.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=35\", \"type\": \"scatter\", \"x\": [71.5, 71.5, 92.5, 92.5, 71.5], \"y\": [-0.5, 20.5, 20.5, -0.5, -0.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=36\", \"type\": \"scatter\", \"x\": [71.5, 71.5, 92.5, 92.5, 71.5], \"y\": [71.5, 92.5, 92.5, 71.5, 71.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=37\", \"type\": \"scatter\", \"x\": [75.5, 75.5, 80.5, 80.5, 75.5], \"y\": [31.5, 60.5, 60.5, 31.5, 31.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=38\", \"type\": \"scatter\", \"x\": [83.5, 83.5, 92.5, 92.5, 83.5], \"y\": [31.5, 60.5, 60.5, 31.5, 31.5]}],                        {\"autosize\": false, \"height\": 900, \"hoverlabel\": {\"bgcolor\": \"white\", \"font\": {\"family\": \"Rockwell\", \"size\": 16}}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"width\": 900, \"xaxis\": {\"fixedrange\": true, \"showgrid\": false, \"showline\": false, \"showticklabels\": false, \"zeroline\": false}, \"yaxis\": {\"scaleanchor\": \"x\", \"scaleratio\": 1, \"showgrid\": false, \"showline\": false, \"showticklabels\": false, \"zeroline\": false}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('6eb21137-f95a-4891-a6d8-335fab353683');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "axis = dict(showline=False, zeroline=False,showgrid=False,showticklabels=False,)\n",
    "fig.update_layout(showlegend=False,xaxis=axis,yaxis=axis,plot_bgcolor='white')\n",
    "fig.update_layout(\n",
    "         autosize=False,\n",
    "            width=900,\n",
    "            height=900,\n",
    "        hoverlabel=dict(\n",
    "        bgcolor=\"white\",\n",
    "        font_size=16,\n",
    "        font_family=\"Rockwell\"\n",
    "        )\n",
    ")\n",
    "fig.update_xaxes(fixedrange=True)\n",
    "fig.update_yaxes(scaleanchor = \"x\",scaleratio = 1,)\n",
    "#if show_name: self.depoly_label(fig)\n",
    "for obj in objects:fig.add_trace(obj)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "matrix=[]\n",
    "for i in range(24):\n",
    "    line=[]\n",
    "    for j in range(24):\n",
    "        line.append(info_per_point[i,j]['group'])\n",
    "    matrix.append(line)\n",
    "matrix = np.array(matrix)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[{'val': 4, 'group': 0}, {'val': 4, 'group': 0},\n",
       "        {'val': 4, 'group': 0}, {'val': 4, 'group': 0},\n",
       "        {'val': 4, 'group': 0}, {'val': 4, 'group': 0},\n",
       "        {'val': 0, 'group': 1}, {'val': 0, 'group': 1},\n",
       "        {'val': 4, 'group': 2}, {'val': 4, 'group': 2},\n",
       "        {'val': 4, 'group': 2}, {'val': 4, 'group': 2},\n",
       "        {'val': 4, 'group': 2}, {'val': 4, 'group': 2},\n",
       "        {'val': 4, 'group': 2}, {'val': 4, 'group': 2},\n",
       "        {'val': 0, 'group': 3}, {'val': 0, 'group': 3},\n",
       "        {'val': 4, 'group': 4}, {'val': 4, 'group': 4},\n",
       "        {'val': 4, 'group': 4}, {'val': 4, 'group': 4},\n",
       "        {'val': 4, 'group': 4}, {'val': 4, 'group': 4}],\n",
       "       [{'val': 4, 'group': 0}, {'val': 4, 'group': 0},\n",
       "        {'val': 4, 'group': 0}, {'val': 4, 'group': 0},\n",
       "        {'val': 4, 'group': 0}, {'val': 4, 'group': 0},\n",
       "        {'val': 0, 'group': 1}, {'val': 0, 'group': 1},\n",
       "        {'val': 4, 'group': 2}, {'val': 4, 'group': 2},\n",
       "        {'val': 4, 'group': 2}, {'val': 4, 'group': 2},\n",
       "        {'val': 4, 'group': 2}, {'val': 4, 'group': 2},\n",
       "        {'val': 4, 'group': 2}, {'val': 4, 'group': 2},\n",
       "        {'val': 0, 'group': 3}, {'val': 0, 'group': 3},\n",
       "        {'val': 4, 'group': 4}, {'val': 4, 'group': 4},\n",
       "        {'val': 4, 'group': 4}, {'val': 4, 'group': 4},\n",
       "        {'val': 4, 'group': 4}, {'val': 4, 'group': 4}],\n",
       "       [{'val': 4, 'group': 0}, {'val': 4, 'group': 0},\n",
       "        {'val': 4, 'group': 0}, {'val': 4, 'group': 0},\n",
       "        {'val': 4, 'group': 0}, {'val': 4, 'group': 0},\n",
       "        {'val': 0, 'group': 1}, {'val': 0, 'group': 1},\n",
       "        {'val': 6, 'group': 5}, {'val': 6, 'group': 5},\n",
       "        {'val': 6, 'group': 5}, {'val': 6, 'group': 5},\n",
       "        {'val': 6, 'group': 5}, {'val': 6, 'group': 5},\n",
       "        {'val': 6, 'group': 5}, {'val': 6, 'group': 5},\n",
       "        {'val': 0, 'group': 3}, {'val': 0, 'group': 3},\n",
       "        {'val': 4, 'group': 4}, {'val': 4, 'group': 4},\n",
       "        {'val': 4, 'group': 4}, {'val': 4, 'group': 4},\n",
       "        {'val': 4, 'group': 4}, {'val': 4, 'group': 4}],\n",
       "       [{'val': 4, 'group': 0}, {'val': 4, 'group': 0},\n",
       "        {'val': 4, 'group': 0}, {'val': 4, 'group': 0},\n",
       "        {'val': 4, 'group': 0}, {'val': 4, 'group': 0},\n",
       "        {'val': 0, 'group': 1}, {'val': 0, 'group': 1},\n",
       "        {'val': 6, 'group': 5}, {'val': 6, 'group': 5},\n",
       "        {'val': 6, 'group': 5}, {'val': 6, 'group': 5},\n",
       "        {'val': 6, 'group': 5}, {'val': 6, 'group': 5},\n",
       "        {'val': 6, 'group': 5}, {'val': 6, 'group': 5},\n",
       "        {'val': 0, 'group': 3}, {'val': 0, 'group': 3},\n",
       "        {'val': 4, 'group': 4}, {'val': 4, 'group': 4},\n",
       "        {'val': 4, 'group': 4}, {'val': 4, 'group': 4},\n",
       "        {'val': 4, 'group': 4}, {'val': 4, 'group': 4}],\n",
       "       [{'val': 4, 'group': 0}, {'val': 4, 'group': 0},\n",
       "        {'val': 4, 'group': 0}, {'val': 4, 'group': 0},\n",
       "        {'val': 4, 'group': 0}, {'val': 4, 'group': 0},\n",
       "        {'val': 0, 'group': 1}, {'val': 0, 'group': 1},\n",
       "        {'val': 2, 'group': 6}, {'val': 2, 'group': 6},\n",
       "        {'val': 2, 'group': 6}, {'val': 4, 'group': 7},\n",
       "        {'val': 4, 'group': 7}, {'val': 2, 'group': 8},\n",
       "        {'val': 2, 'group': 8}, {'val': 2, 'group': 8},\n",
       "        {'val': 0, 'group': 3}, {'val': 0, 'group': 3},\n",
       "        {'val': 4, 'group': 4}, {'val': 4, 'group': 4},\n",
       "        {'val': 4, 'group': 4}, {'val': 4, 'group': 4},\n",
       "        {'val': 4, 'group': 4}, {'val': 4, 'group': 4}],\n",
       "       [{'val': 4, 'group': 0}, {'val': 4, 'group': 0},\n",
       "        {'val': 4, 'group': 0}, {'val': 4, 'group': 0},\n",
       "        {'val': 4, 'group': 0}, {'val': 4, 'group': 0},\n",
       "        {'val': 0, 'group': 1}, {'val': 0, 'group': 1},\n",
       "        {'val': 2, 'group': 6}, {'val': 2, 'group': 6},\n",
       "        {'val': 2, 'group': 6}, {'val': 4, 'group': 7},\n",
       "        {'val': 4, 'group': 7}, {'val': 2, 'group': 8},\n",
       "        {'val': 2, 'group': 8}, {'val': 2, 'group': 8},\n",
       "        {'val': 0, 'group': 3}, {'val': 0, 'group': 3},\n",
       "        {'val': 4, 'group': 4}, {'val': 4, 'group': 4},\n",
       "        {'val': 4, 'group': 4}, {'val': 4, 'group': 4},\n",
       "        {'val': 4, 'group': 4}, {'val': 4, 'group': 4}],\n",
       "       [{'val': 4, 'group': 0}, {'val': 4, 'group': 0},\n",
       "        {'val': 4, 'group': 0}, {'val': 4, 'group': 0},\n",
       "        {'val': 4, 'group': 0}, {'val': 4, 'group': 0},\n",
       "        {'val': 0, 'group': 1}, {'val': 0, 'group': 1},\n",
       "        {'val': 2, 'group': 6}, {'val': 2, 'group': 6},\n",
       "        {'val': 2, 'group': 6}, {'val': 4, 'group': 7},\n",
       "        {'val': 4, 'group': 7}, {'val': 2, 'group': 8},\n",
       "        {'val': 2, 'group': 8}, {'val': 2, 'group': 8},\n",
       "        {'val': 0, 'group': 3}, {'val': 0, 'group': 3},\n",
       "        {'val': 4, 'group': 4}, {'val': 4, 'group': 4},\n",
       "        {'val': 4, 'group': 4}, {'val': 4, 'group': 4},\n",
       "        {'val': 4, 'group': 4}, {'val': 4, 'group': 4}],\n",
       "       [{'val': 0, 'group': 9}, {'val': 0, 'group': 9},\n",
       "        {'val': 0, 'group': 9}, {'val': 2, 'group': 10},\n",
       "        {'val': 2, 'group': 10}, {'val': 5, 'group': 11},\n",
       "        {'val': 6, 'group': 12}, {'val': 6, 'group': 12},\n",
       "        {'val': 6, 'group': 12}, {'val': 4, 'group': 13},\n",
       "        {'val': 4, 'group': 13}, {'val': 2, 'group': 14},\n",
       "        {'val': 2, 'group': 14}, {'val': 4, 'group': 15},\n",
       "        {'val': 4, 'group': 15}, {'val': 6, 'group': 16},\n",
       "        {'val': 6, 'group': 16}, {'val': 6, 'group': 16},\n",
       "        {'val': 5, 'group': 17}, {'val': 2, 'group': 18},\n",
       "        {'val': 2, 'group': 18}, {'val': 0, 'group': 19},\n",
       "        {'val': 0, 'group': 19}, {'val': 0, 'group': 19}],\n",
       "       [{'val': 0, 'group': 9}, {'val': 0, 'group': 9},\n",
       "        {'val': 0, 'group': 9}, {'val': 2, 'group': 10},\n",
       "        {'val': 2, 'group': 10}, {'val': 5, 'group': 11},\n",
       "        {'val': 6, 'group': 12}, {'val': 6, 'group': 12},\n",
       "        {'val': 6, 'group': 12}, {'val': 4, 'group': 13},\n",
       "        {'val': 4, 'group': 13}, {'val': 2, 'group': 14},\n",
       "        {'val': 2, 'group': 14}, {'val': 4, 'group': 15},\n",
       "        {'val': 4, 'group': 15}, {'val': 6, 'group': 16},\n",
       "        {'val': 6, 'group': 16}, {'val': 6, 'group': 16},\n",
       "        {'val': 5, 'group': 17}, {'val': 2, 'group': 18},\n",
       "        {'val': 2, 'group': 18}, {'val': 0, 'group': 19},\n",
       "        {'val': 0, 'group': 19}, {'val': 0, 'group': 19}],\n",
       "       [{'val': 0, 'group': 9}, {'val': 0, 'group': 9},\n",
       "        {'val': 0, 'group': 9}, {'val': 2, 'group': 10},\n",
       "        {'val': 2, 'group': 10}, {'val': 5, 'group': 11},\n",
       "        {'val': 6, 'group': 12}, {'val': 6, 'group': 12},\n",
       "        {'val': 6, 'group': 12}, {'val': 4, 'group': 13},\n",
       "        {'val': 4, 'group': 13}, {'val': 2, 'group': 14},\n",
       "        {'val': 2, 'group': 14}, {'val': 4, 'group': 15},\n",
       "        {'val': 4, 'group': 15}, {'val': 6, 'group': 16},\n",
       "        {'val': 6, 'group': 16}, {'val': 6, 'group': 16},\n",
       "        {'val': 5, 'group': 17}, {'val': 2, 'group': 18},\n",
       "        {'val': 2, 'group': 18}, {'val': 0, 'group': 19},\n",
       "        {'val': 0, 'group': 19}, {'val': 0, 'group': 19}],\n",
       "       [{'val': 0, 'group': 9}, {'val': 0, 'group': 9},\n",
       "        {'val': 0, 'group': 9}, {'val': 2, 'group': 10},\n",
       "        {'val': 2, 'group': 10}, {'val': 5, 'group': 11},\n",
       "        {'val': 0, 'group': 20}, {'val': 0, 'group': 20},\n",
       "        {'val': 2, 'group': 21}, {'val': 2, 'group': 21},\n",
       "        {'val': 2, 'group': 21}, {'val': 0, 'group': 22},\n",
       "        {'val': 0, 'group': 22}, {'val': 2, 'group': 23},\n",
       "        {'val': 2, 'group': 23}, {'val': 2, 'group': 23},\n",
       "        {'val': 0, 'group': 24}, {'val': 0, 'group': 24},\n",
       "        {'val': 5, 'group': 17}, {'val': 2, 'group': 18},\n",
       "        {'val': 2, 'group': 18}, {'val': 0, 'group': 19},\n",
       "        {'val': 0, 'group': 19}, {'val': 0, 'group': 19}],\n",
       "       [{'val': 0, 'group': 9}, {'val': 0, 'group': 9},\n",
       "        {'val': 0, 'group': 9}, {'val': 2, 'group': 10},\n",
       "        {'val': 2, 'group': 10}, {'val': 5, 'group': 11},\n",
       "        {'val': 0, 'group': 20}, {'val': 0, 'group': 20},\n",
       "        {'val': 2, 'group': 21}, {'val': 2, 'group': 21},\n",
       "        {'val': 2, 'group': 21}, {'val': 0, 'group': 22},\n",
       "        {'val': 0, 'group': 22}, {'val': 2, 'group': 23},\n",
       "        {'val': 2, 'group': 23}, {'val': 2, 'group': 23},\n",
       "        {'val': 0, 'group': 24}, {'val': 0, 'group': 24},\n",
       "        {'val': 5, 'group': 17}, {'val': 2, 'group': 18},\n",
       "        {'val': 2, 'group': 18}, {'val': 0, 'group': 19},\n",
       "        {'val': 0, 'group': 19}, {'val': 0, 'group': 19}],\n",
       "       [{'val': 0, 'group': 9}, {'val': 0, 'group': 9},\n",
       "        {'val': 0, 'group': 9}, {'val': 2, 'group': 10},\n",
       "        {'val': 2, 'group': 10}, {'val': 5, 'group': 11},\n",
       "        {'val': 0, 'group': 20}, {'val': 0, 'group': 20},\n",
       "        {'val': 2, 'group': 21}, {'val': 2, 'group': 21},\n",
       "        {'val': 2, 'group': 21}, {'val': 0, 'group': 22},\n",
       "        {'val': 0, 'group': 22}, {'val': 2, 'group': 23},\n",
       "        {'val': 2, 'group': 23}, {'val': 2, 'group': 23},\n",
       "        {'val': 0, 'group': 24}, {'val': 0, 'group': 24},\n",
       "        {'val': 5, 'group': 17}, {'val': 2, 'group': 18},\n",
       "        {'val': 2, 'group': 18}, {'val': 0, 'group': 19},\n",
       "        {'val': 0, 'group': 19}, {'val': 0, 'group': 19}],\n",
       "       [{'val': 0, 'group': 9}, {'val': 0, 'group': 9},\n",
       "        {'val': 0, 'group': 9}, {'val': 2, 'group': 10},\n",
       "        {'val': 2, 'group': 10}, {'val': 5, 'group': 11},\n",
       "        {'val': 6, 'group': 25}, {'val': 6, 'group': 25},\n",
       "        {'val': 6, 'group': 25}, {'val': 4, 'group': 26},\n",
       "        {'val': 4, 'group': 26}, {'val': 2, 'group': 27},\n",
       "        {'val': 2, 'group': 27}, {'val': 4, 'group': 28},\n",
       "        {'val': 4, 'group': 28}, {'val': 6, 'group': 29},\n",
       "        {'val': 6, 'group': 29}, {'val': 6, 'group': 29},\n",
       "        {'val': 5, 'group': 17}, {'val': 2, 'group': 18},\n",
       "        {'val': 2, 'group': 18}, {'val': 0, 'group': 19},\n",
       "        {'val': 0, 'group': 19}, {'val': 0, 'group': 19}],\n",
       "       [{'val': 0, 'group': 9}, {'val': 0, 'group': 9},\n",
       "        {'val': 0, 'group': 9}, {'val': 2, 'group': 10},\n",
       "        {'val': 2, 'group': 10}, {'val': 5, 'group': 11},\n",
       "        {'val': 6, 'group': 25}, {'val': 6, 'group': 25},\n",
       "        {'val': 6, 'group': 25}, {'val': 4, 'group': 26},\n",
       "        {'val': 4, 'group': 26}, {'val': 2, 'group': 27},\n",
       "        {'val': 2, 'group': 27}, {'val': 4, 'group': 28},\n",
       "        {'val': 4, 'group': 28}, {'val': 6, 'group': 29},\n",
       "        {'val': 6, 'group': 29}, {'val': 6, 'group': 29},\n",
       "        {'val': 5, 'group': 17}, {'val': 2, 'group': 18},\n",
       "        {'val': 2, 'group': 18}, {'val': 0, 'group': 19},\n",
       "        {'val': 0, 'group': 19}, {'val': 0, 'group': 19}],\n",
       "       [{'val': 0, 'group': 9}, {'val': 0, 'group': 9},\n",
       "        {'val': 0, 'group': 9}, {'val': 2, 'group': 10},\n",
       "        {'val': 2, 'group': 10}, {'val': 5, 'group': 11},\n",
       "        {'val': 6, 'group': 25}, {'val': 6, 'group': 25},\n",
       "        {'val': 6, 'group': 25}, {'val': 4, 'group': 26},\n",
       "        {'val': 4, 'group': 26}, {'val': 2, 'group': 27},\n",
       "        {'val': 2, 'group': 27}, {'val': 4, 'group': 28},\n",
       "        {'val': 4, 'group': 28}, {'val': 6, 'group': 29},\n",
       "        {'val': 6, 'group': 29}, {'val': 6, 'group': 29},\n",
       "        {'val': 5, 'group': 17}, {'val': 2, 'group': 18},\n",
       "        {'val': 2, 'group': 18}, {'val': 0, 'group': 19},\n",
       "        {'val': 0, 'group': 19}, {'val': 0, 'group': 19}],\n",
       "       [{'val': 0, 'group': 9}, {'val': 0, 'group': 9},\n",
       "        {'val': 0, 'group': 9}, {'val': 2, 'group': 10},\n",
       "        {'val': 2, 'group': 10}, {'val': 5, 'group': 11},\n",
       "        {'val': 1, 'group': 30}, {'val': 1, 'group': 30},\n",
       "        {'val': 2, 'group': 31}, {'val': 2, 'group': 31},\n",
       "        {'val': 2, 'group': 31}, {'val': 4, 'group': 32},\n",
       "        {'val': 4, 'group': 32}, {'val': 2, 'group': 33},\n",
       "        {'val': 2, 'group': 33}, {'val': 2, 'group': 33},\n",
       "        {'val': 1, 'group': 34}, {'val': 1, 'group': 34},\n",
       "        {'val': 5, 'group': 17}, {'val': 2, 'group': 18},\n",
       "        {'val': 2, 'group': 18}, {'val': 0, 'group': 19},\n",
       "        {'val': 0, 'group': 19}, {'val': 0, 'group': 19}],\n",
       "       [{'val': 0, 'group': 9}, {'val': 0, 'group': 9},\n",
       "        {'val': 0, 'group': 9}, {'val': 2, 'group': 10},\n",
       "        {'val': 2, 'group': 10}, {'val': 5, 'group': 11},\n",
       "        {'val': 1, 'group': 30}, {'val': 1, 'group': 30},\n",
       "        {'val': 2, 'group': 31}, {'val': 2, 'group': 31},\n",
       "        {'val': 2, 'group': 31}, {'val': 4, 'group': 32},\n",
       "        {'val': 4, 'group': 32}, {'val': 2, 'group': 33},\n",
       "        {'val': 2, 'group': 33}, {'val': 2, 'group': 33},\n",
       "        {'val': 1, 'group': 34}, {'val': 1, 'group': 34},\n",
       "        {'val': 5, 'group': 17}, {'val': 2, 'group': 18},\n",
       "        {'val': 2, 'group': 18}, {'val': 0, 'group': 19},\n",
       "        {'val': 0, 'group': 19}, {'val': 0, 'group': 19}],\n",
       "       [{'val': 4, 'group': 35}, {'val': 4, 'group': 35},\n",
       "        {'val': 4, 'group': 35}, {'val': 4, 'group': 35},\n",
       "        {'val': 4, 'group': 35}, {'val': 4, 'group': 35},\n",
       "        {'val': 1, 'group': 30}, {'val': 1, 'group': 30},\n",
       "        {'val': 2, 'group': 31}, {'val': 2, 'group': 31},\n",
       "        {'val': 2, 'group': 31}, {'val': 4, 'group': 32},\n",
       "        {'val': 4, 'group': 32}, {'val': 2, 'group': 33},\n",
       "        {'val': 2, 'group': 33}, {'val': 2, 'group': 33},\n",
       "        {'val': 1, 'group': 34}, {'val': 1, 'group': 34},\n",
       "        {'val': 4, 'group': 36}, {'val': 4, 'group': 36},\n",
       "        {'val': 4, 'group': 36}, {'val': 4, 'group': 36},\n",
       "        {'val': 4, 'group': 36}, {'val': 4, 'group': 36}],\n",
       "       [{'val': 4, 'group': 35}, {'val': 4, 'group': 35},\n",
       "        {'val': 4, 'group': 35}, {'val': 4, 'group': 35},\n",
       "        {'val': 4, 'group': 35}, {'val': 4, 'group': 35},\n",
       "        {'val': 1, 'group': 30}, {'val': 1, 'group': 30},\n",
       "        {'val': 6, 'group': 37}, {'val': 6, 'group': 37},\n",
       "        {'val': 6, 'group': 37}, {'val': 6, 'group': 37},\n",
       "        {'val': 6, 'group': 37}, {'val': 6, 'group': 37},\n",
       "        {'val': 6, 'group': 37}, {'val': 6, 'group': 37},\n",
       "        {'val': 1, 'group': 34}, {'val': 1, 'group': 34},\n",
       "        {'val': 4, 'group': 36}, {'val': 4, 'group': 36},\n",
       "        {'val': 4, 'group': 36}, {'val': 4, 'group': 36},\n",
       "        {'val': 4, 'group': 36}, {'val': 4, 'group': 36}],\n",
       "       [{'val': 4, 'group': 35}, {'val': 4, 'group': 35},\n",
       "        {'val': 4, 'group': 35}, {'val': 4, 'group': 35},\n",
       "        {'val': 4, 'group': 35}, {'val': 4, 'group': 35},\n",
       "        {'val': 1, 'group': 30}, {'val': 1, 'group': 30},\n",
       "        {'val': 6, 'group': 37}, {'val': 6, 'group': 37},\n",
       "        {'val': 6, 'group': 37}, {'val': 6, 'group': 37},\n",
       "        {'val': 6, 'group': 37}, {'val': 6, 'group': 37},\n",
       "        {'val': 6, 'group': 37}, {'val': 6, 'group': 37},\n",
       "        {'val': 1, 'group': 34}, {'val': 1, 'group': 34},\n",
       "        {'val': 4, 'group': 36}, {'val': 4, 'group': 36},\n",
       "        {'val': 4, 'group': 36}, {'val': 4, 'group': 36},\n",
       "        {'val': 4, 'group': 36}, {'val': 4, 'group': 36}],\n",
       "       [{'val': 4, 'group': 35}, {'val': 4, 'group': 35},\n",
       "        {'val': 4, 'group': 35}, {'val': 4, 'group': 35},\n",
       "        {'val': 4, 'group': 35}, {'val': 4, 'group': 35},\n",
       "        {'val': 1, 'group': 30}, {'val': 1, 'group': 30},\n",
       "        {'val': 4, 'group': 38}, {'val': 4, 'group': 38},\n",
       "        {'val': 4, 'group': 38}, {'val': 4, 'group': 38},\n",
       "        {'val': 4, 'group': 38}, {'val': 4, 'group': 38},\n",
       "        {'val': 4, 'group': 38}, {'val': 4, 'group': 38},\n",
       "        {'val': 1, 'group': 34}, {'val': 1, 'group': 34},\n",
       "        {'val': 4, 'group': 36}, {'val': 4, 'group': 36},\n",
       "        {'val': 4, 'group': 36}, {'val': 4, 'group': 36},\n",
       "        {'val': 4, 'group': 36}, {'val': 4, 'group': 36}],\n",
       "       [{'val': 4, 'group': 35}, {'val': 4, 'group': 35},\n",
       "        {'val': 4, 'group': 35}, {'val': 4, 'group': 35},\n",
       "        {'val': 4, 'group': 35}, {'val': 4, 'group': 35},\n",
       "        {'val': 1, 'group': 30}, {'val': 1, 'group': 30},\n",
       "        {'val': 4, 'group': 38}, {'val': 4, 'group': 38},\n",
       "        {'val': 4, 'group': 38}, {'val': 4, 'group': 38},\n",
       "        {'val': 4, 'group': 38}, {'val': 4, 'group': 38},\n",
       "        {'val': 4, 'group': 38}, {'val': 4, 'group': 38},\n",
       "        {'val': 1, 'group': 34}, {'val': 1, 'group': 34},\n",
       "        {'val': 4, 'group': 36}, {'val': 4, 'group': 36},\n",
       "        {'val': 4, 'group': 36}, {'val': 4, 'group': 36},\n",
       "        {'val': 4, 'group': 36}, {'val': 4, 'group': 36}],\n",
       "       [{'val': 4, 'group': 35}, {'val': 4, 'group': 35},\n",
       "        {'val': 4, 'group': 35}, {'val': 4, 'group': 35},\n",
       "        {'val': 4, 'group': 35}, {'val': 4, 'group': 35},\n",
       "        {'val': 1, 'group': 30}, {'val': 1, 'group': 30},\n",
       "        {'val': 4, 'group': 38}, {'val': 4, 'group': 38},\n",
       "        {'val': 4, 'group': 38}, {'val': 4, 'group': 38},\n",
       "        {'val': 4, 'group': 38}, {'val': 4, 'group': 38},\n",
       "        {'val': 4, 'group': 38}, {'val': 4, 'group': 38},\n",
       "        {'val': 1, 'group': 34}, {'val': 1, 'group': 34},\n",
       "        {'val': 4, 'group': 36}, {'val': 4, 'group': 36},\n",
       "        {'val': 4, 'group': 36}, {'val': 4, 'group': 36},\n",
       "        {'val': 4, 'group': 36}, {'val': 4, 'group': 36}]], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from mltool.visualization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype object cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-2470c7245a85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2876\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2877\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2878\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m   2879\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2880\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5587\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5589\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5590\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5591\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[1;32m    700\u001b[0m             raise TypeError(\"Image data of dtype {} cannot be converted to \"\n\u001b[0;32m--> 701\u001b[0;31m                             \"float\".format(self._A.dtype))\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(np.array(matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tensornetwork_base import TN_Base\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opt_einsum as oe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     88
    ]
   },
   "outputs": [],
   "source": [
    "class PEPS_einsum_arbitrary_partition_optim(TN_Base):\n",
    "    def __init__(self,out_features=10,in_physics_bond = 2, virtual_bond_dim=\"models/arbitary_shape/arbitary_shape_1.json\",\n",
    "                       bias=True,label_position='center',contraction_mode = 'recursion',\n",
    "                 init_std=1e-10,\n",
    "                 seted_variation=10,\n",
    "                 solved_std=None):\n",
    "        super().__init__()\n",
    "        if isinstance(virtual_bond_dim,str):\n",
    "            arbitary_shape_state_dict = torch.load(virtual_bond_dim)\n",
    "        else:\n",
    "            arbitary_shape_state_dict = virtual_bond_dim\n",
    "        assert isinstance(arbitary_shape_state_dict,dict)\n",
    "        \n",
    "        \n",
    "        info_per_group = arbitary_shape_state_dict['node']\n",
    "        info_per_line  = arbitary_shape_state_dict['line']\n",
    "        info_per_point = arbitary_shape_state_dict['element']\n",
    "        \n",
    "        if solved_std is None:\n",
    "            num_of_tensor   = len(info_per_group)\n",
    "            list_of_virt_dim= [t['D'] for t in info_per_line.values()]\n",
    "            list_of_phys_dim= [len(t['element']) for t in info_per_group.values()]\n",
    "            divider         = np.prod([np.power(t,1/num_of_tensor) for t in list_of_phys_dim+list_of_virt_dim])\n",
    "            solved_var      = np.power(seted_variation,1/num_of_tensor)/divider\n",
    "            solved_std      = np.sqrt(solved_var)\n",
    "        \n",
    "        \n",
    "        center_group    = 0\n",
    "        damgling_num    = len(info_per_group)\n",
    "        info_per_group[center_group]['neighbor'].insert(0,damgling_num)\n",
    "        info_per_line[(center_group,damgling_num)]={'D': out_features}\n",
    "\n",
    "        self.info_per_group=info_per_group\n",
    "        self.info_per_line =info_per_line\n",
    "        self.info_per_point=info_per_point\n",
    "\n",
    "        operands = []\n",
    "        sublist_list=[]\n",
    "        outlist  = [list(info_per_line.keys()).index((center_group,damgling_num))]\n",
    "        ranks_list=[]\n",
    "        for group_now in range(len(info_per_group)):\n",
    "            group_info= info_per_group[group_now]\n",
    "            neighbors = group_info['neighbor']\n",
    "            ranks = []\n",
    "            sublist=[]\n",
    "            for neighbor_id in neighbors:\n",
    "                line_tuple = [group_now,neighbor_id]\n",
    "                line_tuple.sort()\n",
    "                line_tuple= tuple(line_tuple)\n",
    "                D = int(info_per_line[line_tuple]['D'])\n",
    "                idx = list(info_per_line.keys()).index(line_tuple)\n",
    "                ranks.append(D)\n",
    "                sublist.append(idx)\n",
    "            tensor = np.random.randn(*ranks)\n",
    "            operands+=[tensor,[*sublist]]\n",
    "\n",
    "            ranks_list.append(ranks)\n",
    "            sublist_list.append(sublist)\n",
    "        operands+= [[...,*outlist]]\n",
    "        path,info = oe.contract_path(*operands,optimize='random-greedy-128')\n",
    "        self.path         = path\n",
    "        self.sublist_list = sublist_list\n",
    "        self.outlist      = outlist\n",
    "    \n",
    "        # assume all element for the tensornetwork is indenpendent. \n",
    "        # The bond (include physics) list is l0,l1,l2,...,ln\n",
    "        # All element follow normal distribution X - sigma(0,alpha)\n",
    "        # where alpha is the variation we need to calculated.\n",
    "        # the output after contracting is also a tensor (may 1-rank scalar, 2-rank matrix, etc)\n",
    "        # the element of the output follow the composite normal distribution Y - sigma(0,beta)\n",
    "        # where beta = l0 x l1 x l2 x ... x ln x alpha^(# of tensor)\n",
    "        \n",
    "        unit_list = []\n",
    "        for i in range(len(sublist_list)):\n",
    "            shape = ranks_list[i]\n",
    "            P        = len(info_per_group[i]['element'])\n",
    "            #control_mat = self.rde2D((P,*shape),0,physics_index=0,offset= 2 if i==center_group else 1)\n",
    "            #bias_mat    = torch.normal(0,solved_std,(P,*shape))\n",
    "            #bias_mat[control_mat.nonzero(as_tuple=True)]=0                           \n",
    "            #unit_list.append(control_mat+bias_mat)\n",
    "            #unit_list.append(self.rde2D((P,*shape),init_std,offset=1))\n",
    "            unit_list.append(torch.normal(mean=0,std=solved_std,size=(P,*shape)))\n",
    "        assert len(unit_list)==len(sublist_list)\n",
    "\n",
    "        self.unit_list = [nn.Parameter(v) for v in unit_list]\n",
    "        for i, v in enumerate(self.unit_list):\n",
    "            self.register_parameter(f'unit_{i}', param=v)\n",
    "\n",
    "    def forward(self,input_data):\n",
    "        #input data shape B,1,W,H\n",
    "        assert len(input_data.shape)==4\n",
    "        input_data  = input_data.flatten(-3,-1)\n",
    "\n",
    "        _input = []\n",
    "        for i,unit in enumerate(self.unit_list):\n",
    "            patch_idx  = self.info_per_group[i]['element_idx']\n",
    "            batch_input= input_data[...,patch_idx] # B,P\n",
    "            batch_unit = torch.tensordot(batch_input,unit,dims=([-1], [0]))\n",
    "            #print(f\"{batch_input.norm()}-{unit.norm()}->{batch_unit.norm()}\")\n",
    "            _input.append(batch_unit)\n",
    "\n",
    "        operands=[]\n",
    "        for tensor,sublist in zip(_input,self.sublist_list):\n",
    "            operand = [tensor,[...,*sublist]]\n",
    "            operands+=operand\n",
    "        operands+= [[...,*self.outlist]]\n",
    "        return self.einsum_engine(*operands,optimize=self.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d9ddc21e31df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "a=torch.randn(10,6,6,16)\n",
    "model(a).norm().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Deep model (with nonlienar layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from models.tensornetwork_base import TN_Base\n",
    "import torch.nn as nn\n",
    "from models.model_utils import *\n",
    "from models.two_dim_model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###### the random set for tensornetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#         num_of_edge     = (W-1)*H+(H-1)*W\n",
    "#         num_of_unit     = W*H\n",
    "#         solved_var      = np.power(set_var,1/num_of_unit)*np.power(1/virtual_bond_dim,num_of_edge/(num_of_unit))/in_physics_bond\n",
    "#         solved_std      = np.sqrt(solved_var)\n",
    "#         print(solved_std)\n",
    "#         random_engine   = lambda shape:torch.normal(0,solved_std,shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "W=H=10\n",
    "LW = W//2\n",
    "LH = H//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "index_matrix = torch.LongTensor([[[i,j] for j in range(W)] for i in range(H)])\n",
    "bulk_index,edge_index,corn_index=PEPS_uniform_shape_symmetry_base.flatten_image_input(index_matrix)\n",
    "\n",
    "flag_matrix = torch.zeros(W,H).long()\n",
    "position_matrix = torch.zeros(W,H).long()\n",
    "\n",
    "for n,(i,j) in enumerate(corn_index.numpy()):\n",
    "    flag_matrix[i,j]=0\n",
    "    position_matrix[i,j]=n\n",
    "for n,(i,j) in enumerate(edge_index.numpy()):\n",
    "    flag_matrix[i,j]=1\n",
    "    position_matrix[i,j]=n\n",
    "for n,(i,j) in enumerate(bulk_index.numpy()):\n",
    "    flag_matrix[i,j]=2\n",
    "    position_matrix[i,j]=n\n",
    "\n",
    "flag_matrix     = flag_matrix\n",
    "position_matrix = position_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "O=2;D=3;B=5\n",
    "corn_tensors = torch.randn(4,B,O,D,D)\n",
    "edge_tensors = torch.randn(2*(W-2)+2*(H-2),B,D,D,D)\n",
    "bulk_tensors = torch.randn((W-2)*(H-2),B,D,D,D,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "point_x = [0,0,1,1]\n",
    "point_y = [0,1,1,0]\n",
    "p       = part_idex[point_x,point_y]#(L,4,2)\n",
    "indexrule=position_matrix[p[...,0],p[...,1]]\n",
    "partrule =flag_matrix[p[...,0],p[...,1]][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "L=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "point_x = [j for j in range(L)]\n",
    "point_y = [L for j in range(L)]\n",
    "p       = part_idex[point_x,point_y]#(L,4,2)\n",
    "indexrule=position_matrix[p[...,0],p[...,1]]\n",
    "partrule =flag_matrix[p[...,0],p[...,1]][:,0]\n",
    "should = PEPS_uniform_shape_symmetry_base.pick_tensors(partrule,indexrule,corn_tensors,edge_tensors,bulk_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class PEPS_uniform_shape_symmetry_deep_model(PEPS_uniform_shape_symmetry_base):\n",
    "    def __init__(self, nonlinear_layer=nn.Tanh(),\n",
    "                       normlized_layer_module=nn.InstanceNorm3d,\n",
    "                       init_std=1e-10,set_var=1,**kargs):\n",
    "        super().__init__(**kargs)\n",
    "        H = self.H\n",
    "        W = self.W\n",
    "        LW= self.LW\n",
    "        LH= self.LH\n",
    "        D = self.D\n",
    "        O = self.O\n",
    "        P = self.P\n",
    "        num_of_edge     = (W-1)*H+(H-1)*W\n",
    "        num_of_unit     = W*H\n",
    "        solved_var      = np.power(set_var,1/num_of_unit)*np.power(1/D,num_of_edge/(num_of_unit))/P\n",
    "        solved_std      = np.sqrt(solved_var)\n",
    "        print(solved_std)\n",
    "        random_engine   = lambda shape:torch.normal(0,solved_std,shape)\n",
    "        self.corn_tensors = torch.nn.init.normal_(self.corn_tensors,mean=0.0, std=solved_std)\n",
    "        self.edge_tensors = torch.nn.init.normal_(self.edge_tensors,mean=0.0, std=solved_std)\n",
    "        self.bulk_tensors = torch.nn.init.normal_(self.bulk_tensors,mean=0.0, std=solved_std)\n",
    "        \n",
    "        flag_matrix     = self.flag_matrix\n",
    "        position_matrix = self.position_matrix\n",
    "        index_matrix    = self.index_matrix\n",
    "        part_lu_idex = torch.rot90(index_matrix,k=0)[:LW,:LH]\n",
    "        part_ru_idex = torch.rot90(index_matrix,k=1)[:LW,:LH]\n",
    "        part_rd_idex = torch.rot90(index_matrix,k=2)[:LW,:LH]\n",
    "        part_ld_idex = torch.rot90(index_matrix,k=3)[:LW,:LH]\n",
    "        part_idex = torch.stack([part_lu_idex,\n",
    "                                 part_ru_idex,\n",
    "                                 part_rd_idex,\n",
    "                                 part_ld_idex],-2)\n",
    "        \n",
    "        indexrules = []\n",
    "        partrules  = []\n",
    "        point_x = [0,0,1,1]\n",
    "        point_y = [0,1,1,0]\n",
    "        p       = part_idex[point_x,point_y]#(L,4,2)\n",
    "        indexrule=position_matrix[p[...,0],p[...,1]]\n",
    "        partrule =flag_matrix[p[...,0],p[...,1]][:,0]\n",
    "\n",
    "        indexrules.append(indexrule)\n",
    "        partrules.append(partrule)\n",
    "        edge_contraction_path=[]\n",
    "        for L in range(2,LW):\n",
    "            indexrule={}\n",
    "            partrule={}\n",
    "            tn2D_shape_list = [[(D,D,D)]+[(D,D,D,D)]*(L-1)]\n",
    "            path,sublist_list,outlist = get_best_path(tn2D_shape_list,store=path_recorder,type='sub')\n",
    "            edge_contraction_path.append([path,sublist_list,outlist])\n",
    "            point_x = [[j for j in range(L)],[L for j in range(L)]]\n",
    "            point_y = [[L for j in range(L)],[j for j in range(L)]]\n",
    "            p       = part_idex[point_x,point_y]#(2,L,4,2)\n",
    "            indexrule['edge']= position_matrix[p[...,0],p[...,1]].transpose(0,1)\n",
    "            partrule['edge'] = flag_matrix[p[...,0],p[...,1]][0][:,0]\n",
    "            \n",
    "            point_x = [L]\n",
    "            point_y = [L]\n",
    "            p       = part_idex[point_x,point_y]#(L,4,2)\n",
    "            \n",
    "            indexrule['cent']= position_matrix[p[...,0],p[...,1]]\n",
    "            partrule['cent'] = flag_matrix[p[...,0],p[...,1]][:,0]\n",
    "            \n",
    "            indexrules.append(indexrule)\n",
    "            partrules.append(partrule)\n",
    "        self.indexrules = indexrules\n",
    "        self.partrules  = partrules\n",
    "        self.edge_contraction_path = edge_contraction_path\n",
    "        self.nonlinear_layer = nonlinear_layer\n",
    "        self.normlized_layers = nn.ModuleList([normlized_layer_module(O,affine=True) for _ in self.partrules])\n",
    "        \n",
    "    def forward(self,input_data):\n",
    "        LH = self.LH\n",
    "        LW = self.LW\n",
    "        D  = self.D\n",
    "        bulk_tensors,edge_tensors,corn_tensors = self.get_batch_contraction_network(input_data)\n",
    "        corn_tensors = self.pick_tensors(self.partrules[0],self.indexrules[0],corn_tensors,edge_tensors,bulk_tensors)\n",
    "        corn = self.einsum_engine(\"lkoab,lkcdb,lkefcg,lkgah->lkohedf\",*corn_tensors).flatten(-4,-3).flatten(-2,-1)\n",
    "        corn = self.nonlinear_layer(corn)# (4,B,O,D,D)\n",
    "        corn = self.normlized_layers[0](corn.permute(1,2,0,3,4)).permute(2,0,1,3,4)\n",
    "        #corn = corn/D**2\n",
    "        for i,(partrule, indexrule) in enumerate(zip(self.partrules[1:],self.indexrules[1:])):\n",
    "            path,sublist_list,outlist = self.edge_contraction_path[i]\n",
    "            edge_tensors= self.pick_tensors(partrule['edge'],indexrule['edge'],corn_tensors,edge_tensors,bulk_tensors)\n",
    "            cent_tensor = self.pick_tensors(partrule['cent'],indexrule['cent'],corn_tensors,edge_tensors,bulk_tensors)[0]\n",
    "            L           = len(edge_tensors)\n",
    "            operands    = structure_operands(edge_tensors,sublist_list,outlist)\n",
    "            edge1,edge2 = self.einsum_engine(*operands,optimize=path).flatten(-L-L,-L-1).flatten(-L,-1)\n",
    "            corn = self.einsum_engine(\"lkoab,lkcdb,lkefcg,lkgah->lkohedf\",corn ,edge1,cent_tensor,edge2).flatten(-4,-3).flatten(-2,-1)\n",
    "            corn = self.nonlinear_layer(corn)\n",
    "            corn = self.normlized_layers[i+1](corn.permute(1,2,0,3,4)).permute(2,0,1,3,4)\n",
    "            #corn = corn/D**(L+1)\n",
    "        # corn now is a tensor (B,4,D^(L/2),D^(L/2))\n",
    "        corn   = corn/D**(LW/3)\n",
    "        corn   = self.einsum_engine(\"kvab,kxbc,kycd,kzda->kvxyz\",*corn).flatten(-4,-1)# -> (B,O^4)\n",
    "        \n",
    "        return corn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06538302430059152\n"
     ]
    }
   ],
   "source": [
    "model = PEPS_uniform_shape_symmetry_deep_model(W=6,H=6,virtual_bond_dim=5,in_physics_bond=16,\n",
    "                                               nonlinear_layer=nn.Identity(),\n",
    "                                               normlized_layer_module=nn.Identity)\n",
    "#model.weight_init(method=\"Expecatation_Normalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.9999), tensor(-0.0018))\n",
      "(tensor(0.0016), tensor(-3.4246e-05))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x=torch.normal(mean=0,std=1,size=(1000,6,6,16));print(torch.std_mean(x))\n",
    "    x=model(x);print(torch.std_mean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Contractor Test perodic condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D=4;L=H=W=5;B=10;\n",
    "tn2D_shape_list = [[(D,D)]+[(D,D,D)]*(H-1)]+[[(D,D,D)]+[(D,D,D,D)]*(H-1)]*(W-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path,sublist_list,outlist = get_best_path(tn2D_shape_list,store=path_recorder,type='sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tensornetwork as tn\n",
    "import opt_einsum as oe\n",
    "import os,json\n",
    "from tensornetwork.network_components import get_all_nondangling,get_all_dangling\n",
    "from tensornetwork.contractors.opt_einsum_paths.utils import get_subgraph_dangling,get_all_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equation   = \"kab,kcdb,kefcg,kgha->khedf\"\n",
    "tensor_l   = [torch.randn(B,D,D) ,torch.randn(B,D,D,D),torch.randn(B,D,D,D,D),torch.randn(B,D,D,D)]\n",
    "oe.contract_path(equation, *tensor_l)[0]\n",
    "path = oe.contract_path(equation, *tensor_l)[0]\n",
    "oe.contract(equation,*tensor_l,optimize=path).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rd_engine(*x,**kargs):\n",
    "    x =  torch.randn(*x,device='cpu',**kargs)\n",
    "    x/=  torch.norm(x).sqrt()\n",
    "    x =  torch.autograd.Variable(x,requires_grad=True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path_recorder={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from models.model_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tn2D_shape_list = [[(D,D)]+[(D,D,D)]*(H-1)]+[[(D,D,D)]+[(D,D,D,D)]*(H-1)]*(W-1)\n",
    "path,sublist_list,outlist = get_best_path(tn2D_shape_list,store=path_recorder,type='sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tensor_list     = [rd_engine(B,*l) for t in tn2D_shape_list for l in t]\n",
    "operands=[]\n",
    "for tensor,sublist in zip(tensor_list,sublist_list):\n",
    "    operand = [tensor,[...,*sublist]]\n",
    "    operands+=operand\n",
    "operands+= [[...,*outlist]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oe.contract(*operands,optimize=path).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### test_the_TRG_on_even_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Contractor2D/test_the_TRG_on_even_number.py\n"
     ]
    }
   ],
   "source": [
    "# #%%writefile Contractor2D/test_the_TRG_on_even_number.py\n",
    "# import torch\n",
    "# from Contractor2D.utils import apply_SVD\n",
    "\n",
    "# tensor = torch.randn(4,4,2,2,2,2)\n",
    "\n",
    "# print(uniform_shape_tensor_contractor_tn(tensor))\n",
    "\n",
    "# truncate= None\n",
    "# lu_tensor = tensor[0::2,0::2]\n",
    "# ld_tensor = tensor[0::2,1::2]\n",
    "# ru_tensor = tensor[1::2,0::2]\n",
    "# rd_tensor = tensor[1::2,1::2]\n",
    "# lu_lu,lu_rd = apply_SVD(lu_tensor,left_bond=[0,1],right_bond=[2,3],truncate=truncate)# abk ,kcd\n",
    "# rd_lu,rd_rd = apply_SVD(rd_tensor,left_bond=[0,1],right_bond=[2,3],truncate=truncate)# abk, kcd\n",
    "# ld_ld,ld_ru = apply_SVD(ld_tensor,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# bck, kda\n",
    "# ru_ld,ru_ru = apply_SVD(ru_tensor,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# bck, kda\n",
    "# tensor1     = torch.einsum(\"whicd,whjac,whbak,whdbl->whijkl\",\n",
    "#                             lu_rd,\n",
    "#                             ld_ru,\n",
    "#                             rd_lu,\n",
    "#                             ru_ld)\n",
    "# tensor2     = torch.einsum(\"whicd,whjac,whbak,whdbl->whijkl\",\n",
    "#                            rd_rd,\n",
    "#                            ru_ru.roll(-1,1),\n",
    "#                            lu_lu.roll(shifts=(-1, -1), dims=(0, 1)),\n",
    "#                            ld_ld.roll(-1,0))\n",
    "\n",
    "# print(tensor1_and_tensor2_contractor_tn(tensor1,tensor2))\n",
    "\n",
    "# #print(torch.einsum(\"abcd,cdab->\",tensor1[0,0],tensor2[0,0]))\n",
    "# left,right  = apply_SVD(tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)# ABK,KCD\n",
    "# lower,uppe  = apply_SVD(tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "# # new_tensor  = torch.einsum(\"whicd,whjac,whbak,whdbl->whijkl\",\n",
    "# #                            right,\n",
    "# #                            uppe,\n",
    "# #                            left.roll(shifts=-1,dims=0),\n",
    "# #                            lower.roll(shifts=1,dims=1))\n",
    "# new_tensor  = torch.einsum(\"whadi,whjba,whkcb,whdcl->whijkl\",\n",
    "#                            lower,\n",
    "#                            right.roll(-1,1),\n",
    "#                            uppe.roll(-1,1),\n",
    "#                            left.roll(shifts=(-1, -1), dims=(0, 1))\n",
    "#                            )\n",
    "# print(uniform_shape_tensor_contractor_tn(new_tensor))\n",
    "\n",
    "# torch.einsum(\"abn,nji,lkh,hdc,caw,wkj,ilm,mbd->\",\n",
    "#              lu_lu[0,0],lu_rd[0,0],\n",
    "#              rd_lu[0,0],rd_rd[0,0],\n",
    "#              ld_ld[0,0],ld_ru[0,0],\n",
    "#              ru_ld[0,0],ru_ru[0,0])\n",
    "\n",
    "# torch.einsum(\"abji,lkdc,jcak,dilb->\",\n",
    "#              torch.einsum(\"abn,nji->abji\",lu_lu[0,0],lu_rd[0,0]),\n",
    "#              torch.einsum(\"lkh,hdc->lkdc\",rd_lu[0,0],rd_rd[0,0]),\n",
    "#              torch.einsum(\"caw,wkj->jcak\",ld_ld[0,0],ld_ru[0,0]),\n",
    "#              torch.einsum(\"ilm,mbd->dilb\",ru_ld[0,0],ru_ru[0,0]))\n",
    "\n",
    "# torch.dist(torch.einsum(\"abn,nji->abji\",lu_lu[0,0],lu_rd[0,0]),lu_tensor)\n",
    "\n",
    "# torch.dist(torch.einsum(\"lkh,hdc->lkdc\",rd_lu[0,0],rd_rd[0,0]),rd_tensor)\n",
    "\n",
    "# torch.dist(torch.einsum(\"caw,wkj->jcak\",ld_ld[0,0],ld_ru[0,0]),ld_tensor)\n",
    "\n",
    "# torch.dist(torch.einsum(\"ilm,mbd->dilb\",ru_ld[0,0],ru_ru[0,0]),ru_tensor)\n",
    "\n",
    "# torch.dist(lu_tensor[0,0],tensor[0,0])\n",
    "\n",
    "# torch.dist(rd_tensor[0,0],tensor[1,1])\n",
    "\n",
    "# torch.dist(ld_tensor[0,0],tensor[0,1])\n",
    "\n",
    "# torch.dist(ru_tensor[0,0],tensor[1,0])\n",
    "\n",
    "# torch.einsum(\"abji,lkdc,jcak,dilb->\",\n",
    "#              torch.einsum(\"abn,nji->abji\",lu_lu[0,0],lu_rd[0,0]),\n",
    "#              torch.einsum(\"lkh,hdc->lkdc\",rd_lu[0,0],rd_rd[0,0]),\n",
    "#              torch.einsum(\"caw,wkj->jcak\",ld_ld[0,0],ld_ru[0,0]),\n",
    "#              torch.einsum(\"ilm,mbd->dilb\",ru_ld[0,0],ru_ru[0,0]))\n",
    "\n",
    "# torch.einsum(\"abcd,idjb,ckal,jlik->\",lu_tensor[0,0],ld_tensor[0,0],ru_tensor[0,0],rd_tensor[0,0])\n",
    "\n",
    "# torch.einsum(\"abcd,ciaj,ldkb,kjli->\",lu_tensor[0,0],ld_tensor[0,0],ru_tensor[0,0],rd_tensor[0,0])\n",
    "\n",
    "# tensor1 = tensor[0,0]\n",
    "# tensor2 = tensor[0,1]\n",
    "# tensor3 = tensor[1,0]\n",
    "# tensor4 = tensor[1,1]\n",
    "# torch.einsum(\"abcd,idjb,ckal,jlik->\",tensor1,tensor2,tensor3,tensor4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### check_the_brdc_coding_on_even_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Contractor2D/check_the_brdc_coding_on_even_number.py\n"
     ]
    }
   ],
   "source": [
    "# #%%writefile Contractor2D/check_the_brdc_coding_on_even_number.py\n",
    "# import torch\n",
    "# from Contractor2D.utils import apply_SVD\n",
    "\n",
    "# tensor     = torch.randn(8,8,2,2,2,2)/2\n",
    "# uniform_shape_tensor_contractor_tn(tensor)\n",
    "\n",
    "# lu_lu_origin,lu_rd_origin = apply_SVD(tensor[0::2,0::2],left_bond=[0,1],right_bond=[2,3],truncate=None)# abk ,kcd\n",
    "# rd_lu_origin,rd_rd_origin = apply_SVD(tensor[1::2,1::2],left_bond=[0,1],right_bond=[2,3],truncate=None)# abk, kcd\n",
    "# ld_ld_origin,ld_ru_origin = apply_SVD(tensor[0::2,1::2],left_bond=[1,2],right_bond=[3,0],truncate=None)# bck, kda\n",
    "# ru_ld_origin,ru_ru_origin = apply_SVD(tensor[1::2,0::2],left_bond=[1,2],right_bond=[3,0],truncate=None)# bck, kda\n",
    "\n",
    "# lu_lu,lu_rd = apply_SVD(bulk_tensor[0::2,0::2],left_bond=[0,1],right_bond=[2,3],truncate=None)# abk ,kcd\n",
    "# rd_lu,rd_rd = apply_SVD(bulk_tensor[1::2,1::2],left_bond=[0,1],right_bond=[2,3],truncate=None)# abk, kcd\n",
    "# ld_ld,ld_ru = apply_SVD(bulk_tensor[0::2,1::2],left_bond=[1,2],right_bond=[3,0],truncate=None)# bck, kda\n",
    "# ru_ld,ru_ru = apply_SVD(bulk_tensor[1::2,0::2],left_bond=[1,2],right_bond=[3,0],truncate=None)# bck, kda\n",
    "\n",
    "# print(lu_lu.shape)\n",
    "# print(rd_lu.shape)\n",
    "# print(ld_ld.shape)\n",
    "# print(ru_ld.shape)\n",
    "\n",
    "# lu_lu_should = lu_lu_origin[:,:]    ;lu_rd_should =lu_rd_origin[:,:]\n",
    "# rd_lu_should = rd_lu_origin[:-1,:-1];rd_rd_should =rd_rd_origin[:-1,:-1]\n",
    "# ld_ld_should = ld_ld_origin[:,:-1]  ;ld_ru_should =ld_ru_origin[:,:-1]\n",
    "# ru_ld_should = ru_ld_origin[:-1,:]  ;ru_ru_should =ru_ru_origin[:-1,:]\n",
    "\n",
    "# print(lu_lu_should.shape)\n",
    "# print(rd_lu_should.shape)\n",
    "# print(ld_ld_should.shape)\n",
    "# print(ru_ld_should.shape)\n",
    "\n",
    "# print(torch.dist(lu_lu_should,lu_lu),torch.dist(lu_rd_should,lu_rd))\n",
    "# print(torch.dist(rd_lu_should,rd_lu),torch.dist(rd_rd_should,rd_rd))\n",
    "# print(torch.dist(ld_ld_should,ld_ld),torch.dist(ld_ru_should,ld_ru))\n",
    "# print(torch.dist(ru_ld_should,ru_ld),torch.dist(ru_ru_should,ru_ru))\n",
    "\n",
    "# # right_edge == bulk_tensor[-1]\n",
    "# # down_edge  == bulk_tensor[:,-1]\n",
    "\n",
    "# rd_lu_r,rd_rd_r = apply_SVD(right_edge[1::2],left_bond=[0,1],right_bond=[2,3],truncate=None)# abk, kcd\n",
    "# ru_ld_r,ru_ru_r = apply_SVD(right_edge[0::2],left_bond=[1,2],right_bond=[3,0],truncate=None)# bck, kda\n",
    "# rd_lu_d,rd_rd_d = apply_SVD( down_edge[1::2],left_bond=[0,1],right_bond=[2,3],truncate=None)# abk, kcd\n",
    "# ld_ld_d,ld_ru_d = apply_SVD( down_edge[0::2],left_bond=[1,2],right_bond=[3,0],truncate=None)# bck, kda\n",
    "# rd_lu_c,rd_rd_c = apply_SVD(corn_tensor     ,left_bond=[0,1],right_bond=[2,3],truncate=None)# bck, kda\n",
    "\n",
    "# rd_lu_r_should=rd_lu_origin[-1,:-1];rd_rd_r_should=rd_rd_origin[-1,:-1]\n",
    "# ru_ld_r_should=ru_ld_origin[-1,:]  ;ru_ru_r_should=ru_ru_origin[-1,:]\n",
    "# rd_lu_d_should=rd_lu_origin[:-1,-1];rd_rd_d_should=rd_rd_origin[:-1,-1]\n",
    "# ld_ld_d_should=ld_ld_origin[:,-1]  ;ld_ru_d_should=ld_ru_origin[:,-1]\n",
    "# rd_lu_c_should=rd_lu_origin[ -1,-1];rd_rd_c_should=rd_rd_origin[ -1,-1]\n",
    "\n",
    "# print(rd_lu_r_should.shape)\n",
    "# print(ru_ld_r_should.shape)\n",
    "# print(rd_lu_d_should.shape)\n",
    "# print(ld_ld_d_should.shape)\n",
    "# print(rd_lu_c_should.shape)\n",
    "\n",
    "# print(torch.dist(rd_lu_r_should,rd_lu_r),torch.dist(rd_rd_r_should,rd_rd_r))\n",
    "# print(torch.dist(ru_ld_r_should,ru_ld_r),torch.dist(ru_ru_r_should,ru_ru_r))\n",
    "# print(torch.dist(rd_lu_d_should,rd_lu_d),torch.dist(rd_rd_d_should,rd_rd_d))\n",
    "# print(torch.dist(ld_ld_d_should,ld_ld_d),torch.dist(ld_ru_d_should,ld_ru_d))\n",
    "# print(torch.dist(rd_lu_c_should,rd_lu_c),torch.dist(rd_rd_c_should,rd_rd_c))\n",
    "\n",
    "# tensor1     = torch.einsum(\"whicd,whjac,whbak,whdbl->whijkl\",\n",
    "#                                     lu_rd_origin,\n",
    "#                                     ld_ru_origin,\n",
    "#                                     rd_lu_origin,\n",
    "#                                     ru_ld_origin)\n",
    "# tensor2     = torch.einsum(\"whicd,whjac,whbak,whdbl->whijkl\",\n",
    "#                            rd_rd_origin,\n",
    "#                            ru_ru_origin.roll(shifts=-1,dims=1),\n",
    "#                            lu_lu_origin.roll(shifts=(-1, -1), dims=(0, 1)),\n",
    "#                            ld_ld_origin.roll(shifts=-1,dims=0))\n",
    "\n",
    "# bulk_tensor1_should= tensor1[:-1,:-1]\n",
    "# rigt_tensor1_should= tensor1[-1,:-1]\n",
    "# down_tensor1_should= tensor1[:-1,-1]\n",
    "# corn_tensor1_should= tensor1[-1,-1]\n",
    "# bulk_tensor2_should= tensor2[:-1,:-1]\n",
    "# rigt_tensor2_should= tensor2[-1,:-1]\n",
    "# down_tensor2_should= tensor2[:-1,-1]\n",
    "# corn_tensor2_should= tensor2[-1,-1]\n",
    "\n",
    "# print(bulk_tensor1_should.shape)\n",
    "# print(rigt_tensor1_should.shape)  \n",
    "# print(down_tensor1_should.shape)  \n",
    "# print(corn_tensor1_should.shape)  \n",
    "# print(bulk_tensor2_should.shape)  \n",
    "# print(rigt_tensor2_should.shape)  \n",
    "# print(down_tensor2_should.shape)  \n",
    "# print(corn_tensor2_should.shape)  \n",
    "\n",
    "# bulk_tensor1 = torch.einsum(\"whicd,whjac,whbak,whdbl->whijkl\",lu_rd[:-1,:-1],ld_ru[:-1],rd_lu,ru_ld[:,:-1])\n",
    "# rigt_tensor1 = torch.einsum(\"wicd,wjac,wbak,wdbl->wijkl\",lu_rd[-1,:-1],ld_ru[-1]   ,rd_lu_r, ru_ld_r[:-1])\n",
    "# down_tensor1 = torch.einsum(\"wicd,wjac,wbak,wdbl->wijkl\",lu_rd[:-1,-1],ld_ru_d[:-1],rd_lu_d, ru_ld[:,-1])\n",
    "# corn_tensor1 = torch.einsum(\" icd, jac, bak, dbl-> ijkl\",lu_rd[-1,-1] ,ld_ru_d[-1] ,rd_lu_c, ru_ld_r[-1])\n",
    "# bulk_tensor2 = torch.einsum(\"whicd,whjac,whbak,whdbl->whijkl\",rd_rd,ru_ru[:,1:],lu_lu[1:,1:],ld_ld[1:])\n",
    "# rigt_tensor2 = torch.einsum(\"wicd,wjac,wbak,wdbl->wijkl\",rd_rd_r, ru_ru_r[1:],lu_lu[0,1:], ld_ld[0])\n",
    "# down_tensor2 = torch.einsum(\"wicd,wjac,wbak,wdbl->wijkl\",rd_rd_d, ru_ru[:,0],lu_lu[1:,0], ld_ld_d[1:])\n",
    "# corn_tensor2 = torch.einsum(\" icd, jac, bak, dbl-> ijkl\",rd_rd_c, ru_ru_r[0],lu_lu[0,0] , ld_ld_d[0])\n",
    "\n",
    "# print(bulk_tensor1.shape)\n",
    "# print(rigt_tensor1.shape)  \n",
    "# print(down_tensor1.shape)  \n",
    "# print(corn_tensor1.shape)  \n",
    "# print(bulk_tensor2.shape)  \n",
    "# print(rigt_tensor2.shape)  \n",
    "# print(down_tensor2.shape)  \n",
    "# print(corn_tensor2.shape)  \n",
    "\n",
    "# print(torch.dist(bulk_tensor1,bulk_tensor1_should))\n",
    "# print(torch.dist(rigt_tensor1,rigt_tensor1_should))  \n",
    "# print(torch.dist(down_tensor1,down_tensor1_should))  \n",
    "# print(torch.dist(corn_tensor1,corn_tensor1_should))  \n",
    "# print(torch.dist(bulk_tensor2,bulk_tensor2_should))  \n",
    "# print(torch.dist(rigt_tensor2,rigt_tensor2_should))  \n",
    "# print(torch.dist(down_tensor2,down_tensor2_should))  \n",
    "# print(torch.dist(corn_tensor2,corn_tensor2_should)) \n",
    "\n",
    "# computer_vie_tn(tensor)\n",
    "\n",
    "# truncate = None\n",
    "# bulk_left ,bulk_right= apply_SVD(bulk_tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)\n",
    "# rigt_left ,rigt_right= apply_SVD(rigt_tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)\n",
    "# down_left ,down_right= apply_SVD(down_tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)\n",
    "# corn_left ,corn_right= apply_SVD(corn_tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)\n",
    "# bulk_lower,bulk_uppe = apply_SVD(bulk_tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "# rigt_lower,rigt_uppe = apply_SVD(rigt_tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "# down_lower,down_uppe = apply_SVD(down_tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "# corn_lower,corn_uppe = apply_SVD(corn_tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "\n",
    "# bulk_tensor           = torch.einsum(\"whadi,whjba,whkcb,whdcl->whijkl\", bulk_lower[:-1,:-1],bulk_right[:-1,1:],bulk_uppe[:-1,1:],bulk_left[1:,1:])\n",
    "# rigt_bulk_tensor      = torch.einsum(\"hadi,hjba,hkcb,hdcl->hijkl\"     , rigt_lower[:-1]    ,rigt_right[1:]    ,rigt_uppe[1:]    ,bulk_left[0,1:])\n",
    "# down_bulk_tensor      = torch.einsum(\"hadi,hjba,hkcb,hdcl->hijkl\"     , down_lower[:-1]    ,bulk_right[:-1,0] ,bulk_uppe[:-1,0] ,bulk_left[1:,0])\n",
    "# bulk_rigt_tensor      = torch.einsum(\"hadi,hjba,hkcb,hdcl->hijkl\"     , bulk_lower[-1,:-1] ,bulk_right[-1,1:] ,bulk_uppe[-1,1:] ,rigt_left[1:])\n",
    "# bulk_down_tensor      = torch.einsum(\"hadi,hjba,hkcb,hdcl->hijkl\"     , bulk_lower[:-1,-1] ,down_right[:-1]   ,down_uppe[:-1]   ,down_left[1:])\n",
    "# bulk_down_corn_tensor = torch.einsum(\"adi,jba,kcb,dcl->ijkl\"          , bulk_lower[-1,-1]  ,down_right[-1]    ,down_uppe[-1]    ,corn_left)\n",
    "# corn_right_bulk_tensor= torch.einsum(\"adi,jba,kcb,dcl->ijkl\"          , corn_lower         ,rigt_right[0]     ,rigt_uppe[0]     ,bulk_left[0,0])\n",
    "# right_corn_down_tensor= torch.einsum(\"adi,jba,kcb,dcl->ijkl\"          , rigt_lower[-1]     ,corn_right        ,corn_uppe        ,down_left[0])\n",
    "# down_bulk_right_tensor= torch.einsum(\"adi,jba,kcb,dcl->ijkl\"          , down_lower[-1]     ,bulk_right[-1,0]  ,bulk_uppe[-1,0]  ,rigt_left[0])\n",
    "\n",
    "# left,right  = apply_SVD(tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)# ABK,KCD\n",
    "# lower,uppe  = apply_SVD(tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "# new_tensor_should  = torch.einsum(\"whadi,whjba,whkcb,whdcl->whijkl\",\n",
    "#                    lower,\n",
    "#                    right.roll(-1,1),\n",
    "#                    uppe.roll(-1,1),\n",
    "#                    left.roll(shifts=(-1, -1), dims=(0, 1))\n",
    "#                    )\n",
    "\n",
    "# print(bulk_tensor.shape)           \n",
    "# print(rigt_bulk_tensor.shape)      \n",
    "# print(down_bulk_tensor.shape)      \n",
    "# print(bulk_rigt_tensor.shape)      \n",
    "# print(bulk_down_tensor.shape)      \n",
    "# print(bulk_down_corn_tensor.shape) \n",
    "# print(corn_right_bulk_tensor.shape)\n",
    "# print(right_corn_down_tensor.shape)\n",
    "# print(down_bulk_right_tensor.shape)\n",
    "\n",
    "# bulk_tensor_should            = new_tensor_should[:-2, :-2]\n",
    "# rigt_bulk_tensor_should       = new_tensor_should[-1,:-2]\n",
    "# down_bulk_tensor_should       = new_tensor_should[:-2,-1]\n",
    "# bulk_rigt_tensor_should       = new_tensor_should[-2,:-2]\n",
    "# bulk_down_tensor_should       = new_tensor_should[:-2,-2]\n",
    "# bulk_down_corn_tensor_should  = new_tensor_should[-2,-2]\n",
    "# corn_right_bulk_tensor_should = new_tensor_should[-1,-1]\n",
    "# right_corn_down_tensor_should = new_tensor_should[-1,-2]\n",
    "# down_bulk_right_tensor_should = new_tensor_should[-2,-1]\n",
    "\n",
    "# print(bulk_tensor_should.shape           )\n",
    "# print(rigt_bulk_tensor_should.shape      )\n",
    "# print(down_bulk_tensor_should.shape      )\n",
    "# print(bulk_rigt_tensor_should.shape      )\n",
    "# print(bulk_down_tensor_should.shape      )\n",
    "# print(bulk_down_corn_tensor_should.shape )\n",
    "# print(corn_right_bulk_tensor_should.shape)\n",
    "# print(right_corn_down_tensor_should.shape)\n",
    "# print(down_bulk_right_tensor_should.shape)\n",
    "\n",
    "# print(torch.dist(bulk_tensor_should            ,bulk_tensor           ))\n",
    "# print(torch.dist(rigt_bulk_tensor_should       ,rigt_bulk_tensor      ))\n",
    "# print(torch.dist(down_bulk_tensor_should       ,down_bulk_tensor      ))\n",
    "# print(torch.dist(bulk_rigt_tensor_should       ,bulk_rigt_tensor      ))\n",
    "# print(torch.dist(bulk_down_tensor_should       ,bulk_down_tensor      ))\n",
    "# print(torch.dist(bulk_down_corn_tensor_should  ,bulk_down_corn_tensor ))\n",
    "# print(torch.dist(corn_right_bulk_tensor_should ,corn_right_bulk_tensor))\n",
    "# print(torch.dist(right_corn_down_tensor_should ,right_corn_down_tensor))\n",
    "# print(torch.dist(down_bulk_right_tensor_should ,down_bulk_right_tensor))\n",
    "\n",
    "# new_tensor = torch.cat(\n",
    "#     [torch.cat([bulk_tensor,bulk_rigt_tensor.unsqueeze(0),rigt_bulk_tensor.unsqueeze(0)]),\n",
    "#      torch.cat([bulk_down_tensor,bulk_down_corn_tensor.unsqueeze(0),right_corn_down_tensor.unsqueeze(0)]).unsqueeze(1),\n",
    "#      torch.cat([down_bulk_tensor,down_bulk_right_tensor.unsqueeze(0),corn_right_bulk_tensor.unsqueeze(0)]).unsqueeze(1),\n",
    "#     ],dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### odd number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #%%writefile Contractor2D/test_for_TRG_odd_number.py\n",
    "# import torch\n",
    "\n",
    "# from Contractor2D.utils import apply_SVD\n",
    "\n",
    "# tensor = torch.randn(5,5,2,2,2,2)\n",
    "# print(f\"the input tensor network store in {tensor.shape}\")\n",
    "# print(f\"the ultimate result should be {uniform_shape_tensor_contractor_tn(tensor)}\")\n",
    "\n",
    "\n",
    "# right_edge1,right_edge2 = tensor[-2:]\n",
    "# right_edge = torch.einsum(\"wabcd,wedfg->waebcfg\",right_edge1,right_edge2).flatten(1,2).flatten(-3,-2)\n",
    "# down_edge1, down_edge2 = tensor[:-2,-2:].transpose(1,0)\n",
    "# corn_tensor1,corn_tensor2= right_edge[-2:]\n",
    "# bulk_tensor= tensor[:-2,:-2]\n",
    "# right_edge = right_edge[:-2]\n",
    "# down_edge  = torch.einsum(\"wabcd,wcefg->wabefdg\",down_edge1,down_edge2).flatten(2,3).flatten(-2,-1)\n",
    "# corn_tensor= torch.einsum(\"abcd,cefg->abefdg\",corn_tensor1,corn_tensor2).flatten(1,2).flatten(-2,-1)\n",
    "\n",
    "# print(f\"the input bulk_right_left_corner tensor :\")\n",
    "# print(f\"bulk_tensor.shape = {bulk_tensor.shape}\")\n",
    "# print(f\"right_edge.shape  = {right_edge.shape }\")\n",
    "# print(f\"down_edge.shape   = {down_edge.shape  }\")\n",
    "# print(f\"corn_tensor.shape = {corn_tensor.shape}\")\n",
    "\n",
    "# print(f\"the bulk_right_left_corner_contractor result {bulk_right_left_corner_contractor_tn(bulk_tensor,right_edge,down_edge,corn_tensor)}\")\n",
    "\n",
    "# lu_lu,lu_rd = apply_SVD(bulk_tensor[0::2,0::2],left_bond=[0,1],right_bond=[2,3],truncate=None)# abk ,kcd\n",
    "# rd_lu,rd_rd = apply_SVD(bulk_tensor[1::2,1::2],left_bond=[0,1],right_bond=[2,3],truncate=None)# abk, kcd\n",
    "# ld_ld,ld_ru = apply_SVD(bulk_tensor[0::2,1::2],left_bond=[1,2],right_bond=[3,0],truncate=None)# bck, kda\n",
    "# ru_ld,ru_ru = apply_SVD(bulk_tensor[1::2,0::2],left_bond=[1,2],right_bond=[3,0],truncate=None)# bck, kda\n",
    "\n",
    "# rd_lu_r,rd_rd_r = apply_SVD(right_edge[1::2],left_bond=[0,1],right_bond=[2,3],truncate=None)# abk, kcd\n",
    "# ru_ld_r,ru_ru_r = apply_SVD(right_edge[0::2],left_bond=[1,2],right_bond=[3,0],truncate=None)# bck, kda\n",
    "# rd_lu_d,rd_rd_d = apply_SVD( down_edge[1::2],left_bond=[0,1],right_bond=[2,3],truncate=None)# abk, kcd\n",
    "# ld_ld_d,ld_ru_d = apply_SVD( down_edge[0::2],left_bond=[1,2],right_bond=[3,0],truncate=None)# bck, kda\n",
    "# rd_lu_c,rd_rd_c = apply_SVD(corn_tensor     ,left_bond=[0,1],right_bond=[2,3],truncate=None)# bck, kda\n",
    "\n",
    "# bulk_tensor1 = torch.einsum(\"whicd,whjac,whbak,whdbl->whijkl\",lu_rd[:-1,:-1],ld_ru[:-1],rd_lu,ru_ld[:,:-1])\n",
    "# rigt_tensor1 = torch.einsum(\"wicd,wjac,wbak,wdbl->wijkl\",lu_rd[-1,:-1],ld_ru[-1]   ,rd_lu_r, ru_ld_r[:-1])\n",
    "# down_tensor1 = torch.einsum(\"wicd,wjac,wbak,wdbl->wijkl\",lu_rd[:-1,-1],ld_ru_d[:-1],rd_lu_d, ru_ld[:,-1])\n",
    "# corn_tensor1 = torch.einsum(\" icd, jac, bak, dbl-> ijkl\",lu_rd[-1,-1] ,ld_ru_d[-1] ,rd_lu_c, ru_ld_r[-1])\n",
    "# bulk_tensor2 = torch.einsum(\"whicd,whjac,whbak,whdbl->whijkl\",rd_rd,ru_ru[:,1:],lu_lu[1:,1:],ld_ld[1:])\n",
    "# rigt_tensor2 = torch.einsum(\"wicd,wjac,wbak,wdbl->wijkl\",rd_rd_r, ru_ru_r[1:],lu_lu[0,1:], ld_ld[0])\n",
    "# down_tensor2 = torch.einsum(\"wicd,wjac,wbak,wdbl->wijkl\",rd_rd_d, ru_ru[:,0],lu_lu[1:,0], ld_ld_d[1:])\n",
    "# corn_tensor2 = torch.einsum(\" icd, jac, bak, dbl-> ijkl\",rd_rd_c, ru_ru_r[0],lu_lu[0,0] , ld_ld_d[0])\n",
    "\n",
    "# print(\"phase1:result\")\n",
    "# print(f\"bulk_tensor1.shape={bulk_tensor1.shape}\")\n",
    "# print(f\"rigt_tensor1.shape={rigt_tensor1.shape}\")\n",
    "# print(f\"down_tensor1.shape={down_tensor1.shape}\")\n",
    "# print(f\"corn_tensor1.shape={corn_tensor1.shape}\")\n",
    "# print()\n",
    "# print(f\"bulk_tensor2.shape={bulk_tensor2.shape}\")\n",
    "# print(f\"rigt_tensor2.shape={rigt_tensor2.shape}\")\n",
    "# print(f\"down_tensor2.shape={down_tensor2.shape}\")\n",
    "# print(f\"corn_tensor2.shape={corn_tensor2.shape}\")\n",
    "\n",
    "# # if we don't truncate at this step, the map will become too complex and can not code as unique way,\n",
    "# # so in such case, we will require truncate 16 in here and the recommend input not big than 32.\n",
    "# truncate = None\n",
    "# bulk_left ,bulk_right= apply_SVD(bulk_tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)\n",
    "# rigt_left ,rigt_right= apply_SVD(rigt_tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)\n",
    "# down_left ,down_right= apply_SVD(down_tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)\n",
    "# corn_left ,corn_right= apply_SVD(corn_tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)\n",
    "# bulk_lower,bulk_uppe = apply_SVD(bulk_tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "# rigt_lower,rigt_uppe = apply_SVD(rigt_tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "# down_lower,down_uppe = apply_SVD(down_tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "# corn_lower,corn_uppe = apply_SVD(corn_tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "\n",
    "# bulk_tensor_cent      = torch.einsum(\"whadi,whjba,whkcb,whdcl->whijkl\", bulk_lower[:-1,:-1],bulk_right[:-1,1:],bulk_uppe[:-1,1:],bulk_left[1:,1:])\n",
    "# rigt_bulk_tensor      = torch.einsum(\"hadi,hjba,hkcb,hdcl->hijkl\"     , rigt_lower[:-1]    ,rigt_right[1:]    ,rigt_uppe[1:]    ,bulk_left[0,1:])\n",
    "# down_bulk_tensor      = torch.einsum(\"hadi,hjba,hkcb,hdcl->hijkl\"     , down_lower[:-1]    ,bulk_right[:-1,0] ,bulk_uppe[:-1,0] ,bulk_left[1:,0])\n",
    "# bulk_rigt_tensor      = torch.einsum(\"hadi,hjba,hkcb,hdcl->hijkl\"     , bulk_lower[-1,:-1] ,bulk_right[-1,1:] ,bulk_uppe[-1,1:] ,rigt_left[1:])\n",
    "# bulk_down_tensor      = torch.einsum(\"hadi,hjba,hkcb,hdcl->hijkl\"     , bulk_lower[:-1,-1] ,down_right[:-1]   ,down_uppe[:-1]   ,down_left[1:])\n",
    "# bulk_down_corn_tensor = torch.einsum(\"adi,jba,kcb,dcl->ijkl\"          , bulk_lower[-1,-1]  ,down_right[-1]    ,down_uppe[-1]    ,corn_left)\n",
    "# corn_right_bulk_tensor= torch.einsum(\"adi,jba,kcb,dcl->ijkl\"          , corn_lower         ,rigt_right[0]     ,rigt_uppe[0]     ,bulk_left[0,0])\n",
    "# right_corn_down_tensor= torch.einsum(\"adi,jba,kcb,dcl->ijkl\"          , rigt_lower[-1]     ,corn_right        ,corn_uppe        ,down_left[0])\n",
    "# down_bulk_right_tensor= torch.einsum(\"adi,jba,kcb,dcl->ijkl\"          , down_lower[-1]     ,bulk_right[-1,0]  ,bulk_uppe[-1,0]  ,rigt_left[0])\n",
    "# # down_bulk_tensor       = down_bulk_tensor[None]\n",
    "# # down_bulk_right_tensor = down_bulk_right_tensor[None]\n",
    "# # corn_right_bulk_tensor = corn_right_bulk_tensor[None]\n",
    "# # bulk_down_corn_tensor  = bulk_down_corn_tensor[None]\n",
    "\n",
    "# print(\"phase2 result:\")\n",
    "# print(f\"bulk_tensor_cent.shape      ={bulk_tensor_cent.shape      }\")\n",
    "# print(f\"down_bulk_tensor.shape      ={down_bulk_tensor.shape      }\")      \n",
    "# print(f\"bulk_rigt_tensor.shape      ={bulk_rigt_tensor.shape      }\")   \n",
    "# print(f\"down_bulk_right_tensor.shape={down_bulk_right_tensor.shape}\")\n",
    "# print(f\"rigt_bulk_tensor.shape      ={rigt_bulk_tensor.shape      }\")      \n",
    "# print(f\"corn_right_bulk_tensor.shape={corn_right_bulk_tensor.shape}\")\n",
    "# print(f\"bulk_down_tensor.shape      ={bulk_down_tensor.shape      }\") \n",
    "# print(f\"bulk_down_corn_tensor.shape ={bulk_down_corn_tensor.shape }\") \n",
    "# print(f\"right_corn_down_tensor.shape={right_corn_down_tensor.shape}\")\n",
    "\n",
    "# bulk_tensor = torch.cat([\n",
    "#     torch.cat([bulk_tensor_cent,down_bulk_tensor[None]],1),\n",
    "#     torch.cat([bulk_rigt_tensor,down_bulk_right_tensor[None]])[None]\n",
    "# ])\n",
    "\n",
    "# bulk_tensor.shape\n",
    "\n",
    "# bulk_tensor = down_bulk_right_tensor[None][None]\n",
    "\n",
    "# right_edge = torch.cat([rigt_bulk_tensor,corn_right_bulk_tensor[None]])\n",
    "# down_edge  = torch.cat([bulk_down_tensor,bulk_down_corn_tensor[None]])\n",
    "# corn_tensor =right_corn_down_tensor\n",
    "\n",
    "# print(f\"next tensor shape:\")\n",
    "# print(f\"bulk_tensor.shape = {bulk_tensor.shape}\")\n",
    "# print(f\"right_edge.shape  = {right_edge.shape }\")\n",
    "# print(f\"down_edge.shape   = {down_edge.shape  }\")\n",
    "# print(f\"corn_tensor.shape = {corn_tensor.shape}\")\n",
    "\n",
    "# print(f\"next tensor contraction result:\")\n",
    "# print(bulk_right_left_corner_contractor_tn(bulk_tensor,right_edge,down_edge,corn_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### time test for different engine (only bulk $2^n$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import torch_semiring_einsum\n",
    "# def TRT_semiring(tensor,truncate=None, block_size=5):\n",
    "#     W,H = tensor.shape[:2]\n",
    "#     einsum_1 = torch_semiring_einsum.compile_equation(\"whicd,whjac,whbak,whdbl->whijkl\")\n",
    "#     einsum_2 = torch_semiring_einsum.compile_equation(\"whadi,whjba,whkcb,whdcl->whijkl\")\n",
    "#     einsum_3 = torch_semiring_einsum.compile_equation(\"abcd,ciaj,ldkb,kjli->\")\n",
    "#     while True:\n",
    "#         print(tensor.shape)\n",
    "#         W,H = tensor.shape[:2]\n",
    "#         #if W<=1 or H<=1:break\n",
    "#         lu_tensor = tensor[0::2,0::2]\n",
    "#         ld_tensor = tensor[0::2,1::2]\n",
    "#         ru_tensor = tensor[1::2,0::2]\n",
    "#         rd_tensor = tensor[1::2,1::2]\n",
    "#         if W<=2 or H<=2:break\n",
    "            \n",
    "#         lu_lu,lu_rd = apply_SVD(lu_tensor,left_bond=[0,1],right_bond=[2,3],truncate=truncate)# abk ,kcd\n",
    "#         rd_lu,rd_rd = apply_SVD(rd_tensor,left_bond=[0,1],right_bond=[2,3],truncate=truncate)# abk, kcd\n",
    "#         ld_ld,ld_ru = apply_SVD(ld_tensor,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# bck, kda\n",
    "#         ru_ld,ru_ru = apply_SVD(ru_tensor,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# bck, kda\n",
    "#         tensor1     = torch_semiring_einsum.einsum(einsum_1,\n",
    "#                                     lu_rd,\n",
    "#                                     ld_ru,\n",
    "#                                     rd_lu,\n",
    "#                                     ru_ld,block_size=block_size)\n",
    "#         tensor2     = torch_semiring_einsum.einsum(einsum_1,\n",
    "#                                    rd_rd,\n",
    "#                                    ru_ru.roll(shifts=-1,dims=1),\n",
    "#                                    lu_lu.roll(shifts=(-1, -1), dims=(0, 1)),\n",
    "#                                    ld_ld.roll(shifts=-1,dims=0),block_size=block_size)\n",
    "#         left,right  = apply_SVD(tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)# ABK,KCD\n",
    "#         lower,uppe  = apply_SVD(tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "#         tensor  = torch_semiring_einsum.einsum(einsum_2,\n",
    "#                            lower,\n",
    "#                            right.roll(-1,1),\n",
    "#                            uppe.roll(-1,1),\n",
    "#                            left.roll(shifts=(-1, -1), dims=(0, 1)),block_size=block_size\n",
    "#                            )\n",
    "#     value   = torch_semiring_einsum.einsum(einsum_3,\n",
    "#                            lu_tensor[0,0],ld_tensor[0,0],\n",
    "#                            ru_tensor[0,0],rd_tensor[0,0],block_size=block_size)\n",
    "#     #value = torch.einsum(\"abab->\",tensor[0,0])\n",
    "#     return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tensor = torch.randn(14,14,2,2,2,2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def TRT(tensor,truncate=None,einsum_engin=torch.einsum):\n",
    "    W,H = tensor.shape[:2]\n",
    "    while True:\n",
    "        print(tensor.shape)\n",
    "        W,H = tensor.shape[:2]\n",
    "        #if W<=1 or H<=1:break\n",
    "        lu_tensor = tensor[0::2,0::2]\n",
    "        ld_tensor = tensor[0::2,1::2]\n",
    "        ru_tensor = tensor[1::2,0::2]\n",
    "        rd_tensor = tensor[1::2,1::2]\n",
    "        if W<=2 or H<=2:break\n",
    "#         print(\"SVD:time\"),\n",
    "#         start_time  = time.time()\n",
    "        lu_lu,lu_rd = apply_SVD(lu_tensor,left_bond=[0,1],right_bond=[2,3],truncate=truncate)# abk ,kcd\n",
    "        rd_lu,rd_rd = apply_SVD(rd_tensor,left_bond=[0,1],right_bond=[2,3],truncate=truncate)# abk, kcd\n",
    "        ld_ld,ld_ru = apply_SVD(ld_tensor,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# bck, kda\n",
    "        ru_ld,ru_ru = apply_SVD(ru_tensor,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# bck, kda\n",
    "#         cost = time.time() - start_time\n",
    "#         print(cost)       \n",
    "#         print(\"einsum:time\"),\n",
    "#         start_time  = time.time()\n",
    "        tensor1     = einsum_engin(\"whicd,whjac,whbak,whdbl->whijkl\",\n",
    "                                    lu_rd,\n",
    "                                    ld_ru,\n",
    "                                    rd_lu,\n",
    "                                    ru_ld)\n",
    "        tensor2     = einsum_engin(\"whicd,whjac,whbak,whdbl->whijkl\",\n",
    "                                   rd_rd,\n",
    "                                   ru_ru.roll(shifts=-1,dims=1),\n",
    "                                   lu_lu.roll(shifts=(-1, -1), dims=(0, 1)),\n",
    "                                   ld_ld.roll(shifts=-1,dims=0))\n",
    "#         cost = time.time() - start_time\n",
    "#         print(cost)\n",
    "#         print(\"SVD:time\"),\n",
    "#         start_time  = time.time()\n",
    "        \n",
    "        left,right  = apply_SVD(tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)# ABK,KCD\n",
    "        lower,uppe  = apply_SVD(tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "#         cost = time.time() - start_time\n",
    "#         print(cost)\n",
    "#         print(\"einsum:time\"),\n",
    "#         start_time  = time.time()\n",
    "        tensor  = einsum_engin(\"whadi,whjba,whkcb,whdcl->whijkl\",\n",
    "                           lower,\n",
    "                           right.roll(-1,1),\n",
    "                           uppe.roll(-1,1),\n",
    "                           left.roll(shifts=(-1, -1), dims=(0, 1))\n",
    "                           )\n",
    "#         cost = time.time() - start_time\n",
    "#         print(cost)\n",
    "    value   = einsum_engin(\"abcd,ciaj,ldkb,kjli->\",lu_tensor[0,0],ld_tensor[0,0],ru_tensor[0,0],rd_tensor[0,0])\n",
    "    #value = torch.einsum(\"abab->\",tensor[0,0])\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tensor = torch.randn(14,14,2,2,2,2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "engine=lambda equ,*karg:torch_semiring_einsum.einsum(torch_semiring_einsum.compile_equation(equ),*karg,block_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.49 ms ± 10 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn(4,4,2,2,2,2)\n",
    "%timeit TRT(tensor,truncate=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.67 ms ± 1.43 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit TRT(tensor,truncate=None,einsum_engin=contract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Boundary MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from utils import *\n",
    "\n",
    "\n",
    "def rd_engine(*x,**kargs):\n",
    "    x =  torch.randn(*x,device='cpu',**kargs)\n",
    "    x/=  torch.norm(x).sqrt()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D=4;P=4;L=7;\n",
    "# top_mps_list    = [rd_engine(P,D)] + [rd_engine(L-2,D,P,D)]  + [rd_engine(D,P)]\n",
    "# middle_mpo_list = [[rd_engine(P,D,P)]+[rd_engine(L-2,D,P,D,P)]+ [rd_engine(D,P,P)]\n",
    "#                   for _ in range(L-2)]\n",
    "# bottom_mps_list = [rd_engine(P,D)] + [rd_engine(L-2,D,P,D)]  + [rd_engine(D,P)]\n",
    "# peps  = [top_mps_list]+middle_mpo_list+[bottom_mps_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D=4;P=4;L=7;\n",
    "top_mps_list    = [rd_engine(D,D)]     + [rd_engine(L-2,D,D,D)]  + [rd_engine(D,D)]\n",
    "middle_mpo_list = [[rd_engine(D,D,D)]  + [rd_engine(L-2,D,D,D,D)]+ [rd_engine(D,D,D)]\n",
    "                  for _ in range(L-2)]\n",
    "bottom_mps_list = [rd_engine(D,D)]     + [rd_engine(L-2,D,D,D)]  + [rd_engine(D,D)]\n",
    "peps  = [top_mps_list]+middle_mpo_list+[bottom_mps_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     3,
     64,
     94,
     127,
     131,
     159
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from engine.torch_dense import approxmate_mps_line\n",
    "import torch\n",
    "import numpy as np\n",
    "def truncated_SVD(tensor,output='RQ',max_singular_values= None,\n",
    "                  max_truncation_error= None,\n",
    "                  relative = True,\n",
    "                  normlized= True,\n",
    "                  verbose  = False,auto_check_diagonal=False):\n",
    "    # the canonocal\n",
    "    # tensor is batched\n",
    "    reduce = False\n",
    "    u=s=v = None\n",
    "    if len(tensor.shape)==2:\n",
    "        tensor = tensor.unsqueeze(0)\n",
    "        reduce = True\n",
    "    if auto_check_diagonal:\n",
    "        out = diagonal_tensor_svd_torch_dense(tensor)\n",
    "        if out is not None:u, s, v = out\n",
    "    if u is None: u, s, v = torch.svd(tensor)\n",
    "\n",
    "\n",
    "    max_singular_values = s.shape[-1] if max_singular_values is None else max_singular_values\n",
    "\n",
    "    if max_truncation_error is not None:\n",
    "        # Cumulative norms of singular values in ascending order\n",
    "        s_sorted, _ = torch.sort(s**2,-1)\n",
    "        trunc_errs  = torch.sqrt(torch.cumsum(s_sorted, -1))\n",
    "        # If relative is true, rescale max_truncation error with the largest\n",
    "        # singular value to yield the absolute maximal truncation error.\n",
    "        abs_max_truncation_error = max_truncation_error * s[:,0:1] if relative else max_truncation_error\n",
    "        # We must keep at least this many singular values to ensure the\n",
    "        # truncation error is <= abs_max_truncation_error.\n",
    "        num_sing_vals_err = torch.sum(trunc_errs > abs_max_truncation_error,-1).max()\n",
    "        if max_singular_values>num_sing_vals_err and verbose:\n",
    "            print(f\"use {num_sing_vals_err}/{max_singular_values} sing vals\")\n",
    "    else:\n",
    "        num_sing_vals_err  = max_singular_values\n",
    "\n",
    "    num_sing_vals_keep = min(max_singular_values, num_sing_vals_err)\n",
    "\n",
    "\n",
    "    #s_rest = s[...,num_sing_vals_keep:]\n",
    "    u      = u[...,:num_sing_vals_keep]\n",
    "    s      = s[...,:num_sing_vals_keep]\n",
    "    v      = v[...,:num_sing_vals_keep]\n",
    "    v      = torch.transpose(v, -1, -2)#vh\n",
    "\n",
    "    if num_sing_vals_keep == s.shape[-1] and normlized:\n",
    "        Z = 1.0*torch.ones(s.shape[0])\n",
    "    else:\n",
    "        Z = torch.sum(s**2,-1).sqrt()\n",
    "\n",
    "    if output == 'RQ':\n",
    "        R = torch.einsum('iab,ibc->iac',u ,torch.diag_embed(s))\n",
    "        Q = v\n",
    "        output = [R,Q,Z]\n",
    "    elif output == 'QR':\n",
    "        Q = u\n",
    "        R = torch.einsum('iab,ibc->iac',torch.diag_embed(s),v)\n",
    "        output = [Q,R,Z]\n",
    "    else:\n",
    "        output = [u,s,v,Z]\n",
    "    if reduce:output = [t[0] for t in output]\n",
    "    return output\n",
    "def left_canonicalize_MPS(mps_line,Decomposition_Engine=torch.qr,\n",
    "                          normlization =True):\n",
    "    # for any not canonical mps line\n",
    "    # the chain size (D,P,D)\n",
    "    new_chain = []\n",
    "    R         = None\n",
    "    #Z_list    = []# record the scale information for each unit.\n",
    "    # for a perfect MPS state, we expect the norm for each tensor is 1.\n",
    "    for i,tensor in enumerate(mps_line):\n",
    "        if len(tensor.shape)==2:\n",
    "            new_tensor = torch.einsum('ab,bd->ad',R,tensor) if R is not None else tensor\n",
    "            shape      = new_tensor.shape\n",
    "        elif len(tensor.shape)==3:\n",
    "            new_tensor = torch.einsum('ab,bcd->acd',R,tensor) if R is not None else tensor\n",
    "            shape      = new_tensor.shape\n",
    "            a,b,c = shape\n",
    "            new_tensor = new_tensor.reshape(a*b,c)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        if i == len(mps_line) - 1:\n",
    "            Z = torch.norm(new_tensor)\n",
    "            if normlization:new_tensor /= (Z)\n",
    "            new_chain.append(new_tensor.reshape(*shape[:-1],-1))\n",
    "        else:\n",
    "            Q,R = Decomposition_Engine(new_tensor)[:2]\n",
    "            Q   = Q.reshape(*shape[:-1],-1)\n",
    "            new_chain.append(Q)\n",
    "\n",
    "    return new_chain,[Z]\n",
    "def right_canonicalize_MPS(mps_line,Decomposition_Engine=truncated_SVD,\n",
    "                          #normlization =True\n",
    "                          ):\n",
    "    new_chain = []\n",
    "    R         = None\n",
    "    Z_list    = []\n",
    "    svd_Z         = torch.Tensor([1.0])#input has already been normalized\n",
    "    for i,tensor in enumerate(mps_line[::-1]):\n",
    "\n",
    "        if len(tensor.shape)==2:\n",
    "            new_tensor = torch.einsum('ab,bc->ac',tensor, R) if R is not None else tensor\n",
    "            shape      = new_tensor.shape\n",
    "        elif len(tensor.shape)==3:\n",
    "            new_tensor = torch.einsum('alb,bc->alc',tensor, R) if R is not None else tensor\n",
    "            shape      = new_tensor.shape\n",
    "            a,b,c      = shape\n",
    "            new_tensor = new_tensor.reshape(a,b*c)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        Z = torch.norm(new_tensor)\n",
    "        Z_list.append(Z)\n",
    "        new_tensor /= Z\n",
    "        # normlization is necessary; directly use the SVD_Z may cause problem due to precision\n",
    "        #print(f\"svd_Z{svd_Z.item()}<->all_Z {Z.item()} <-> after_Z{torch.norm(new_tensor).item()}\")\n",
    "        #if normlization:new_tensor /= Z\n",
    "        if i == len(mps_line) - 1:\n",
    "            new_chain.append(new_tensor.reshape(-1,*shape[1:]))\n",
    "        else:\n",
    "            R,Q,svd_Z = Decomposition_Engine(new_tensor)\n",
    "            Q   = Q.reshape(-1,*shape[1:])\n",
    "            new_chain.append(Q)\n",
    "    new_chain=new_chain[::-1]\n",
    "    return new_chain,Z_list\n",
    "def torchrq(tensor):\n",
    "    q, r = torch.qr(torch.transpose(tensor, -2, -1))\n",
    "    r, q = torch.transpose(r, -2, -1), torch.transpose(q, -2, -1)  #M=r*q at this point\n",
    "    return r,qx\n",
    "def approxmate_mps_line(mps_line,\n",
    "                        max_singular_values= None,max_truncation_error= None,relative = True,\n",
    "                        mode='full',left_method='qr'\n",
    "                       ):\n",
    "\n",
    "\n",
    "    scalar = 1\n",
    "    if mode != 'right':\n",
    "        if left_method == 'qr':\n",
    "            DCEngine = torch.linalg.qr if float(torch.__version__[:4])>1.07 else torch.qr\n",
    "        elif left_method == 'svd':\n",
    "            DCEngine = lambda x:truncated_SVD(x,output='QR')\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        mps_line,Z_list = left_canonicalize_MPS(mps_line,Decomposition_Engine=DCEngine)\n",
    "        #print(get_mps_size_list(mps_line))\n",
    "        print(f\"   left canonical scalar:{np.prod(Z_list)}\")\n",
    "        scalar *= np.prod(Z_list)\n",
    "        #print(f\"now tensor norm: {torch.norm(mps_line[-1])}\")\n",
    "    SVD_Engine = lambda x:truncated_SVD(x,max_singular_values = max_singular_values,\n",
    "                                          max_truncation_error= max_truncation_error,\n",
    "                                          relative = relative)\n",
    "    mps_line,Z_list = right_canonicalize_MPS(mps_line,Decomposition_Engine=SVD_Engine)\n",
    "    #print(get_mps_size_list(mps_line))\n",
    "    #print(f\"   right canonical Z:{[np.round(t.item(),3) for t in Z_list]}\")\n",
    "    print(f\"   right canonical scalar:{np.prod(Z_list)}\")\n",
    "    scalar *= np.prod(Z_list)\n",
    "    return mps_line,scalar\n",
    "def diagonal_tensor_svd_torch_dense(tensor):\n",
    "    # support batch tensor\n",
    "    reduce = False\n",
    "    if len(tensor.shape)==2:\n",
    "        tensor = tensor.unsqueeze(0)\n",
    "        reduce = True\n",
    "    W,H   = tensor.shape[-2:]\n",
    "    batch_shape= tensor.shape[:-2]\n",
    "    u = s = v = None\n",
    "    if W>=H:\n",
    "        batch_diag = torch.matmul(tensor.transpose(-1,-2),tensor)#auto broadcast, or can use bmm\n",
    "    else:\n",
    "        batch_diag = torch.matmul(tensor,tensor.transpose(-1,-2))#auto broadcast, or can use bmm\n",
    "    diagnol_num = torch.diagonal(a,dim1=-2,dim2=-1).nelement()\n",
    "    tensor_num  = tensor.nelement()\n",
    "    if diagnol_num != tensor_num:return None\n",
    "    A,A        = batch_diag.shape[-2:]\n",
    "    batch_diag = batch_diag[...,range(A),range(A)]\n",
    "    batch_diag,batch_order= batch_diag.sort(-1,descending=True)\n",
    "    #fast_V      = [get_sort_matrix(order).to_dense() for order in batch_order]\n",
    "    batch_order = batch_order.flatten(start_dim=0,end_dim=-2)\n",
    "    K,A         = batch_order.shape\n",
    "    s           = batch_diag.sqrt()\n",
    "    s           = s.reshape(*batch_shape,A)\n",
    "    if W>=H:\n",
    "        v = torch.sparse_coo_tensor([list(range(K*A)),batch_order.flatten().tolist()], [1.0]*K*A,(K*A,A))\n",
    "        v = v.to_dense().reshape(-1,A,A)\n",
    "        u = torch.bmm(tensor,v.transpose(-1,-2)/s.unsqueeze(-2))\n",
    "        v = v.reshape(*batch_shape,A,A)\n",
    "        u = u.reshape(*batch_shape,W,A)\n",
    "    else:\n",
    "        u = torch.sparse_coo_tensor([list(range(K*A)),batch_order.flatten().tolist()], [1.0]*K*A,(K*A,A))\n",
    "        u = u.to_dense().reshape(-1,A,A).transpose(-1,-2)\n",
    "        v = torch.bmm(u.transpose(-1,-2)/s.unsqueeze(-1),tensor)#TODO: case when s==0\n",
    "        u = u.reshape(*batch_shape,A,A)\n",
    "        v = v.reshape(*batch_shape,A,H)\n",
    "    output = [u,s,v.transpose(-1,-2)]\n",
    "    if reduce:\n",
    "        output = [t[0] for t in output]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0+cu102'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   left canonical scalar:0.5324269533157349\n",
      "   right canonical scalar:0.9999996423721313\n",
      "(4, 4)-(4, 4, 16)- 3x(16, 4, 16) -(16, 4, 4)-(4, 4)\n",
      "   left canonical scalar:0.17249836027622223\n",
      "   right canonical scalar:0.9999997615814209\n",
      "(4, 4)-(4, 4, 16)-(16, 4, 64)-(64, 4, 64)-(64, 4, 16)-(16, 4, 4)-(4, 4)\n",
      "   left canonical scalar:0.141238734126091\n",
      "   right canonical scalar:0.9999996423721313\n",
      "(4, 4)-(4, 4, 16)-(16, 4, 64)-(64, 4, 64)-(64, 4, 16)-(16, 4, 4)-(4, 4)\n",
      "   left canonical scalar:0.13460852205753326\n",
      "   right canonical scalar:0.9999997019767761\n",
      "(4, 4)-(4, 4, 16)-(16, 4, 64)-(64, 4, 64)-(64, 4, 16)-(16, 4, 4)-(4, 4)\n",
      "   left canonical scalar:0.1684599667787552\n",
      "   right canonical scalar:1.000000238418579\n",
      "(4, 4)-(4, 4, 16)-(16, 4, 64)-(64, 4, 64)-(64, 4, 16)-(16, 4, 4)-(4, 4)\n"
     ]
    }
   ],
   "source": [
    "tensor = peps[0]\n",
    "for mpo in peps[1:-1]:\n",
    "    tensor = contract_mps_mpo(tensor,mpo)\n",
    "    #print(get_mps_size_list(tensor))\n",
    "    tensor = right_mps_form(tensor)\n",
    "    tensor,scale = approxmate_mps_line(tensor,max_singular_values=100)\n",
    "    print(get_mps_size_list(tensor))\n",
    "tensor = contract_two_mps_tn(tensor,peps[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def onebyoneBMPS(tensor,truncate=None,einsum_engin=torch.einsum):\n",
    "    W,H = tensor.shape[:2]\n",
    "    while W > 1:\n",
    "            half_size = size // 2\n",
    "            nice_size = 2 * half_size\n",
    "            leftover  = tensor[nice_size:]\n",
    "            tensor    = torch.einsum(\"mbik,mbkj->mbij\",tensor[0:nice_size:2], tensor[1:nice_size:2])\n",
    "            #(k/2,NB,D,D),(k/2,NB,D,D) <-> (k/2,NB,D,D)\n",
    "            tensor   = torch.cat([tensor, leftover], axis=0)\n",
    "            size     = half_size + int(size % 2 == 1)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Batch Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from utils import *\n",
    "\n",
    "D=10\n",
    "P=4\n",
    "L=14\n",
    "def rd_engine(*x,**kargs):\n",
    "    x =  torch.randn(*x,device='cpu',**kargs)\n",
    "    x/=  torch.norm(x).sqrt()\n",
    "    return x\n",
    "def generate_test_data(L=10,num=20,k=2):\n",
    "    #images,labels = iter(train_loader).next()\n",
    "    #inputs = preprocess_sum_one(images)\n",
    "    inputs = rd_engine(L,num,k)\n",
    "    inputs = inputs.permute(1,2,0)#(B,num,k)->(num,k,B)\n",
    "    inputs = torch.diag_embed(inputs)#(num,k,B)->(num,k,B,B)\n",
    "    inputs = inputs.permute(0,2,1,3)#(num,k,B,B)->(num,B,k,B)\n",
    "    #inputs= [v for v in inputs]\n",
    "    #inputs[0]= torch.diagonal(inputs[0], dim1=0, dim2=-1)#(B,k,B) -> #(k,B)\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.935704472353725e-15\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(result_should-the_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "mnist_data = np.load('archive/tn-for-unsup-ml/data/binarized_mnist.npz')\n",
    "train_data = torch.from_numpy(mnist_data['train_data'])\n",
    "test_data  = torch.from_numpy(mnist_data['test_data'])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=(0.0,), std=(1.0,))\n",
    "])\n",
    "DATAPATH    = '/media/tianning/DATA/DATASET/MNIST/'\n",
    "mnist_train = datasets.MNIST(DATAPATH, train=True, download=False, transform=transform)\n",
    "mnist_test  = datasets.MNIST(DATAPATH, train=False,download=False, transform=transform)\n",
    "train_loader= torch.utils.data.DataLoader(dataset=mnist_train, batch_size=1000, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test , batch_size=1000, shuffle=False)\n",
    "images,labels = iter(train_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "now_result = np.einsum(\"abc,cd,de,ef,fg,gh,hi,ijk->abjk\",\n",
    "                       imps.get_tensor(len(imps) - 1), \n",
    "                       inv_sqrtl, \n",
    "                       U, \n",
    "                       np.sqrt(lam),np.sqrt(lam), \n",
    "                       V, \n",
    "                       inv_sqrtr, \n",
    "                       imps.tensors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(images1,images2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.051250619959221\n",
      "1.5940558554691758e-14\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(now_result-result_should))\n",
    "print(np.linalg.norm(now_result-the_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### torch.dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a,X,U,S,V,Y,b = canonicalize(imps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from engine.torch_dense import *\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "left  = np.einsum('ea,ab,bc->ec',X,U,np.sqrt(S)).real\n",
    "right = np.einsum('ea,ab,bc->ec',np.sqrt(S),V,Y).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.35 +0.j, -1.134+0.j,  0.117+0.j,  2.915+0.j],\n",
       "       [ 1.193+0.j,  1.376+0.j, -3.855+0.j,  0.129+0.j],\n",
       "       [-1.92 +0.j,  2.322+0.j,  0.48 +0.j,  0.344+0.j],\n",
       "       [ 2.836+0.j,  0.947+0.j,  0.577+0.j, -0.068+0.j]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('ab,ca->bc',X,Y).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### diagonal.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from engine.sparse import *\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imps = FiniteMPS.random(d=[3,3]*5,\n",
    "      D=[2]*9,\n",
    "      dtype=np.float64)\n",
    "imps.canonicalize()\n",
    "imps.position(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n",
      "(10, 20)\n"
     ]
    }
   ],
   "source": [
    "L=10\n",
    "idx1     = list(range(2*L))\n",
    "idx2     = [i for i in range(L) for j in range(2)]\n",
    "mps_unit = sparse.COO([idx1,idx2],np.random.randn(2*L),(2*L,L)).reshape((L,L*2))\n",
    "R,Q = diagonal_tensor_RQ(mps_unit)\n",
    "print(R.shape)\n",
    "print(Q.shape)\n",
    "# u0,s0,v0 = diagonal_tensor_svd_sparse_2D(mps_unit)\n",
    "# u1,s1,v1 = np.linalg.svd(mps_unit.todense(),full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a=np.random.randint(3,(100,100)).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.save(\"tttest\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "b=np.load(\"tttest.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 43], dtype=uint8)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "code_folding": [
     1,
     3,
     8,
     14,
     39
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Efficient_Sparse_Matrix_List_Saver:\n",
    "    def __init__(self,dtype = 'sparse'):\n",
    "        self.dtype = dtype\n",
    "    def save(self,sparse_matrix_list,save_dir):\n",
    "        if self.dtype == 'sparse':\n",
    "            self.save_sparse_data(sparse_matrix_list,save_dir)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    def load(self,save_dir):\n",
    "        if self.dtype == 'sparse':\n",
    "            return self.load_sparse_data(save_dir)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    @staticmethod \n",
    "    def save_sparse_data(sparse_matrix_list,save_dir):\n",
    "        max_shape_len = max([len(t.shape) for t in sparse_matrix_list])\n",
    "        save_indexes  = []\n",
    "        save_shapes   = []\n",
    "        for i in range(len(sparse_matrix_list)):\n",
    "            save_index = sparse_matrix_list[i].coords.transpose()\n",
    "            save_shape = list(sparse_matrix_list[i].shape)\n",
    "            if len(save_shape)< max_shape_len:\n",
    "                padding     = max_shape_len-len(save_shape)\n",
    "                save_index  = np.pad(save_index,[[0,0],[0,padding]])\n",
    "                save_shape  = save_shape+[1]*padding\n",
    "            save_indexes.append(save_index) \n",
    "            save_shapes.append(save_shape)\n",
    "        all_indexs  = np.concatenate(save_indexes)\n",
    "        all_values  = np.concatenate([t.data for t in sparse_matrix_list])\n",
    "        all_shape   = np.stack(save_shapes)\n",
    "        all_idx_size= np.array([len(t.shape) for t in sparse_matrix_list])\n",
    "        nnz_list    = np.array([t.nnz for t in sparse_matrix_list])\n",
    "        assert sum(nnz_list) == len(all_indexs) == len(all_values)\n",
    "        np.save(os.path.join(save_dir,\"all_indexs\"),all_indexs)\n",
    "        np.save(os.path.join(save_dir,\"all_idx_size\"),all_idx_size)\n",
    "        np.save(os.path.join(save_dir,\"all_values\"),all_values)\n",
    "        np.save(os.path.join(save_dir,\"all_shape\"),all_shape)\n",
    "        np.save(os.path.join(save_dir,\"nnz_list\"),nnz_list)\n",
    "    @staticmethod\n",
    "    def load_sparse_data(save_dir):\n",
    "        all_indexs   = np.load(os.path.join(save_dir,\"all_indexs.npy\"))\n",
    "        all_idx_size = np.load(os.path.join(save_dir,\"all_idx_size.npy\"))\n",
    "        all_values   = np.load(os.path.join(save_dir,\"all_values.npy\"))\n",
    "        all_shape    = np.load(os.path.join(save_dir,\"all_shape.npy\"))\n",
    "        nnz_list     = np.load(os.path.join(save_dir,\"nnz_list.npy\"))\n",
    "        \n",
    "        sparse_matrix_list =[]\n",
    "        start = 0 \n",
    "        for nnz,sz,shape in zip(nnz_list,all_idx_size,all_shape):\n",
    "            indexs = all_indexs[start:start+nnz][...,:sz].transpose()\n",
    "            values = all_values[start:start+nnz]\n",
    "            shape  = shape[:sz]\n",
    "            tensor = sparse.COO(indexs,values,shape.tolist())\n",
    "            start  = start+nnz\n",
    "            sparse_matrix_list.append(tensor)\n",
    "        return sparse_matrix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "L=10\n",
    "idx1     = list(range(2*L))\n",
    "idx2     = [i for i in range(L) for j in range(2)]\n",
    "#mps_unit = sparse.COO([idx1,idx2],np.random.randn(2*L),(2*L,L)).reshape((L,2,L))\n",
    "mps_line = ([sparse.as_coo(np.random.randn(2,L))]+\n",
    "            [sparse.COO([idx1,idx2],np.random.randn(2*L),(2*L,L)).reshape((L,2,L))\n",
    "               for i in range(9)])\n",
    "#mps_line[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_loader= torch.utils.data.DataLoader(dataset=mnist_train, batch_size=1000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test , batch_size=1000, shuffle=False)\n",
    "images,labels = iter(train_loader).next()\n",
    "origin_inputs = preprocess_sum_one(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "L=origin_inputs.shape[0]\n",
    "idx1     = list(range(2*L))\n",
    "idx2     = [i for i in range(L) for j in range(2)]\n",
    "mps_line=[sparse.as_coo(origin_inputs[:,0,:].transpose(1,0).numpy())]\n",
    "for tensor in origin_inputs.permute(1,0,2)[1:]:\n",
    "    #print(tensor.flatten().numpy().shape)\n",
    "    mps_line.append(sparse.COO([idx1,idx2],tensor.flatten().numpy(),(2*L,L)).reshape((L,2,L)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# next_line,z = right_canonicalize_MPS_sparse(mps_line,final_normlization =True,all_renormlization=False)\n",
    "\n",
    "# Decomposition_Engine=lambda x:truncated_SVD_sparse(x,output='QR',\n",
    "#                                                     max_truncation_error=0.00,\n",
    "#                                                     max_singular_values=100,\n",
    "#                                                    )\n",
    "# next_line_2,z_2 = left_canonicalize_MPS_sparse(next_line,final_normlization =True,\n",
    "#                                                all_renormlization=True,\n",
    "#                                                Decomposition_Engine=Decomposition_Engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.67 ms ± 33.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "u,s,v = diagonal_tensor_svd_sparse(sparse_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### diagonal.torch.dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def diagonal_tensor_svd_torch_dense(tensor):\n",
    "    reduce = False\n",
    "    if len(tensor.shape)==2:\n",
    "        tensor = tensor.unsqueeze(0)\n",
    "        reduce = True\n",
    "    W,H   = tensor.shape[-2:]\n",
    "    batch_shape= tensor.shape[:-2]\n",
    "    u = s = v = None\n",
    "    if W>=H:\n",
    "        batch_diag = torch.matmul(tensor.transpose(-1,-2),tensor)#auto broadcast, or can use bmm\n",
    "    else:\n",
    "        batch_diag = torch.matmul(tensor,tensor.transpose(-1,-2))#auto broadcast, or can use bmm\n",
    "    A,A        = batch_diag.shape[-2:]\n",
    "    batch_diag = batch_diag[...,range(A),range(A)]\n",
    "    batch_diag,batch_order= batch_diag.sort(-1,descending=True)\n",
    "    #fast_V      = [get_sort_matrix(order).to_dense() for order in batch_order]\n",
    "    batch_order = batch_order.flatten(start_dim=0,end_dim=-2)\n",
    "    K,A         = batch_order.shape\n",
    "    s           = batch_diag.sqrt()\n",
    "    s           = s.reshape(*batch_shape,A)\n",
    "    if W>=H:\n",
    "        v = torch.sparse_coo_tensor([list(range(K*A)),batch_order.flatten().tolist()], [1.0]*K*A,(K*A,A))\n",
    "        v = v.to_dense().reshape(-1,A,A)\n",
    "        u = torch.bmm(tensor,v.transpose(-1,-2)/s.unsqueeze(-2))\n",
    "        v = v.reshape(*batch_shape,A,A)\n",
    "        u = u.reshape(*batch_shape,W,A)\n",
    "    else:\n",
    "        u = torch.sparse_coo_tensor([list(range(K*A)),batch_order.flatten().tolist()], [1.0]*K*A,(K*A,A))\n",
    "        u = u.to_dense().reshape(-1,A,A).transpose(-1,-2)\n",
    "        v = torch.bmm(u.transpose(-1,-2)/s.unsqueeze(-1),tensor)#TODO: case when s==0\n",
    "        u = u.reshape(*batch_shape,A,A)\n",
    "        v = v.reshape(*batch_shape,A,H)\n",
    "    output = [u,s,v.transpose(-1,-2)]\n",
    "    if reduce:\n",
    "        output = [t[0] for t in output]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8abfe4bc2fdb4e06b505cc3e15235fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# i=0\n",
    "# for images,labels in tqdm(train_loader):\n",
    "#     #images,labels = iter(train_loader).next()\n",
    "#     inputs = preprocess_sum_one(images)\n",
    "#     #inputs= rd_engine(10,50,2)\n",
    "#     inputs= inputs.permute(1,2,0)#(B,num,k)->(num,k,B)\n",
    "#     inputs= torch.diag_embed(inputs)#(num,k,B)->(num,k,B,B)\n",
    "#     inputs= inputs.permute(0,2,1,3)#(num,k,B,B)->(num,B,k,B)\n",
    "#     inputs= [v for v in inputs]\n",
    "#     inputs[0]= torch.diagonal(inputs[0], dim1=0, dim2=-1)#(B,k,B) -> #(k,B)\n",
    "#     DCEngine = lambda x:truncated_SVD(x,output='QR',max_truncation_error=0.00,max_singular_values=100)\n",
    "#     mps_line,Z_list = left_canonicalize_MPS(inputs,Decomposition_Engine=DCEngine,normlization=False)\n",
    "#     state_dict = {}\n",
    "#     state_dict['xdata']=dict([[i,t] for i,t in enumerate(mps_line)])\n",
    "#     state_dict['ydata']=labels\n",
    "#     torch.save(state_dict,f'offline_SVD_data/preprocess_sum_one.cut100/mps_line_{i}.pt')\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use 1/2 sing vals\n"
     ]
    }
   ],
   "source": [
    "Q,R        = Decomposition_Engine(inputs[0])[:2]\n",
    "new_tensor = torch.einsum('ab,bcd->acd',R,inputs[1])\n",
    "shape      = new_tensor.shape\n",
    "a,b,c = shape\n",
    "new_tensor = new_tensor.reshape(a*b,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### diagonal.torch_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# L=10\n",
    "# idx1     = list(range(2*L))\n",
    "# idx2     = [i for i in range(L) for j in range(2)]\n",
    "# #mps_unit = sparse.COO([idx1,idx2],np.random.randn(2*L),(2*L,L)).reshape((L,2,L))\n",
    "# mps_line = ([sparse.as_coo(np.random.randn(2,L))]+\n",
    "#             [sparse.COO([idx1,idx2],np.random.randn(2*L),(2*L,L)).reshape((L,2,L))\n",
    "#                for i in range(9)])\n",
    "# #mps_line[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# L=10\n",
    "# num=1\n",
    "# k=2\n",
    "# origin_inputs = rd_engine(L,num,k)\n",
    "# inputs = origin_inputs.permute(1,2,0)#(B,num,k)->(num,k,B)\n",
    "# inputs = torch.diag_embed(inputs)#(num,k,B)->(num,k,B,B)\n",
    "# inputs = inputs.permute(0,2,1,3)#(num,k,B,B)->(num,B,k,B)\n",
    "# num,B,k,B     = inputs.shape\n",
    "# inputs        = inputs.reshape(num,B*k,B )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch_sparse import coalesce\n",
    "# idx1          = list(range(2*L))\n",
    "# idx2          = [i for i in range(L) for j in range(2)]\n",
    "# index         = torch.tensor([idx1,idx2])\n",
    "# sparse_tensor = torch.sparse_coo_tensor(index, origin_inputs.flatten(), (2*L,L)).coalesce()\n",
    "# sparse_tensor = reshape_sparse_tensor(sparse_tensor,(L,2*L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": [
     0,
     3,
     15,
     26,
     31,
     42,
     74,
     80,
     92,
     124,
     160,
     180,
     191
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def transpose_sparse_tensor(coalesce_sparse_tensor):\n",
    "    return coalesce_sparse_tensor.transpose(1,0).coalesce()\n",
    "\n",
    "def matmul_sparse_tensor(coalesce_sparse_tensor_1,coalesce_sparse_tensor_2):\n",
    "    m,k1   = coalesce_sparse_tensor_1.size()\n",
    "    k2,n   = coalesce_sparse_tensor_2.size()\n",
    "    assert k1==k2\n",
    "    indexA = coalesce_sparse_tensor_1.indices()\n",
    "    valueA = coalesce_sparse_tensor_1.values()\n",
    "    \n",
    "    indexB = coalesce_sparse_tensor_2.indices()\n",
    "    valueB = coalesce_sparse_tensor_2.values()\n",
    "\n",
    "    indexC, valueC = torch_sparse.spspmm(indexA, valueA, indexB, valueB, m, k1, n)\n",
    "    return torch.sparse_coo_tensor(indexC, valueC, (m,n)).coalesce()\n",
    "def reshape_sparse_tensor(coalesce_sparse_tensor,target_shape):\n",
    "    indices = coalesce_sparse_tensor.indices().tolist()\n",
    "    size    = coalesce_sparse_tensor.size()\n",
    "    assert np.prod(size)==np.prod(target_shape)\n",
    "    target_indices = np.stack(np.unravel_index(np.ravel_multi_index(indices,size),target_shape))\n",
    "    target_indices = torch.Tensor(target_indices)\n",
    "    target_indices = target_indices.to(coalesce_sparse_tensor.device)\n",
    "    tensor = torch.sparse_coo_tensor(target_indices, coalesce_sparse_tensor.values(), target_shape).coalesce()\n",
    "    #tensor.to(coalesce_sparse_tensor.device)\n",
    "    return tensor\n",
    "\n",
    "def sparse_diagonal(dense_matrix):\n",
    "    A = len(dense_matrix)\n",
    "    idx = torch.stack([torch.arange(A),torch.arange(A)]).to(dense_matrix.device)\n",
    "    return torch.sparse_coo_tensor(idx,dense_matrix, (A,A)).coalesce()\n",
    "\n",
    "def sparse_take_first(coalesce_sparse_tensor,row_num,axis=0):\n",
    "    size    = list(coalesce_sparse_tensor.shape)\n",
    "    if row_num > size[axis]:return coalesce_sparse_tensor\n",
    "    indexes = coalesce_sparse_tensor.indices()\n",
    "    value   = coalesce_sparse_tensor.values()\n",
    "    good_i=indexes[axis]<row_num\n",
    "    indexes = torch.stack([t[good_i] for t in indexes])\n",
    "    value   = value[good_i]\n",
    "    size[axis] = row_num\n",
    "    return torch.sparse_coo_tensor(indexes,value, size).coalesce().to(coalesce_sparse_tensor.device)\n",
    "\n",
    "def diagonal_tensor_svd_torch_sparse_2D(tensor):\n",
    "    W,H   = tensor.size()\n",
    "    if W>=H:\n",
    "        MstarM     = matmul_sparse_tensor(transpose_sparse_tensor(tensor),tensor)\n",
    "    else:\n",
    "        MstarM     = matmul_sparse_tensor(tensor,transpose_sparse_tensor(tensor))\n",
    "    diagonal_svd_flag = True\n",
    "    a,b = MstarM.indices()\n",
    "    if (a!=b).any():\n",
    "        return None\n",
    "    L,L = MstarM.shape\n",
    "    batch_diag  = torch.Tensor([MstarM[i,i] for i in range(L)]).to(tensor.device)\n",
    "    #batch_diag = MstarM.values()\n",
    "    # in sparse representation, only value > 0 takes.\n",
    "    batch_diag,batch_order = batch_diag.sort(-1,descending=True)\n",
    "    s          = batch_diag.sqrt()\n",
    "    nonzero_num= torch.sum(s>0)\n",
    "    s          = s[:nonzero_num]\n",
    "    A = len(batch_order)\n",
    "    index = torch.stack([torch.arange(A).to(tensor.device),batch_order])\n",
    "    value = torch.ones(A).to(tensor.device)\n",
    "    if W>=H: \n",
    "        v = torch.sparse_coo_tensor(index,value,(A,A)).coalesce()\n",
    "        if nonzero_num < A :v = sparse_take_first(v,nonzero_num,axis=1)\n",
    "        u = matmul_sparse_tensor(tensor,matmul_sparse_tensor(transpose_sparse_tensor(v),sparse_diagonal(1/s)))\n",
    "    else:\n",
    "        u = torch.sparse_coo_tensor(index,value,(A,A)).coalesce()\n",
    "        if nonzero_num < A :u = sparse_take_first(u,nonzero_num,axis=0)\n",
    "        v = matmul_sparse_tensor(matmul_sparse_tensor(sparse_diagonal(1/s),u),tensor)\n",
    "        u = transpose_sparse_tensor(u)\n",
    "    return u,s,v\n",
    "\n",
    "def reciprocal_sparse_tensor(coalesce_sparse_tensor):\n",
    "    size   = coalesce_sparse_tensor.size()\n",
    "    indexA = coalesce_sparse_tensor.indices()\n",
    "    valueA = coalesce_sparse_tensor.values()\n",
    "    return torch.sparse_coo_tensor(indexA, 1/valueA, size).coalesce()\n",
    "\n",
    "def diagonal_tensor_RQ_torch_sparse(tensor):\n",
    "    W,H   = tensor.shape\n",
    "    assert W<=H\n",
    "    MstarM     = matmul_sparse_tensor(tensor,transpose_sparse_tensor(tensor))\n",
    "    a,b = MstarM.indices()\n",
    "    assert (a==b).any()\n",
    "    #batch_diag = MstarM.values()\n",
    "    #s = batch_diag.sqrt()\n",
    "    R = MstarM.sqrt()\n",
    "    Q = matmul_sparse_tensor(reciprocal_sparse_tensor(R),tensor)\n",
    "    return R,Q\n",
    "\n",
    "def right_canonicalize_MPS_torch_sparse(mps_line,Decomposition_Engine=diagonal_tensor_RQ_torch_sparse,\n",
    "                          final_normlization =True,all_renormlization=False\n",
    "                          ):\n",
    "    new_chain = []\n",
    "    R         = None\n",
    "    Z_list    = []\n",
    "    # assume every mps_unit is store (kD,D)\n",
    "    for i,tensor in enumerate(mps_line[::-1]):\n",
    "        if R is not None:\n",
    "            new_tensor = matmul_sparse_tensor(tensor,R)   \n",
    "        else:\n",
    "            new_tensor = tensor\n",
    "        kD,D  = new_tensor.shape\n",
    "        if kD>D:\n",
    "            new_tensor = reshape_sparse_tensor(new_tensor,(D,kD))\n",
    "\n",
    "        if i == len(mps_line) - 1:\n",
    "            if final_normlization:\n",
    "                Z = (new_tensor**2).values().sum().sqrt()\n",
    "                new_tensor /= Z\n",
    "                Z_list.append(Z)\n",
    "            new_chain.append(new_tensor)\n",
    "        else:\n",
    "            if all_renormlization:\n",
    "                Z = (new_tensor**2).values().sum().sqrt()\n",
    "                new_tensor /= Z\n",
    "                Z_list.append(Z)\n",
    "            R,Q = Decomposition_Engine(new_tensor)[:2]\n",
    "            new_chain.append(Q)\n",
    "    new_chain=new_chain[::-1]\n",
    "    return new_chain,Z_list\n",
    "\n",
    "def left_canonicalize_MPS_torch_sparse(mps_line,Decomposition_Engine=None,\n",
    "                          final_normlization =True,all_renormlization=False):\n",
    "    # for any not canonical mps line\n",
    "    # the chain size (D,P,D)\n",
    "    new_chain = []\n",
    "    R         = None\n",
    "    Z_list    = []# record the scale information for each unit.\n",
    "    # assume every mps_unit is store (D,kD)\n",
    "    for i,tensor in enumerate(tqdm(mps_line)):\n",
    "        if R is not None:\n",
    "            D,kD       = tensor.shape\n",
    "            B,D        = R.shape\n",
    "            new_tensor = matmul_sparse_tensor(R,tensor)   \n",
    "            new_shape  = new_tensor.shape\n",
    "            new_tensor = reshape_sparse_tensor(new_tensor,(B*kD//D,D))\n",
    "        else:\n",
    "            new_tensor = tensor        \n",
    "        if i == len(mps_line) - 1:\n",
    "            if final_normlization:\n",
    "                Z = (new_tensor**2).values().sum().sqrt()\n",
    "                new_tensor /= Z\n",
    "                Z_list.append(Z)\n",
    "            new_chain.append(new_tensor)\n",
    "        else:\n",
    "            if all_renormlization:\n",
    "                Z = (new_tensor**2).values().sum().sqrt()\n",
    "                new_tensor /= Z\n",
    "                Z_list.append(Z)\n",
    "            Q,R,_,diagonal_svd_flag = Decomposition_Engine(new_tensor)\n",
    "            new_chain.append(Q)\n",
    "           # print(Q.shape)\n",
    "#         if not diagonal_svd_flag:\n",
    "#             print(f\"full matrix SVD at unit {i}\")\n",
    "\n",
    "    return new_chain,Z_list\n",
    "\n",
    "def truncated_SVD_torch_sparse(tensor,output='RQ',max_singular_values= None,\n",
    "                          max_truncation_error= None,\n",
    "                          relative = True,\n",
    "                          normlized= True,\n",
    "                          verbose  = False):\n",
    "    # the canonocal\n",
    "    # tensor is batched\n",
    "    assert len(tensor.shape)  == 2\n",
    "    diagonal_svd_flag = True\n",
    "    out = diagonal_tensor_svd_torch_sparse_2D(tensor)\n",
    "    if out is None:\n",
    "        diagonal_svd_flag=False\n",
    "        q = min(tensor.size())\n",
    "        q = min(q,max_singular_values) \n",
    "        u, s, v = torch.svd_lowrank(tensor,q=q)\n",
    "        v       = v.T\n",
    "        #print(q,s.shape)\n",
    "    else:\n",
    "        u, s, v = out\n",
    "        max_singular_values = s.shape[-1] if max_singular_values is None else max_singular_values\n",
    "        if max_truncation_error is not None and len(s)>max_singular_values:\n",
    "            # Cumulative norms of singular values in ascending order\n",
    "            s_normlized  = s**2\n",
    "            s_normlized /= torch.sum(s_normlized)\n",
    "            s_sorted,_   = torch.sort(s_normlized)# 0.1,0.2,...,0.4\n",
    "            trunc_errs   = torch.sqrt(torch.cumsum(s_sorted,0))# 0.1,0.3,....1\n",
    "            # If relative is true, rescale max_truncation error with the largest\n",
    "            # singular value to yield the absolute maximal truncation error.\n",
    "            num_sing_vals_err = torch.sum(trunc_errs > max_truncation_error)\n",
    "            if max_singular_values>num_sing_vals_err and verbose:\n",
    "                print(f\"use {num_sing_vals_err}/{max_singular_values} sing vals\")\n",
    "        else:\n",
    "            num_sing_vals_err  = max_singular_values\n",
    "\n",
    "        nk = min(max_singular_values, num_sing_vals_err)\n",
    "\n",
    "\n",
    "        #s_rest = s[...,num_sing_vals_keep:]\n",
    "\n",
    "        u  = sparse_take_first(u,nk,axis=1) if u.is_sparse else u[...,:nk]\n",
    "        s  = s[...,:nk]\n",
    "        v  = sparse_take_first(v,nk,axis=0) if v.is_sparse else v[:nk,:]\n",
    "    Z  = None #maybe add in the furture\n",
    "    if output == 'RQ':\n",
    "        R = u*s[None] if not u.is_sparse else matmul_sparse_tensor(u,sparse_diagonal(s))\n",
    "        Q = v\n",
    "        if not R.is_sparse:R = R.to_sparse() \n",
    "        if not Q.is_sparse:Q = Q.to_sparse() \n",
    "        output = [R,Q,Z,diagonal_svd_flag]\n",
    "    elif output == 'QR':\n",
    "        Q = u\n",
    "        R = s[:,None]*v if not  v.is_sparse else matmul_sparse_tensor(sparse_diagonal(s),v)\n",
    "        if not R.is_sparse:R = R.to_sparse()\n",
    "        if not Q.is_sparse:Q = Q.to_sparse()\n",
    "        output = [Q,R,Z,diagonal_svd_flag]\n",
    "    else:\n",
    "        if not u.is_sparse:u = u.to_sparse() \n",
    "        if not v.is_sparse:v = v.to_sparse() \n",
    "        output = [u,s,v,Z,diagonal_svd_flag]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_loader= torch.utils.data.DataLoader(dataset=mnist_train, batch_size=1000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test , batch_size=1000, shuffle=False)\n",
    "images,labels = iter(train_loader).next()\n",
    "origin_inputs = preprocess_sum_one(images)\n",
    "\n",
    "L=origin_inputs.shape[0]\n",
    "idx1          = list(range(2*L))\n",
    "idx2          = [i for i in range(L) for j in range(2)]\n",
    "index         = torch.tensor([idx1,idx2])\n",
    "mps_line=[(origin_inputs[:,0,:].transpose(1,0)).to_sparse()]\n",
    "for tensor in origin_inputs.permute(1,0,2)[1:]:\n",
    "    sparse_tensor = torch.sparse_coo_tensor(index, tensor.flatten(), (2*L,L)).coalesce()      \n",
    "    #sparse_tensor = reshape_sparse_tensor(sparse_tensor,(L,2*L))                              \n",
    "    mps_line.append(sparse_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mps_line=[t.cuda() for t in mps_line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mps_line,Z = right_canonicalize_MPS_torch_sparse(mps_line,final_normlization =True,all_renormlization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860f1c30906e46208b3c22b98cd2c437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/784 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Decomposition_Engine=lambda x:truncated_SVD_torch_sparse(x,output='QR',\n",
    "                                                        max_truncation_error=0.00,\n",
    "                                                        max_singular_values=1,\n",
    "                                                       )\n",
    "mps_line2,z_2 = left_canonicalize_MPS_torch_sparse(mps_line,final_normlization =True,\n",
    "                                               all_renormlization=True,\n",
    "                                               Decomposition_Engine=Decomposition_Engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### torch_sparse MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_sparse\n",
    "import numpy as np\n",
    "from utils import *\n",
    "\n",
    "def rd_engine(*x,**kargs):\n",
    "    x =  torch.randn(*x,device='cpu',**kargs)\n",
    "    x/=  torch.norm(x).sqrt()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "mnist_data = np.load('archive/tn-for-unsup-ml/data/binarized_mnist.npz')\n",
    "train_data = torch.from_numpy(mnist_data['train_data'])\n",
    "test_data  = torch.from_numpy(mnist_data['test_data'])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=(0.0,), std=(1.0,))\n",
    "])\n",
    "DATAPATH    = '/media/tianning/DATA/DATASET/MNIST/'\n",
    "mnist_train = datasets.MNIST(DATAPATH, train=True, download=False, transform=transform)\n",
    "mnist_test  = datasets.MNIST(DATAPATH, train=False,download=False, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_loader= torch.utils.data.DataLoader(dataset=mnist_train, batch_size=1000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test , batch_size=1000, shuffle=False)\n",
    "images,labels = iter(train_loader).next()\n",
    "origin_inputs = preprocess_sum_one(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 784, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "device='cpu'\n",
    "L=origin_inputs.shape[0]\n",
    "idx1  = [0]*L+[1]*L\n",
    "idx2  = [(L+1)*i for i in range(L)]\n",
    "idx2  = idx2 + idx2\n",
    "index = torch.tensor([idx2,idx1])\n",
    "input_mps=[(origin_inputs[:,0,:]).to_sparse().to(device)]\n",
    "for tensor in origin_inputs.permute(1,0,2)[1:]:\n",
    "    sparse_tensor = torch.sparse_coo_tensor(index, tensor.flatten(), (L*L,2)).coalesce()      \n",
    "    #sparse_tensor = reshape_sparse_tensor(sparse_tensor,(L,2*L))                              \n",
    "    input_mps.append(sparse_tensor.to(device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# left_tensors = [torch.einsum('cpd,apb->acbd', input_data[i]  ,self.mps_var[i]).flatten(0,1).flatten(-2,-1) for i in range(self.hn)]\n",
    "# rigt_tensors = [torch.einsum('cpd,apb->acbd', input_data[i-1]  ,self.mps_var[i]).flatten(0,1).flatten(-2,-1) for i in range(self.hn+1,len(self.mps_var))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D=2\n",
    "P=2\n",
    "L=14\n",
    "B=3\n",
    "inputs = rd_engine(B,L,P)    \n",
    "# inputs = inputs.permute(1,2,0)#(B,num,k)->(num,k,B)\n",
    "# inputs = torch.diag_embed(inputs)#(num,k,B)->(num,k,B,B)\n",
    "# inputs = inputs.flatten(-2,-1)\n",
    "#inputs = inputs.permute(0,2,1,3)#(num,k,B,B)->(num,B,k,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "B=inputs.shape[0]\n",
    "idx1  = [0]*B+[1]*B\n",
    "idx2  = [(B+1)*i for i in range(B)]\n",
    "idx2  = idx2 + idx2\n",
    "index = torch.tensor([idx2,idx1])\n",
    "input_mps=[(inputs[:,0,:]).to_sparse()]\n",
    "for tensor in inputs.permute(1,0,2)[1:]:\n",
    "    sparse_tensor = torch.sparse_coo_tensor(index, tensor.flatten(), (B*B,2)).coalesce()      \n",
    "    #sparse_tensor = reshape_sparse_tensor(sparse_tensor,(L,2*L))                              \n",
    "    input_mps.append(sparse_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def rd_engine(*x,**kargs):\n",
    "    x =  torch.randn(*x,device='cpu',**kargs)\n",
    "    x/=  torch.norm(x).sqrt()\n",
    "    return x\n",
    "Ds  = [1]+list(np.random.randint(3,10,L-1))+[1]\n",
    "mps_var    = [rd_engine(Ds[i],P,Ds[i+1]) for i in range(L)]  \n",
    "print(Ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 4, 9, 6, 4, 6, 6, 3, 6, 5, 6, 6, 3, 1]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out=[]\n",
    "for inp,mps_unit in zip(input_mps,mps_var):\n",
    "    out.append(torch.sparse.mm(inp,mps_unit.permute(1,0,2).flatten(1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 2])\n"
     ]
    }
   ],
   "source": [
    "idx=4\n",
    "print(input_mps[idx].shape)\n",
    "D1,P,D2=mps_var[idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_values= input_mps[idx].values().reshape(B,P)@mps_var[idx].permute(1,0,2).flatten(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 24])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0746, -0.0109,  0.0053,  0.0967,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0675, -0.0708,  0.1573, -0.1155,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0360,  0.2245,  0.0516,  0.1981,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.2776, -0.2080, -0.0120,  0.1236,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.1618,  0.0482,  0.0096, -0.0264,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.1465, -0.1226, -0.1381,  0.1770,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.1027, -0.0411, -0.0813,  0.1604,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.1903, -0.0082,  0.2638, -0.0855,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0499,  0.3243,  0.0474,  0.2284,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.4458, -0.2313, -0.0468,  0.2555,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.2578,  0.0307,  0.0229, -0.0274,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.1947, -0.2375, -0.2380,  0.2213,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.0436,  0.0053, -0.0069, -0.0554],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.0353,  0.0452, -0.0900,  0.0707],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0254, -0.1306, -0.0312, -0.1177],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.1596,  0.1240,  0.0057, -0.0686],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.0931, -0.0297, -0.0052,  0.0158],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.0860,  0.0687,  0.0787, -0.1045]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.block_diag(*all_values.reshape(B,D1,D2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "LDLD=out[idx].reshape(B,B,Ds[idx],Ds[idx+1]).permute(0,2,1,3).flatten(0,1).flatten(-2,-1).to_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 12])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDLD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.075 -0.011  0.005  0.097  0.     0.     0.     0.     0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.067 -0.071  0.157 -0.115  0.     0.     0.     0.     0.     0.\n",
      "   0.     0.   ]\n",
      " [-0.036  0.225  0.052  0.198  0.     0.     0.     0.     0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.278 -0.208 -0.012  0.124  0.     0.     0.     0.     0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.162  0.048  0.01  -0.026  0.     0.     0.     0.     0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.146 -0.123 -0.138  0.177  0.     0.     0.     0.     0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.     0.     0.     0.     0.103 -0.041 -0.081  0.16   0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.     0.     0.     0.     0.19  -0.008  0.264 -0.086  0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.     0.     0.     0.     0.05   0.324  0.047  0.228  0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.     0.     0.     0.     0.446 -0.231 -0.047  0.256  0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.     0.     0.     0.     0.258  0.031  0.023 -0.027  0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.     0.     0.     0.     0.195 -0.238 -0.238  0.221  0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.    -0.044  0.005\n",
      "  -0.007 -0.055]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.    -0.035  0.045\n",
      "  -0.09   0.071]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.025 -0.131\n",
      "  -0.031 -0.118]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.    -0.16   0.124\n",
      "   0.006 -0.069]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.    -0.093 -0.03\n",
      "  -0.005  0.016]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.    -0.086  0.069\n",
      "   0.079 -0.104]]\n"
     ]
    }
   ],
   "source": [
    "print(LDLD.to_dense().numpy().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###### test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "the max singular value truncation only good for hundreds dimenstion, for small dimenstion not good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "FiniteMPS canonicalize == right_canonicalize_MPS with torchrq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensornetwork.matrixproductstates.finite_mps import FiniteMPS\n",
    "from tensornetwork.matrixproductstates.infinite_mps import InfiniteMPS\n",
    "from typing import Any, List, Optional, Text, Type, Union, Dict, Sequence\n",
    "import numpy as np\n",
    "Tensor = Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# D=6\n",
    "# P=4\n",
    "# L=5\n",
    "# mps_line = [torch.randn(1,P,D)] + [torch.randn(D,P,D) for i in range(L-2)]+ [torch.randn(D,P,1)]\n",
    "# input_mps= [torch.randn(P,D)] + [torch.randn(D,P,D) for i in range(L-2)]+ [torch.randn(D,P)]\n",
    "# approx = approxmate_mps_line(mps_line,max_singular_values=2)\n",
    "# #contract_two_mps(approx,input_mps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tn.set_default_backend(\"pytorch\")\n",
    "# tn_mps_1 = FiniteMPS(mps_line,canonicalize=False)\n",
    "# tn_mps_1.canonicalize(normalize=False)\n",
    "# tn_mps_1.center_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensornetwork as tn\n",
    "from tensornetwork import contractors\n",
    "tn.set_default_backend(\"pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     3
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D=10\n",
    "P=4\n",
    "L=14\n",
    "def rd_engine(*x,**kargs):\n",
    "    x =  torch.randn(*x,device='cpu',**kargs)\n",
    "    x/=  torch.norm(x).sqrt()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": [
     1,
     36
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensornetwork.contractors.opt_einsum_paths.path_contractors import *\n",
    "def my_contracter(nodes: Iterable[AbstractNode],\n",
    "         path = None,\n",
    "         output_edge_order: Optional[Sequence[Edge]] = None,\n",
    "         ignore_edge_order: bool = False,\n",
    "         memory_limit: Optional[int] = None) -> AbstractNode:\n",
    "        \"\"\"Base method for all `opt_einsum` contractors.\n",
    "\n",
    "        Args:\n",
    "        nodes: A collection of connected nodes.\n",
    "        algorithm: `opt_einsum` contraction method to use.\n",
    "        output_edge_order: An optional list of edges. Edges of the\n",
    "        final node in `nodes_set`\n",
    "        are reordered into `output_edge_order`;\n",
    "        if final node has more than one edge,\n",
    "        `output_edge_order` must be provided.\n",
    "        ignore_edge_order: An option to ignore the output edge\n",
    "        order.\n",
    "\n",
    "        Returns:\n",
    "        Final node after full contraction.\n",
    "        \"\"\"\n",
    "        nodes_set = set(nodes)\n",
    "        edges = get_all_edges(nodes_set)\n",
    "        #output edge order has to be determinded before any contraction\n",
    "        #(edges are refreshed after contractions)\n",
    "\n",
    "        if not ignore_edge_order:\n",
    "            if output_edge_order is None:\n",
    "                output_edge_order = list(get_subgraph_dangling(nodes))\n",
    "                if len(output_edge_order) > 1:\n",
    "                    raise ValueError(\"The final node after contraction has more than \"\n",
    "                                 \"one remaining edge. In this case `output_edge_order` \"\n",
    "                                 \"has to be provided.\")\n",
    "\n",
    "            if set(output_edge_order) != get_subgraph_dangling(nodes):\n",
    "                raise ValueError(\"output edges are not equal to the remaining \"\n",
    "                       \"non-contracted edges of the final node.\")\n",
    "\n",
    "        for edge in edges:\n",
    "            if not edge.is_disabled:  #if its disabled we already contracted it\n",
    "                if edge.is_trace():\n",
    "                    nodes_set.remove(edge.node1)\n",
    "                    nodes_set.add(contract_parallel(edge))\n",
    "\n",
    "        if len(nodes_set) == 1:\n",
    "            # There's nothing to contract.\n",
    "            if ignore_edge_order:\n",
    "                return list(nodes_set)[0]\n",
    "            return list(nodes_set)[0].reorder_edges(output_edge_order)\n",
    "\n",
    "        if path is None:\n",
    "            algorithm = functools.partial(opt_einsum.paths.greedy, memory_limit=memory_limit)\n",
    "            # Then apply `opt_einsum`'s algorithm\n",
    "            path, nodes = utils.get_path(nodes_set, algorithm)\n",
    "        else:\n",
    "            nodes = list(nodes_set) \n",
    "        for a, b in path:\n",
    "            new_node = contract_between(nodes[a], nodes[b], allow_outer_product=True)\n",
    "            nodes.append(new_node)\n",
    "            nodes = utils.multi_remove(nodes, [a, b])\n",
    "\n",
    "        # if the final node has more than one edge,\n",
    "        # output_edge_order has to be specified\n",
    "        final_node = nodes[0]  # nodes were connected, we checked this\n",
    "        if not ignore_edge_order:\n",
    "            final_node.reorder_edges(output_edge_order)\n",
    "        return final_node,path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D=10;O=10;mps_core = [rd_engine(P,D)] + [rd_engine(D,P,D) for _ in range(L-1)] + [rd_engine(D,O,D)]+ [rd_engine(D,P)]\n",
    "B=20;inp_line = [rd_engine(B,P)] + [rd_engine(B,P,B) for _ in range(L-1)] + [rd_engine(B,P,B)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7, 18), (12, 28), (10, 27), (14, 17), (25, 26), (0, 25), (21, 24), (20, 23), (19, 22), (5, 21), (1, 20), (1, 19), (1, 18), (8, 17), (11, 16), (12, 15), (5, 14), (4, 13), (7, 12), (7, 11), (8, 10), (4, 9), (0, 8), (2, 7), (1, 6), (0, 5), (0, 4), (0, 3), (0, 2), (0, 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4304e-01, -1.5820e-01, -1.3586e-02, -9.4462e-04, -1.3982e-01,\n",
       "          9.9057e-02,  1.7996e-01, -1.1456e-01,  1.4263e-01, -2.4580e-03],\n",
       "        [ 3.4687e-01, -4.8310e-01,  2.2043e-01, -2.1364e-01,  4.1445e-01,\n",
       "         -2.5674e-01,  1.4035e-01,  2.4091e-01, -2.3025e-01, -1.1829e-01],\n",
       "        [ 2.0311e-01, -8.6519e-02,  3.1690e-01,  2.3554e-01,  1.1007e-02,\n",
       "         -4.1188e-01,  4.2258e-02,  3.6463e-01, -3.4286e-01, -4.0262e-01],\n",
       "        [-4.7547e-01,  3.7831e-01,  3.3061e-02,  2.4604e-01, -1.5482e-01,\n",
       "         -4.6528e-02,  4.5324e-03, -4.0088e-01,  3.5013e-01,  8.5555e-02],\n",
       "        [ 9.9050e-02, -8.2526e-02,  1.8456e-01, -1.9140e-02,  1.1645e-01,\n",
       "         -3.5684e-01, -2.0432e-01,  1.1110e-01,  9.2640e-02, -1.0480e-01],\n",
       "        [ 1.6438e-01,  2.7121e-01, -3.3816e-02, -4.1494e-03,  1.2835e-01,\n",
       "          1.2292e-01,  8.6925e-02,  3.1019e-01,  3.8543e-01,  1.7188e-01],\n",
       "        [-5.1561e-02,  1.1307e-01, -5.6854e-01,  1.4294e-01, -2.3753e-01,\n",
       "          2.2774e-01,  3.7236e-01, -3.5108e-01,  1.8630e-01,  3.9439e-02],\n",
       "        [ 5.2912e-02,  2.5094e-01, -1.9803e-01,  4.7044e-03, -1.8587e-01,\n",
       "          4.2176e-01,  1.8772e-01,  3.0565e-01,  1.2801e-01,  1.9867e-01],\n",
       "        [ 1.1517e-01,  1.0643e-01,  1.5878e-01,  5.5360e-02, -1.3950e-01,\n",
       "          5.1184e-02,  8.2136e-02, -2.4243e-01, -8.4872e-02,  1.3361e-02],\n",
       "        [ 1.4793e-01, -1.5811e-01,  5.4551e-05, -8.3154e-02, -2.5979e-01,\n",
       "         -1.9083e-01, -1.5844e-01,  1.5925e-01,  1.1895e-01,  2.1983e-02],\n",
       "        [-3.0817e-01,  2.3907e-01, -1.7756e-01,  2.8272e-01,  1.4382e-01,\n",
       "          5.0498e-01,  4.2695e-01,  3.0219e-01, -2.6779e-01, -1.2777e-01],\n",
       "        [-3.8576e-02,  9.5788e-03,  8.3571e-02, -7.7039e-02,  3.6145e-03,\n",
       "          1.6885e-01,  1.5983e-01, -2.3978e-01, -2.0942e-01,  9.6214e-02],\n",
       "        [ 4.0893e-03, -3.6139e-01,  4.0647e-01, -2.6646e-01,  1.9695e-01,\n",
       "         -1.0266e-01,  1.9087e-01,  5.0853e-01, -3.8624e-02,  1.8222e-04],\n",
       "        [-2.9511e-02,  3.1189e-01,  2.4094e-01,  1.7423e-01, -2.5471e-01,\n",
       "         -8.0931e-02, -3.8496e-02, -1.2300e-02,  6.1083e-02, -6.5881e-02],\n",
       "        [-2.3669e-01, -3.0595e-01, -1.7096e-01,  1.4025e-02,  1.4744e-01,\n",
       "         -3.6415e-02, -1.7377e-01,  2.5554e-01, -1.3301e-01, -8.9086e-02],\n",
       "        [ 1.0746e-01, -8.4043e-02,  8.2953e-02,  1.8575e-01, -1.6408e-01,\n",
       "          1.5920e-01, -7.5862e-02, -2.0506e-01, -3.0581e-01, -7.0687e-02],\n",
       "        [-8.5354e-02,  2.5426e-01,  1.8748e-01,  8.1318e-02, -2.2259e-01,\n",
       "          4.7392e-02, -3.1515e-01,  1.3632e-01, -1.4565e-01, -2.7911e-01],\n",
       "        [ 1.8653e-01, -1.3372e-01,  4.8352e-02, -1.3855e-01, -1.6892e-01,\n",
       "          2.6170e-01,  1.0761e-01, -6.7705e-02, -4.6117e-02,  1.2726e-01],\n",
       "        [-2.1083e-01, -3.7951e-02, -1.1342e-01,  4.1334e-02, -6.1075e-03,\n",
       "          2.7614e-01,  7.5191e-03, -2.2903e-01, -8.9833e-02,  2.0455e-01],\n",
       "        [ 7.3030e-02,  2.0093e-01, -2.6945e-01,  1.6580e-01, -2.3946e-02,\n",
       "          1.6530e-01, -1.5978e-01, -1.2399e-01,  1.9520e-02, -1.6731e-02]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mps_nodes  = [tn.Node(v, name=f\"t{i}\") for i,v in enumerate(mps_core)]\n",
    "for i in range(len(mps_core)-1):\n",
    "    tn.connect(mps_nodes[i][-1],mps_nodes[i+1][0],name=f\"mps:{i}<->{i+1}\")\n",
    "inp_nodes=[tn.Node(v, name=f\"i{i}\") for i,v in enumerate(inp_line)]\n",
    "tn.connect(inp_nodes[0][0],inp_nodes[1][0],name=f\"inp:{0}<->{1}\")\n",
    "for i in range(1,len(inp_nodes)-1):\n",
    "    tn.connect(inp_nodes[i][-1],inp_nodes[i+1][0],name=f\"inp:{i}<->{i+1}\")\n",
    "for i,input_node in enumerate(inp_nodes):\n",
    "    j = i if i < L else i+1\n",
    "    mps_physicd_edge = mps_nodes[j][0] if j==0 else mps_nodes[j][1]\n",
    "    inp_physics_edge = input_node[1]\n",
    "    tn.connect(mps_physicd_edge,inp_physics_edge,name=f\"phy_{i}\")\n",
    "ans,path = my_contracter(mps_nodes+inp_nodes,\n",
    "                       output_edge_order=[inp_nodes[-1][2],mps_nodes[L][1]])\n",
    "ans.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_mps_list    = [rd_engine(P,D)] + [rd_engine(L-2,D,P,D)]  + [rd_engine(D,P)]\n",
    "middle_mpo_list =[[rd_engine(P,D,P)]+[rd_engine(L-2,D,P,D,P)]+ [rd_engine(D,P,P)]\n",
    "                  for _ in range(L-2)]\n",
    "bottom_mps_list = [rd_engine(P,D)] + [rd_engine(L-2,D,P,D)]  + [rd_engine(D,P)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D=2000\n",
    "P=4\n",
    "L=14\n",
    "top_mps_list = [rd_engine(P,D)] + [rd_engine(L-2,D,P,D)]  + [rd_engine(D,P)]\n",
    "top_mps_list = right_mps_form(top_mps_list)\n",
    "bottom_mps_list= [0.005*torch.randn_like(a)+a for a in top_mps_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bottom_mps_list,Zb = left_canonicalize_MPS(right_mps_form(bottom_mps_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0166)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contract_two_mps(bottom_mps_list,top_mps_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   left canonical scalar:0.09317030757665634\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 0.999, 0.942, 0.938, 0.958, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.8452922105789185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0118)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mps_list, scalar = approxmate_mps_line(top_mps_list,max_singular_values=1000)\n",
    "contract_two_mps(bottom_mps_list,new_mps_list)*scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:0/12 (4, 6) - 12x(6, 4, 6) - (6, 4)\n",
      "start:1/12 \n",
      "get mps (4, 36) - 12x(36, 4, 36) - (36, 4)\n",
      "boundary contraction cost:0.0013422966003417969\n",
      "   left canonical scalar:3.0327204513014294e-05\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:1.0\n",
      "low rank approximation cost:0.11043429374694824 scalar:3.0327204513014294e-05\n",
      "==========================================\n",
      "start:2/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0018436908721923828\n",
      "   left canonical scalar:0.000614150136243552\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:1.0000004768371582\n",
      "low rank approximation cost:0.23517894744873047 scalar:0.0006141504272818565\n",
      "==========================================\n",
      "start:3/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1296)-(1296, 4, 1296)-(1296, 4, 1296)-(1296, 4, 1296)-(1296, 4, 1296)-(1296, 4, 1296)-(1296, 4, 1296)-(1296, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0022668838500976562\n",
      "   left canonical scalar:0.000502652779687196\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.999, 0.998, 0.999, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.9966887831687927\n",
      "low rank approximation cost:1.6759274005889893 scalar:0.0005009883898310363\n",
      "==========================================\n",
      "start:4/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0043697357177734375\n",
      "   left canonical scalar:0.0005132302176207304\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923, 0.91, 0.963, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.808193027973175\n",
      "low rank approximation cost:14.75801420211792 scalar:0.00041478907223790884\n",
      "==========================================\n",
      "start:5/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0012714862823486328\n",
      "   left canonical scalar:0.0005140540306456387\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.906, 0.887, 0.956, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.7686819434165955\n",
      "low rank approximation cost:14.943126678466797 scalar:0.0003951440448872745\n",
      "==========================================\n",
      "start:6/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0012161731719970703\n",
      "   left canonical scalar:0.000582900014705956\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.915, 0.888, 0.958, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.777186393737793\n",
      "low rank approximation cost:14.729921102523804 scalar:0.0004530219594016671\n",
      "==========================================\n",
      "start:7/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0012156963348388672\n",
      "   left canonical scalar:0.0005581201403401792\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.915, 0.88, 0.949, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.7637606859207153\n",
      "low rank approximation cost:14.766213178634644 scalar:0.00042627021321095526\n",
      "==========================================\n",
      "start:8/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.001264333724975586\n",
      "   left canonical scalar:0.0005442900583148003\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.911, 0.876, 0.946, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.7541176080703735\n",
      "low rank approximation cost:14.809579372406006 scalar:0.00041045871330425143\n",
      "==========================================\n",
      "start:9/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0011568069458007812\n",
      "   left canonical scalar:0.0005957805551588535\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 0.878, 0.948, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.7570173740386963\n",
      "low rank approximation cost:14.73672342300415 scalar:0.00045101623982191086\n",
      "==========================================\n",
      "start:10/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0012233257293701172\n",
      "   left canonical scalar:0.0006513702101074159\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 0.881, 0.951, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.7616574168205261\n",
      "low rank approximation cost:14.767654418945312 scalar:0.0004961209488101304\n",
      "==========================================\n",
      "start:11/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0015985965728759766\n",
      "   left canonical scalar:0.0004802705952897668\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 0.999, 0.905, 0.879, 0.949, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.7546309232711792\n",
      "low rank approximation cost:14.78076958656311 scalar:0.0003624270320869982\n",
      "==========================================\n",
      "start:12/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0012969970703125\n",
      "   left canonical scalar:0.0005720893968828022\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.912, 0.88, 0.947, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.7601038813591003\n",
      "low rank approximation cost:14.883152484893799 scalar:0.0004348473739810288\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "now_mps_list = bottom_mps_list\n",
    "print(f\"start:0/{len(middle_mpo_list)} {get_mps_size_list(now_mps_list)}\")\n",
    "for i,next_mpo in enumerate(middle_mpo_list):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    now_mps_list = contract_mps_mpo(now_mps_list,next_mpo)\n",
    "    print(f\"start:{i+1}/{len(middle_mpo_list)} \")\n",
    "    print(f\"get mps {get_mps_size_list(now_mps_list)}\")\n",
    "    cost       = time.time() - start_time\n",
    "    print(f\"boundary contraction cost:{cost}\")\n",
    "    if now_mps_list[0].shape[-1]>1:\n",
    "        start_time = time.time()\n",
    "        now_mps_list,scalar = approxmate_mps_line(right_mps_form(now_mps_list),\n",
    "                                                  max_singular_values= 1000,\n",
    "                                                  mode='full',\n",
    "                                                 # mode='right' if i>3 else 'full'\n",
    "                                                 )\n",
    "        #now_mps_list = [now_mps_list[0],torch.stack(now_mps_list[1:-1],dim=0),now_mps_list[-1]]\n",
    "        cost       = time.time() - start_time\n",
    "        print(f\"low rank approximation cost:{cost} scalar:{scalar}\")\n",
    "        print(\"==========================================\")\n",
    "#     start_time = time.time()\n",
    "#     value      = contract_two_mps(now_mps_list,top_mps_list)\n",
    "#     cost       = time.time() - start_time\n",
    "#     print(f\"col contraction cost:{cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:0/10 (4, 36) - 10x(36, 4, 36) - (36, 4)\n",
      "boundary contraction cost:0.0007288455963134766\n",
      "low rank approximation cost:0.010253667831420898 scalar:5.410343841081405e-23\n",
      "start:1/10 (4, 24)-(24, 4, 96)-(96, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0014865398406982422\n",
      "low rank approximation cost:0.038602352142333984 scalar:1.2635199960961407e-13\n",
      "start:2/10 (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1296)-(1296, 4, 1296)-(1296, 4, 1296)-(1296, 4, 1296)-(1296, 4, 1296)-(1296, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.03164219856262207\n",
      "low rank approximation cost:0.9437947273254395 scalar:1.3323970424988897e-13\n",
      "start:3/10 (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.4210662841796875\n",
      "low rank approximation cost:16.94850254058838 scalar:1.2046462453368452e-13\n",
      "start:4/10 (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.42435622215270996\n",
      "low rank approximation cost:16.967477798461914 scalar:1.1561990114818506e-13\n",
      "start:5/10 (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.4237658977508545\n",
      "low rank approximation cost:16.9342782497406 scalar:1.2458078908988426e-13\n",
      "start:6/10 (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.42182374000549316\n",
      "low rank approximation cost:16.97764825820923 scalar:1.2171254678217144e-13\n",
      "start:7/10 (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.4213716983795166\n",
      "low rank approximation cost:17.01645064353943 scalar:1.169041377770211e-13\n",
      "start:8/10 (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.42140722274780273\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-c84427f25f0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnow_mps_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mnow_mps_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscalar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapproxmate_mps_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_mps_form\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnow_mps_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_singular_values\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m#now_mps_list = [now_mps_list[0],torch.stack(now_mps_list[1:-1],dim=0),now_mps_list[-1]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcost\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-ab53d8dcd2bf>\u001b[0m in \u001b[0;36mapproxmate_mps_line\u001b[0;34m(mps_line, max_singular_values, max_truncation_error, relative)\u001b[0m\n\u001b[1;32m    119\u001b[0m                        ):\n\u001b[1;32m    120\u001b[0m     \u001b[0mscalar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mmps_line\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft_canonicalize_MPS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmps_line\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDecomposition_Engine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     SVD_Engine = lambda x:truncated_SVD(x,max_singular_values = max_singular_values,\n\u001b[1;32m    123\u001b[0m                                           \u001b[0mmax_truncation_error\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmax_truncation_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-ab53d8dcd2bf>\u001b[0m in \u001b[0;36mleft_canonicalize_MPS\u001b[0;34m(mps_line, Decomposition_Engine, normlization)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mnew_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecomposition_Engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mQ\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mnew_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "now_mps_list = bottom_mps_list\n",
    "for i,next_mpo in enumerate(middle_mpo_list):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    now_mps_list = contract_mps_mpo(now_mps_list,next_mpo)\n",
    "    print(f\"start:{i}/{len(middle_mpo_list)} {get_mps_size_list(now_mps_list)}\")\n",
    "    cost       = time.time() - start_time\n",
    "    print(f\"boundary contraction cost:{cost}\")\n",
    "    if now_mps_list[0].shape[-1]>1:\n",
    "        start_time = time.time()\n",
    "        now_mps_list,scalar = approxmate_mps_line(right_mps_form(now_mps_list),max_singular_values= 1000)\n",
    "        #now_mps_list = [now_mps_list[0],torch.stack(now_mps_list[1:-1],dim=0),now_mps_list[-1]]\n",
    "        cost       = time.time() - start_time\n",
    "        print(f\"low rank approximation cost:{cost} scalar:{scalar}\")\n",
    "#     start_time = time.time()\n",
    "#     value      = contract_two_mps(now_mps_list,top_mps_list)\n",
    "#     cost       = time.time() - start_time\n",
    "#     print(f\"col contraction cost:{cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([4, 4, 16]),\n",
       " torch.Size([16, 4, 64]),\n",
       " torch.Size([64, 4, 256]),\n",
       " torch.Size([256, 4, 64]),\n",
       " torch.Size([64, 4, 16]),\n",
       " torch.Size([16, 4, 4])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t.shape for t in now_mps_list[1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def contraction_row(tensor1,tensor2,truncate=None,einsum_engin=einsum_engin):\n",
    "    # tensor1 <-> tensor2 :-> tensor\n",
    "    # (N,H,a,b,c,d) <-> (N,H,c,e,f,g) :-> (N,H,a,be,f,dg)\n",
    "    tensor  = einsum_engin(\"whabcd,whcefg->whabefdg\",tensor1,tensor2).flatten(3,4).flatten(-2,-1)\n",
    "    if truncate is None:return tensor \n",
    "    W,H = tensor.shape[:2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def RecursionBMPS(tensor,truncate=None,einsum_engin=torch.einsum):\n",
    "    W,H = tensor.shape[:2]\n",
    "    while W > 1:\n",
    "            half_size = size // 2\n",
    "            nice_size = 2 * half_size\n",
    "            leftover  = tensor[nice_size:]\n",
    "            tensor    = contraction_line(tensor[0:nice_size:2], tensor[1:nice_size:2],truncate=None,einsum_engin=einsum_engin)\n",
    "            #tensor    = torch.einsum(\"mbik,mbkj->mbij\",tensor[0:nice_size:2], tensor[1:nice_size:2])\n",
    "            #(k/2,NB,D,D),(k/2,NB,D,D) <-> (k/2,NB,D,D)\n",
    "            tensor   = torch.cat([tensor, leftover], axis=0)\n",
    "            size     = half_size + int(size % 2 == 1)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class PEPSLinear(nn.Module):\n",
    "    '''\n",
    "     MPSLinear(in_features: int, out_features: int, W:int,H:int\n",
    "               in_physics_bond: int, out_physics_bond: int, virtual_bond_dim:int,\n",
    "                            bias: bool = True, label_position: int or str):\n",
    "        input  (Batch, in_features , W, H,  in_physics_bond)\n",
    "        output (Batch, out_features,        out_physics_bond)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, in_features,out_features,\n",
    "                       in_physics_bond = 2, out_physics_bond=1, virtual_bond_dim=2,\n",
    "                       bias=True,label_position='center',init_std=1e-10):\n",
    "        super(MPSLinear, self).__init__()\n",
    "        if label_position is 'center':label_position = in_features//2\n",
    "        assert type(label_position) is int\n",
    "        self.in_features   = in_features\n",
    "        self.out_features  = out_features\n",
    "        self.W             = W \n",
    "        self.H             = H\n",
    "        self.vbd           = virtual_bond_dim\n",
    "        self.ipb           = in_physics_bond\n",
    "        self.opb           = out_physics_bond\n",
    "\n",
    "        self.hn            = label_position\n",
    "        left_num           = self.hn\n",
    "        right_num          = in_features - left_num\n",
    "\n",
    "        bias_mat = torch.einsum(\"ij,kl->ijkl\",torch.eye(2),torch.eye(2)).unsqueeze(-1).repeat(1,1,1,1,self.ipb)\n",
    "        self.left_tensors = nn.Parameter(init_std * torch.randn(self.W, left_num  ,self.vbd,self.vbd,self.vbd,self.vbd, self.ipb)+ bias_mat)\n",
    "        self.rigt_tensors = nn.Parameter(init_std * torch.randn(self.W, right_num ,self.vbd,self.vbd,self.vbd,self.vbd, self.ipb)+ bias_mat)\n",
    "\n",
    "        bias_mat = torch.einsum(\"ij,kl->ijkl\",torch.eye(2),torch.eye(2)).unsqueeze(-1).repeat(1,1,1,1,self.opb)\n",
    "        self.cent_tensors = nn.Parameter(init_std * torch.randn(self.W,self.out_features,self.vbd,self.vbd,self.vbd,self.vbd, self.opb)+ bias_mat)\n",
    "\n",
    "    @staticmethod\n",
    "    def TRG_contraction(tensor):\n",
    "        '''\n",
    "        Tensor renormalization group Contraction method\n",
    "                     | \n",
    "           |      —○\n",
    "        —●—\t==>    \\ \n",
    "           |           ○—\n",
    "                       | \n",
    "        input: (W[2^N], H[2^N] , D,D,D,D)\n",
    "        '''\n",
    "        W,H = tensor.shape[:2]\n",
    "        lu_tensor = tensor[0:::2,0:::2]\n",
    "        ll_tensor = tensor[0:::2,1:::2]\n",
    "        ru_tensor = tensor[1:::2,0:::2]\n",
    "        rl_tensor = tensor[1:::2,1:::2]\n",
    "        size   = int(tensor.shape[0])\n",
    "        while size > 1:\n",
    "            half_size = size // 2\n",
    "            nice_size = 2 * half_size\n",
    "            leftover  = tensor[nice_size:]\n",
    "            tensor    = torch.einsum(\"mbik,mbkj->mbij\",tensor[0:nice_size:2], tensor[1:nice_size:2])\n",
    "            #(k/2,NB,D,D),(k/2,NB,D,D) <-> (k/2,NB,D,D)\n",
    "            tensor   = torch.cat([tensor, leftover], axis=0)\n",
    "            size     = half_size + int(size % 2 == 1)\n",
    "        return tensor.squeeze(0)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_chain_contraction(tensor):\n",
    "        size   = int(tensor.shape[0])\n",
    "        while size > 1:\n",
    "            half_size = size // 2\n",
    "            nice_size = 2 * half_size\n",
    "            leftover  = tensor[nice_size:]\n",
    "            tensor    = torch.einsum(\"mbik,mbkj->mbij\",tensor[0:nice_size:2], tensor[1:nice_size:2])\n",
    "            #(k/2,NB,D,D),(k/2,NB,D,D) <-> (k/2,NB,D,D)\n",
    "            tensor   = torch.cat([tensor, leftover], axis=0)\n",
    "            size     = half_size + int(size % 2 == 1)\n",
    "        return tensor.squeeze(0)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # the input data shape is (B,L,pd)\n",
    "        # expand to convolution patch\n",
    "        embedded_data= input_data\n",
    "        left_tensors = torch.einsum('wijp,nwp->wnij',self.left_tensors,embedded_data[:,:self.hn])#i.e. (K,NB,b,b)\n",
    "        rigt_tensors = torch.einsum('wijp,nwp->wnij',self.rigt_tensors,embedded_data[:,-self.hn:])#i.e.(K,NB,b,b)\n",
    "\n",
    "        left_tensors = self.get_chain_contraction(left_tensors) #i.e. (NB,b,b)\n",
    "        rigt_tensors = self.get_chain_contraction(rigt_tensors) #i.e. (NB,b,b)\n",
    "\n",
    "        tensor  = torch.einsum('bip,oplt,bli->bot',left_tensors,self.cent_tensors,rigt_tensors)\n",
    "        # (NB,b,b) <-> (T,b,b,o) <-> (NB,b,b) ==> (NB,T,t)\n",
    "        return tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from mltool.dataaccelerate import DataSimfetcher\n",
    "from mltool.loggingsystem import LoggingSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader= torch.utils.data.DataLoader(dataset=mnist_train, batch_size=3000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test , batch_size=3000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from models.extend_model import Patch2NetworkInput\n",
    "#from models.two_dim_model import PEPS_einsum_uniform_shape_6x6_fast\n",
    "# model = MPSLinear(28*28,10,in_physics_bond = 2, out_physics_bond=1, virtual_bond_dim=100,\n",
    "#                   bias=False,label_position='center',init_std=0)\n",
    "#model = PEPS_einsum_uniform_shape_6x6_fast(in_physics_bond=16,virtual_bond_dim=3,init_std=1)\n",
    "# model = nn.Sequential(Patch2NetworkInput(4,reverse=False),\n",
    "#                       PEPS_uniform_shape_symmetry_deep_model(W=6,H=6,in_physics_bond=16,init_std=1e-5,virtual_bond_dim=5,\n",
    "#                                                                                    normlized_layer_module=nn.InstanceNorm3d,\n",
    "#                                                                                    nonlinear_layer=nn.Tanh()),\n",
    "                     \n",
    "#                      nn.Linear(16,10)\n",
    "#                      )\n",
    "model = PEPS_einsum_arbitrary_partition_optim(virtual_bond_dim=\"models/arbitary_shape/arbitary_shape_2.json\",init_std=1e-2,solved_std=0.04)\n",
    "#model  = AMPSShare(n=28*28, bond_dim=10, phys_dim=2)\n",
    "device = 'cuda'\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(image):\n",
    "    return (1-image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "infiniter = DataSimfetcher(train_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.3471, device='cuda:0'), tensor(0.8227, device='cuda:0'))\n",
      "(tensor(6.3527, device='cuda:0'), tensor(0.1080, device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "image,label= infiniter.next()\n",
    "bs,c,w,h = image.shape\n",
    "with torch.no_grad():\n",
    "    x     = preprocess_images(image);print(torch.std_mean(x))\n",
    "#     x     = model[0](x);print(torch.std_mean(x))\n",
    "#     x     = model[1](x);print(torch.std_mean(x))\n",
    "#     x     = model[2](x);print(torch.std_mean(x))\n",
    "    x     = model(x);print(torch.std_mean(x))\n",
    "    #label = image.flatten().long()\n",
    "    #logits     = model(binary).reshape(bs*w*h,2)\n",
    "    #print(model(binary).squeeze().norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log at log/test\n"
     ]
    }
   ],
   "source": [
    "logsys            = LoggingSystem(True,\"log/test\")\n",
    "metric_list       = ['loss','g_norm','accu']\n",
    "losses=[]\n",
    "accues=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "code_folding": [
     4
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABB4AAAEICAYAAAD4ETcSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAC/SElEQVR4nOy9eXhkZZn+/3lqr1T2rTud3hdomgYBm10UERVXkHEccUEdHHRGxnHUGdev+nN03GbUcV9G3BFFYUBFURYXdhpoaHqDXul0p7MvlUpqf39/nHMqlaQqqSSVVCV5PteVq1Nny3vSqVPnvc/93I8YY1AURVEURVEURVEURZkLXKUegKIoiqIoiqIoiqIoixcVHhRFURRFURRFURRFmTNUeFAURVEURVEURVEUZc5Q4UFRFEVRFEVRFEVRlDlDhQdFURRFURRFURRFUeYMFR4URVEURVEURVEURZkzVHhQFhUiclhELi31OBRFURRFURRFURQLFR4URVEURVEURVEURZkzVHhQFEVRFKWsERFPqcegKIqiKMrMUeFBWZSIiF9Eviwix+2vL4uI317XKCK/EZF+EekVkb+KiMte9wEROSYiYRHZJyIvKu2ZKIqilAcicpaIPG5fH28SkZ+LyKcm2f5iEWkTkfeJSKeItIvI27LW14jIj0SkS0SOiMhHs67FbxWR+0TkSyLSA3xCRH4gIt8Qkd+JyJC9frl9fe8Tkb0icuY8/CoURVHKFhH5oIgcsK/Vu0XkNVnr/kFE9mStO8tevkpEbravxz0i8jV7+SdE5CdZ+68VEaNisDITVHhQFisfAc4DzgCeA5wDfNRe9z6gDWgClgEfBoyInAxcB5xtjKkCXgocntdRK4qilCEi4gNuAX4A1AM/A14z2T42y4EaoBW4Bvi6iNTZ675qr1sPvAC4Gnhb1r7nAgexrtOftpe9Duta3gjEgAeAx+zXvwS+OJPzUxRFWUQcAC7Cur7+f8BPRKRFRP4W+ATWtbYaeDXQIyJu4DfAEWAt1vX6xvkftrLYUeFBWay8EfikMabTGNOFdeF9s70uAbQAa4wxCWPMX40xBkgBfmCLiHiNMYeNMQdKMnpFUZTy4jzAA3zFvm7eDDxcwH4JrGtxwhhzOzAEnGzf6L4e+JAxJmyMOQz8N6PXaYDjxpivGmOSxpgRe9ktxphHjTFRLCEkaoz5kTEmBfwcUMeDoihLGmPMTcaY48aYtDHm58AzWA/g3g583hjziLHYb4w5Yq9bAfybMSZijIkaY+4t4SkoixQVHpTFygos5dbhiL0M4AvAfuAPInJQRD4IYIzZD7wHSw3uFJEbRWQFiqIoygrgmC3SOhwtYL8eY0wy6/UwUInlUPAy8TrdOsXxO7K+H8nxurKAMSmKoixaRORqEdlhlxT3A1uxrrmrsNwQ41kFHBl3rVaUoqPCg7JYOQ6syXq92l6G/XTtfcaY9Vg2s/c6WQ7GmBuMMc+z9zXA5+Z32IqiKGVJO9AqIpK1bNUsjteN5YYYf50+lvXaoCiKohSMiKwBvotVOtxgjKkFngIES8zdkGO3o8DqPLkNEaAi6/Xyog5YWVKo8KAsVn4GfFREmkSkEfgY8BMAEXmliGy0b6AHsEos0iJysohcYodQRrGenqVLNH5FUZRy4gGsa+V1IuIRkcux7Lkzwi6N+AXwaRGpsm+W34t9nVYURVFmRAhLtO0CsAN9t9rr/hd4v4g8Vyw22tfeh7HE5c+KSEhEAiJyob3PDuD5IrJaRGqAD83nySiLCxUelMXKp4DtwJPATqzwMSd9fRNwJ1at8QPAN4wx92DlO3wW60ncCaAZvcAqiqJgjIkDV2IFRPYDb8IKI4vN4rD/jPU07SBwL3ADcP2sBqooirKEMcbsxsrLeQCrFO004D573U1YQb03AGHg/4B6Wwh+FbAReBYrgP3v7H3+iJWf8yTwKNZ1X1FmhIwt11QURVEURZkaEXkI+JYx5vulHouiKIqiKOWNOh4URVEURZkSEXmBiCy3Sy3eApwO/L7U41IURVEUpfxR4UFRFEVRlEI4GXgCq9TifcBrgbeJyFCOr9+VcqCKoiiKopQXWmqhKIqiKIqiKIqiKMqcoY4HRVEURVEURVEURVHmjFz9WsuWxsZGs3bt2lIPQ1EUZQyPPvpotzGmqdTjmA/0OqwoSrmi12JFUZTSMtl1eEEJD2vXrmX79u2lHoaiKMoYRORIqccwX+h1WFGUckWvxYqiKKVlsuuwllooiqIoiqIoiqIoijJnqPCgKIqiKIqiKIqiKMqcocKDoiiKoiiKohSAiFwmIvtEZL+IfDDH+neKyE4R2SEi94rIFnv5i0XkUXvdoyJySdY+f7KPucP+ap7Pc1IURZkPFlTGg6IoiqIoiqKUAhFxA18HXgy0AY+IyG3GmN1Zm91gjPmWvf2rgS8ClwHdwKuMMcdFZCtwB9Catd8bjTEa2qAoyqJFHQ+KoiiKoiiKMjXnAPuNMQeNMXHgRuDy7A2MMYNZL0OAsZc/bow5bi/fBQRFxD8PY1YURSkLVHhQFEVRFEVRlKlpBY5mvW5jrGsBABF5l4gcAD4PvDvHcf4GeMwYE8ta9n27zOL/iYjk+uEicq2IbBeR7V1dXTM/C0VRlBKgwoOiKIqiKIqiFAljzNeNMRuADwAfzV4nIqcCnwPekbX4jcaY04CL7K835znud4wx24wx25qamuZm8IqiKHOECg/KkqJnKMbtO9tLPQxFUWy2H+5lT/vg1BsqiqKUnmPAqqzXK+1l+bgRuMJ5ISIrgVuAq40xB5zlxphj9r9h4Aaskg5FUZS8xJIpfvrQESKxZKmHUjAqPChLilseP8Y//fQxwtFEqYeiKArwsVt38bnf7y31MBRFUQrhEWCTiKwTER/weuC27A1EZFPWy1cAz9jLa4HfAh80xtyXtb1HRBrt773AK4Gn5vIkFEVZ2Bhj+NDNO/nILU9x556OUg+nYLSrhbKkGI6nAIgm0lQFSjwYRVGIxJN0quFBUZQFgDEmKSLXYXWkcAPXG2N2icgnge3GmNuA60TkUiAB9AFvsXe/DtgIfExEPmYvewkQAe6wRQc3cCfw3Xk7KUVRFhzf/stBbn7MMlu1D0RLPJrCUeFBWVLEk2kAoolUiUeiKApY78WRuL4fFUVZGBhjbgduH7fsY1nf/0ue/T4FfCrPYZ9btAEqilLW7D0xyFfv3k/HQJRz1tVz/oYGtq2pJ+hzF7T/H3ad4HO/38srT2/hz/u6aO8fmeMRFw8VHpQlRTxlCQ8xW4BQFKW0jMRTROIp0mmDy5UzyF1RFEVRFGVB80xHmC/f9Qy/fbKdKr+HDc2VfOcvB/nGnw7gdQtnrKrl/PUNvOL0FZy8vCrnMXYfH+Q9P9/B6a01/NffPodXf+1edTwoS4vOwSgBn5vqgLfUQ5kSdTwoSnkRTaZJpQ19w3EaKrWlvaIoiqIoi4cDXUN85a5nuO2J41R43Vz3wo28/aJ11Fb4iMSSPHK4lwcO9vDggR6+ds9+vnL3fl6yZRnvftEmtrbWZI7TGY7y9h8+QnXAy3ev3kbA62Z5TZATgyo8KEuIv//hI5y+spb/fM1ppR7KlDhOB3U8KErpSadNRgzsGoqp8KAoiqIoyqLh9p3tXHfDY/g9bt7x/A1c+/z11Id8mfUhv4eLT27m4pObAeiLxPn+/Yf5/n2H+MPuDi7Z3Mw/X7KRU1qqufZHj9I3nOCmd55Pc7UVVNdSHVhQncFUeFBmTXc4TudgrNTDKIh4RnhQx4OilJpo1vuwOxyH5SUcjKIoiqIoShH54+4OGir9/O5fLqKxgIcrdSEf733xSbz9onX86P7D/O+9h3jNN+6ntTbIsf4RvvWms8a4IJbXBOgeihFPpvF5yr9ZZfmPUCl7oskUI4mF0UM2k/GQUMeDopSaaNb7sGto4VgFFUVRFEVRpuJgd4STl1UVJDpkUx3wct0lm7jvA5fwoZdtBuDDL9/MZVtbxmy3ojaAMdCxQMotphQeRGSViNwjIrtFZJeITEjrFYuviMh+EXlSRM7KWpcSkR32121Zy9eJyEP2Pj+3+yErC5BoIpVpU1nuxO0nrOp4UJTSk5210h2Ol3AkiqIoiqIoxcMYw6GuIdY1hmZ8jJDfwztesIH7PngJ1z5/w4T1y2uCAAsm56EQx0MSeJ8xZgtwHvAuEdkybpuXAZvsr2uBb2atGzHGnGF/vTpr+eeALxljNmL1Ob5mpiehlA5jDNFEesG0w4tlwiXV8aAopWYkS3joGloY5VqKoiiKoihT0TecYDCaZO0shIepaKmxsh4WSmeLKYUHY0y7MeYx+/swsAdoHbfZ5cCPjMWDQK2ItJAHERHgEuCX9qIfAldMf/hKqXEm8gvH8aAZD4pSLox1PKjwoCiKoijK4uBQ9xAA6+dQeFhuCw8nBkbm7GcUk2llPIjIWuBM4KFxq1qBo1mv2xgVJwIisl1EHhSRK+xlDUC/MSaZY/vxP/Nae//tXV1d0xmuMg84WQkLT3hQx4OilJqxGQ8qPCiKoiiKMr8YYzDGFP24B7siALMqtZiKKr+HkM+9YBwPBXe1EJFK4FfAe4wx0+nbscYYc0xE1gN3i8hOYKDQnY0x3wG+A7Bt27bi/1Uos8JJpR+JL6xwyewnrYqyWBGR64FXAp3GmK051gvwP8DLgWHgrY7DbT5w3ofVAQ9d6nhQFEVRFGUeOd4/wluuf5j9XUNU+j2jXwEP1QEv73vJSZy+snZGxz7UHcHjElbWBYs76CxEhJbaIO39C0N4KMjxICJeLNHhp8aYm3NscgxYlfV6pb0MY4zz70HgT1iOiR6scgzP+O2VhYUzcRhOpOZELSw2GceDZjwoS4MfAJdNsn6yfJ45x7l+rKqvoFsdD4qiKIqizBMnBqK84bsPcmIgyj++YAOvfe5KnrexkY3NlVT6PTx2pI///sPTMz7+4Z4Iq+sr8LjntolkS02A9gUSLjml48F+IvY9YI8x5ot5NrsNuE5EbgTOBQaMMe0iUgcMG2NiItIIXAh83hhjROQe4LXAjcBbgFuLcD7KPONYpY2xyhcCXneJRzQ5WmqhLCWMMX+xS+TykcnnAR4UkVoRaTHGtM/H+Jzrx6q6Cva0D5JKG9wumY8frSiKoijKEqVz0BIduofi/Oiaczhrdd2Ebb5y1zN88Y9Ps79ziI3NldP+GQe7InNaZuGwvDrA0x0LI46gEAnmQuDNwCVZbTFfLiLvFJF32tvcDhwE9gPfBf7JXn4KsF1EngDuAT5rjNltr/sA8F4R2Y+V+fC94pySMp9klywshJyH0a4W5T9WRZkHJsvnyTBXWTsjGcdDkLSBnoi6HhRFURRFmTu6wjGu+u6DnBiM8oO3nZ1TdAB4w7mr8bld/OiBw9P+Gem04XBPZE47Wji01AToDMdIpMr/oeqUjgdjzL3ApI+g7Kdl78qx/H7gtDz7HATOKWyYSrkyVnhIUh/ylXA0U+NkPKjjQVEKZ66ydrJLLQC6w3GaqwLFOryiKIqiKEuQZCqds8SheyjGG777IMf7o/zw789h29r6vMdorPTzques4JePtvG+l5xMTdBb8M/vCEeJJtLz4nhoqQ1ijCWorKiduzyJYlBwuKSi5CKaNYEfWQCOh7g6HhQlm7z5PPNBRnios4QH7WyhKIqiKMpMefBgD5/53V52tvWzur6Cjc1VbFpWyabmSlbVV/DRW57iaN8w33/rOZyzLr/o4PC2C9fyq8fauGn7Ud5+0fqCx3HI7mgxl600HZyWmu0DIyo8KIubhVZqoRkPijKGnPk88/XDneuHk/jcrZ0tFEVRFEWZJvtOhPnc7/dy995OWmoCvP2i9bT1DfNMxxB/frqTRMoya/o9Lr7/1rM5f0NDQcfd2lrD2Wvr+NEDR3jbhesKzqE62G0JD/NVagEsiJaaKjwos2LBCQ+ZUovyH6uizBYR+RlwMdAoIm3AxwEvgDHmW1j5PC/HyucZBt42n+OLJtK4XVYrKFDHg6IoiqIohdM+MMIX//A0v3qsjZDfwwcu28zbLlw7Juw+kUpzpGeY/Z1hNjRVsmlZ1bR+xlsvWMe7bniMu/d28uItywra51B3hIDXxfLquS8fbam27qFOqPCgLHaynQMjiWQJRzI1qbQhlbYUz6i201SWAMaYq6ZYnzOfZ74YSaQIeFyEfG6CXrc6HhRFURRFKYifPfwsn7htF8bA31+4jne9cCN1ObLmvG4XG5srZ9SZAuClpy6jpSbAD+4/VLDwcLg7wtqGEK556NRVHfQQ9LqL7nj4+SPP0lwV4IWbm4t2zLltLKosemILyPEQzxJJ1PGgKKUnmkgR8LoRERqrfOp4UBSl7BGRy0Rkn4jsF5EP5lj/ThHZaXeBu1dEtmSt+5C93z4ReWmhx1QUZZRU2vDp3+7mQzfv5Nz1Ddz1vhfw0VduySk6FAOP28Wbz1/Dfft72HciXNA+h7rnp5UmgIjQUhsoquMhnTZ84Y59/N+O4sZ+qfCgzIps58BCEh7U8aAopSeaSGfskE2VfrpVeFAUpYwRETfwdeBlwBbgqmxhweYGY8xpxpgzgM8DX7T33QK8HjgVuAz4hoi4CzymoihYHfTe+ZNH+e5fD/GW89dw/Vu2ZTpjzSVXnb0av8fFD+4/POW2yVSaZ3uH5014ACvn4fjASNGOt+fEIN1DcS7a1FS0Y4IKD8osyc54KPeuFrHU6Pg0XFJRSo/leLA+hhor/XRpqYWiKOXNOcB+Y8xBY0wcuBG4PHsDY8xg1ssQ4LQgvhy40RgTM8YcwsrWOaeQYyqKYmUY/O23HuCuPR184lVb+P8u35qzZeZcUBfy8ZozW7nl8Tb6h+OTbtvWN0IybeZVeFheHSyq4+Gvz3QDcNGmxqIdE1R4UGZJNKmlFoqizAyn1AKgqcpP99DkH+aKoiglphU4mvW6zV42BhF5l4gcwHI8vHuKfQs6pn3ca0Vku4hs7+rqmvFJKEopSaUNjxzunZbL8aljA1z+9Xs53B3hf9+yjbdeuG4OR5ibt1ywlmgizY2PHJ10u0N2R4v5djx0hmMkU8V5sHrvM92ctKySZUUOx1ThQZkV0USakM+NiGV/Kmccl4PXLcS01EJRSk40mSJoCw+NlX56I3ESRfrQVBRFKRXGmK8bYzYAHwA+WsTjfscYs80Ys62pqbgWaEWZDfft7+a//7CPO3d35HUE7Gkf5DO37+GCz97F337rAa76zoMMRhNTHnv74V5e9+0HcIlw0zsv4JLNhQU8FptTWqo5b309P37gyKQT/IMlEB6W1wRIpU1RHuBEEykePtxb9DIL0K4WyizJfmK5UBwPVQGvOh4UpQwYiaeo8FkfQ01VfgB6I/GiK+yKoihF4hiwKuv1SntZPm4EvlnAvtM5pqKUDem04ev37OeLdz6NMaPLT1pWyba19Zy9to6ucIybHzvG3hNhPC7h4pOb+PsL6/nCHft4108f4/q3no03T8nE0x1h/v4Hj7C8OsCN155Hc4nvD956wTre+ZNH+fPTXbzolNwCyOHuCNUBD/VzFHaZixW11u+lfWCE5TWz+x09fKiXeDJd9DILUOFBmSVOOJyILBjhoTrgUUu3opQB0USa+tBoxgNAVzimwoOiKOXKI8AmEVmHJQ68HnhD9gYisskY84z98hWA8/1twA0i8kVgBbAJeBiQqY6pKOVIOJrgfb94gj/s7uA1Z7by8VdtYd+JMNuP9PHwoV5+veM4Nzz0LABnrKrlk5efyitOa6HB/ryvC/n4918+ySdu28WnrtiKyNjWk8f6R7j6ew8T8Lr54d+fU3LRAeCSzc1U+T38YVdHXuHhUHeEdU2VE85nLlleHQSgfSDKmbM81l+f6cLndnHuuobZD2wcKjwosyKaTOH3unC7hJEyL7WIp0YdD8f6i5f8qijKzIgmx2Y8ANpSU1GUssUYkxSR64A7ADdwvTFml4h8EthujLkNuE5ELgUSQB/wFnvfXSLyC2A3kATeZYxJAeQ65nyfm6JMhwNdQ1z7o+0c7hnmY6/cwtsuXIuIcO76Bs5d38C7XmhlOew7EabC52ZtjrKD121bxcGuCN/68wHWN1VyzfNGcxv6InGu/t5DROJJfvGO8+elc0Uh+DwuXnByE3ft7SCVNrhdE8WFQ90Rzl5bN6/jaqlxHA+zD5j86zPdbFtbR9DnnvWxxqPCwxLljl0naK7yc+bq2b0xYokUAY+btNssHMdD0EMiZfJeMBRFmR+i8dSYdpqAdrZQFKWsMcbcDtw+btnHsr7/l0n2/TTw6UKOqSjlyh93d/CvP9+Bz+PiJ9ecy/kbcj8Zd7uELSuqJz3Wv7/0ZA53R/jUb3ezpr6CS7csYzie5O9/+AhH+0b48d+fwyktkx9jvnnxlmX85sl2dhzt47lr6sesiyZSHOsf4XWNq/LsPTfUVnjxe1ycmGVLzc7BKHtPhPn3y04u0sjGouGSS5RP/no33/7zwVkfxyq1cBH0uRlJLAzhocrvBbSzhaKUmmgyPRouWWXVQk4n5VpRFEVRlPnj108c5x9+tJ11jSF+/c/Pyys6FIrLJXzp785g64oa3n3j4zzZ1s91NzzOE0f7+crrz+Dc9cW3+8+Wi09uxuMS/rC7Y8K6Iz3DAKxrmr9gSQARYUVtcNaOh3v3W200nz8HwZKgwsOSpScSIxybOkl2KpxwyQqfu+wdD7FMuKRl9NHOFopSWkbiKQJe62Oowuch5HPTHdb8FUVRFEUpNyKxJP/xm908Z2UNN73zfFprg0U5btDn5n/fso2aoJcrv3E/d+/t5D+u2MplW1uKcvxiUxP0ct76Bv6YQ3g41D0EwLqG+RUeAJZXBzgxW+HhmW7qQz62zJHLRIWHJchwPEk0kWYoOvtMBqdGO+j1lL3w4GQ8VAcdx4MKD4pSKowxYzIewMp50IwHRVEURSk/vvGn/XSGY3z81aeO+ewuBsuqA3zvLWdTW+Hj/S85iTeeu6aoxy82L96yjINdEQ50DY1Z7rTSXNs4/5kULTWBWTkejDH85ZluLtzYiGuOStGnFB5EZJWI3CMiu0Vkl4hMqF0Ti6+IyH4ReVJEzrKXnyEiD9j7PSkif5e1zw9E5JCI7LC/zijqmSl56bE7OoSLITwk0vg9Lip87vIPlxzneIiWeWmIoixm4qk0xjDm5qWx0k+3ZjwoiqIoSllxtHeY7/71EK85s5WzZpkPl48tK6p55CMv4rpLNs3J8YvJpVusjhZ3jnM9HO6O0FTlpyrgnfcxLa8J0DEYJZU2U2+cg70nwnQPxeakjaZDIY6HJPA+Y8wW4DzgXSKyZdw2L8NqC7QJuJbRnsXDwNXGmFOBy4Avi0ht1n7/Zow5w/7aMfPTUKZDb8QWHmLFEB4WTqnFaDtNdTwoSqmJxq33nzoeFEVRFKW8+czv9uAW4QOXbZ7TnzOfLShnQ2ttkFNXVE8otzjUHSlJmQVYjodk2tAzw/uoe5+x8h1KKjwYY9qNMY/Z34eBPUDruM0uB35kLB4EakWkxRjztNPL2BhzHOgE5iatQimYnoj1BxmOFiPjIStcsuyFB2t8TqmFOh4UpXRE7fejk/EAtuNBhQdFURRFKRsePNjD7TtP8I8Xb2C53bZRscotHn22b8x9y6HuCOtytA6dD1pqrMyNmZZb/OWZLjY2V2aOMxdMK+NBRNYCZwIPjVvVChzNet3GOHFCRM4BfMCBrMWftkswviQi/jw/81oR2S4i27u6uqYzXCUPTqlFNJEmkZrdU/9YMoXfYzseEimMmZm9Zz5wMh4y4ZLqeFCUkuEIf8Fxjof+4UTGnaQoiqIoSulIpQ3/369301ob5Nrnry/1cMqKS09ZhjFw955OAAajCbqH4vPe0cLBEYVmIjxEEykePtQ7p24HmIbwICKVwK+A9xhjBqfzQ0SkBfgx8DZjjHNH+SFgM3A2UA98INe+xpjvGGO2GWO2NTWpWaIYOKUWwKwDJmOJtF1q4SGVNpnJfTkysdRCHQ+KUiqc9rvjMx5g1JWlKIqiKErp+MX2o+xpH+SDL9tc9EDJhc6pK6pprQ1m2moedoIlS1hqAdA+MDLtfbcf7iOWTJeH8CAiXizR4afGmJtzbHIMWJX1eqW9DBGpBn4LfMQuwwAyJRzGGBMDvg+cM7NTUKZLtvBQSMDkHbtO5PwjdoSGgNeVeWpZzuUW8WQaEQj5rbFGtZ2mopQM5/2XXWrRVGUJD10aMKkoiqIoJWUwmuC/7tjH2WvreOXp5dnaspSICJee0sy9+7sYiac4ZAsP60vkeKgP+fB5XDNqqfnXZ7rwuoVz1zXMwchGKaSrhQDfA/YYY76YZ7PbgKvt7hbnAQPGmHYR8QG3YOU//HLccVuyjn8F8NTMT0OZDt1DWcJDbPKch2QqzT/+5FF+8uCRCetiydEnlhU+azJfzgGTsVQan9uVUWzV8aAopSOa0/HgA9CcB0VRFEWZBwajCS757z/xyq/+lQ/d/CQ/fegIT7b1E0um+Nrd++kdjvPxV526YEIf55sXb1lONJHmr890cbArggisrp//VppgCSEzban512e6ee6aOkJ+zxyMbJRCjn4h8GZgp4jssJd9GFgNYIz5FnA78HJgP1Yni7fZ270OeD7QICJvtZe91e5g8VMRaQIE2AG8c3anohRKb5aNeSrHw1AsSdpAb2SiQJF5YumxwiWhzIWHRBqfx4XfY+lt6nhQlNKRq9RCHQ+KoiiKMn/cv7+bg10RnrOqlt8+2c7PHrYi+7xuIZU2/O1zV7K1tabEoyxfzl1fT1XAwx93dxBPpVlREyxpScry6sC0HQ9d4Ri72wf5t5eePEejGmVK4cEYcy+WODDZNgZ4V47lPwF+kmefSwoco1JkeiNx6iq89A0npsx4cISJgZH4hHXZTywrfNafUlmXWqTS+D3qeFCUciDmXD88EzMesl1ZiqIoiqJMJJpIEU2kqK3wzfgY9+3vocLn5qZ3nI/XLRztHWHnsQF2HhugfWCEf5/j9pkLHa/bxQtPbubuvZ0srwmUrMzCoaUmwPYjfdPa5779c99G02Fu/RRKWdITibOmIUTfcP+UpRaO8NA/nMvxkKvUYnZhlXNJPGmVWjiOh5g6HhSlZDiOI8ctBda1pCrgUceDoiiKokzBB371JDuO9vOn918841KI+w50c866enz2vfHqhgpWN1TwCs10KJgXb1nGbU8cpycS5+rz15R0LMtrgnQMtpNOG1yuwv4m7tzTQW2Fl1NXzL2zZVrtNJXFQW8kztoGq/5oKsfDUGwy4WE0HC5TapEoXxdBPGmVWjiOh6g6HhSlZIyWWoz9GGqq9NOlGQ+KoiiKkpeOwSi/fbKdIz3DHLRDDadL+8AIB7siPG/j3D/pXsxcfHITXrc1yS9VRwuHlpoAiZShJ1KYc/RQd4Tbd7bzN2etxF2gUDEbVHhYYozEUwzHU6yx3xiDU5ZaWILDwEgO4cGeuPuzHA9lXWphCw8+tzoeFKXURHOUWoBVbqGOB0VRFEXJz40PHyWZNgDcf6BnRse4b7+13wUbVHiYDVUBL+ett7pBrCuDUgug4JyHr971DD6Pi3e+YMNcDiuDCg9LjB47WHJFbQCvWzKOhnyMOh4myXjwuKnwWlU75RwuGU9ZwoPLJfjcLnU8KEoJcRwP2aUWYAVMalcLRVEURclNIpXmhoeP8PyTmlhRE+B+u0Z/uty/v5v6kI/Ny6uKPMKlxytOa8ElcNKy0v4uW2qCgOVmmYqDXUP8345jvPm8NZlw77lGMx6WGL229aY+5KfS78k4GvLhOCIi8VTGMeDgOAb8WaUWIzkyHj50804APnPlabM/gVngZDyANWZ1PChK6XBKtfyesfp3Y6VPHQ+KoiiKkoc7d3fQMRjj01es4fe7TnDnno5p1fQDGGO470A3529omNZ+Sm5et20V56yrp7U2WNJxLLcdD4W01Pzq3fvxeVxc+/z5cTuAOh6WHD0Z4cFHVcA7dcZD1vrx5RZjHA952mnev7+bnz38LL97qh2r+UnpyBZO/B43sWRphYfOwSinffwOnjo2UNJxKEopiCVSBLyuCYFYTVV+wtFk5vqiKIpSTojIZSKyT0T2i8gHc6x/r4jsFpEnReQuEVljL3+hiOzI+oqKyBX2uh+IyKGsdWfM71kpC4kfP3iE1togL9zczIUbG+gfTrC7fXBaxzjQNUTHYEzzHYqEyyWsb6os9TBoCPnwumVK4eFA1xC37jjG1eevnTe3A6jwsOTosdvUNVb6bMdDYRkPMLGlplOqEPC6CNqBjZEs4SGZSvOJX+8CrHDKE4PT6ytbbGKpND67njzgdWXa+ZWKo33DhGNJDvfMLBRIURYyI4lUzl7Xoy011fWgKEp5ISJu4OvAy4AtwFUismXcZo8D24wxpwO/BD4PYIy5xxhzhjHmDOASYBj4Q9Z+/+asN8bsmNszURYq+zvD3H+ghzeetxq3SzL5DPcfmF65hZPvcKHmOywqXC5heU2AE1OUWnzt7v34PW6uff76eRqZhQoPS4xeO+PBcjx4CE+R8ZAtTIzvbDHa1cKNyyUEvK4xpRY/efAIT3cM8fbnrQNgb3u4KOcwU8aUWnhcJXc8RGKW8BHVkg9ljijgydxqEblHRB63n869fL7GFk2kJgRLAhnlvXuosERmRVGUeeQcYL8x5qAxJg7cCFyevYEtMAzbLx8EVuY4zmuB32VtpygF8ZMHn8XndvG6basAWFYdYENTKCMkFMp9+7tZWRdktd3lTlk8tFQHJ3U8jLod1mQe9swXKjwsMXoicXxuF5V+jyU8FNhOE3IJD47jwZo8VPg8mVKLnqEYX/zj01y0qZF3X7oJYNo2sGITT6bwe7NLLUrreIjYv9tSj0NZnBT4ZO6jwC+MMWcCrwe+MV/jiybSE4IlYdTxoDkPiqKUIa3A0azXbfayfFwD/C7H8tcDPxu37NO2APwlEck5GxCRa0Vku4hs7+rqms64lUVAJJbkV4+28fLTlo+ZMF64sZFHDvcSL/CBWipteOBgj5ZZLFKW1wQmdZl/9a5n8Hvc/MM8ux1AhYclR+9QnPqQDxGxMh5ik4dLhqMJQvbkoH9cxoPjGAjYk/mg151pp3nL48cYjCb5f6/cQnXAS2ttkL0nSux4SKXx246HgNdVcqeBU5aiIZfKHDHlkznAANX29zXA8fka3EgiNSFYErIdDyo8KMpSJJpI0TMUI5UubS7UbBGRNwHbgC+MW94CnAbckbX4Q8Bm4GygHvhArmMaY75jjNlmjNnW1NQ0J+NWypdbdxwnHEvy5vPXjFl+wYYGhuMpnmjrL+g4O48NEI4muUCFh0VJS02A9oFozmy9/Z1D3PbE8ZK4HUCFhyVHb8QSHoACMx6SrKq3bFjjW2pmh0sCVPjcGcfD0x1hGiv9mbYyp7RUs7fkjofx4ZKldRoMxx3HgwoPypxQyJO5TwBvEpE24Hbgn3MdaC6eskXzZDw0VFrXJ3U8KMrS5E/7Onnup+5k74nS3jPk4RiwKuv1SnvZGETkUuAjwKuNMeMvZq8DbjHGZJ7mGGPajUUM+D6WcKwoGYwx/OiBw2xpqeas1XVj1p23vgERuL/Acov77PabF2xoKPo4ldKzvCZAPJnm1h3HaesbHiNAfPXuZ0qS7eCg7TSXGN2ReObGvirgYSiaxBgzIVneIRxNsqI2yL6OMIMTulpYmQlOG54Kn5thW4zY3znExuZQZttTWqq4Z19n3snGfJAtPAS8LrqHJhdd5hon46HUAoiypLkK+IEx5r9F5HzgxyKy1RgzRg0zxnwH+A7Atm3bivIYMpZIZ0Jps/F73NQEvep4UJQlivPZWOkvy1vUR4BNIrIOS3B4PfCG7A1E5Ezg28BlxpjOHMe4CsvhkL1PizGmXaybsSuAp+Zg7MoC5tEjfew9EeYzV5424Z69tsLH1hU13Hegm3+xy5sn4/4D3WxeXlWSJ97K3POcVbX43C7e8/MdANRVeNnaWsNJy6q47YnjXPv89TSU6P++LK/qytzRG4mxzg6SqQx4SKZN3lprsDIeqgMeaoLeCaUW0cRoZgJYGQ8jcUvI2N85xKvPWJFZd0pLNam0tXxra80cnNnUjA2XLL3jYTTjQR0PypxQyJO5a4DLAIwxD4hIAGgEct0sF5WRRIpGWwQdT2OlTx0PirJEidhuwApf+d2iGmOSInIdVpmEG7jeGLNLRD4JbDfG3IZVWlEJ3GRPEJ81xrwaQETWYl2X/zzu0D8VkSZAgB3AO+fhdJQFxI8fPEKV38PlWffW2VywoYHr7zvEcDw56XsnmkjxyOE+3nzemrzbKAubs1bX8eQnXsKe9kGeOjbAzmMD7Dw2yAMHDlPp93DtRaVxO4AKD0sOK+PBUrmqAl4AwrFEXuEhHE1QFfBSG/ROCJeMJce6Fyp8bk4MJugaijEYTbIhq5/t5uVWycXu9sGSCQ+x7FILbxl0tbBvrqIlbuupLFqmfDIHPAu8CPiBiJwCBIB5SSybzP3UVOVXx4OiLFGcUOsydTxgjLkdqzQte9nHsr6/dJJ9D5MjjNIYc0kRh6gsMrqHYty+s503nrsmr6hwwcZGvv2Xg2w/3MfzT8qf//HokT7iyTQXbtQyi8VMwOvmzNV1nJlVlhNNpIgl09QEvSUbl2Y8LCGiiRSReGq01ML+UM+X82CMYSiWpDLgoabCl8PxkM4ESwIEfVa45P7OIQA2No8KD2saQgS97pK11EynDcm0GS218LhLPuEfzpRaqONBKT7GmCTgPJnbg9W9YpeIfFJEXm1v9j7gH0TkCayE9beaXGlEc0A0mcpZagFWZwt1PCjK0mQ4lsIljLm/UJSlzE3b20ikDG+axKVw9to6vG7hvgPdkx7rvv3deFzCOetUeFhqBLzukooOoI6HJUVPxAqHdMIlqwLWf/9QHuEhlkyTSBmqAh7b8TAxXNIJloTRcMkDOYQHt0s4aXkVe0oUMBlPWZP7cnQ8aFcLZa4o4MncbuDC+R4XwEg8jX9Sx0M85zpFURY3Q7EkIZ8nb/aUoiwljDHc/Fgbz11TN+a+ejwVPg9nrqqbMmDyvgM9nLGqtmwdRcriZko5WURWicg9IrJbRHaJyL/k2EZE5Csist/uQXxW1rq3iMgz9tdbspY/V0R22vt8RfQTZs7pHRorPFRO4Xhwllf5PdRW5M54GFtq4WE4nmR/5xCVfg/LqwNjtt/SUsXeE4M527vMNY7IMJrx4Cq542E040FLLZSlRyyRyvtEs7HSz1AsmWnPqyjK0iESSxLSSZGiALDr+CDPdA7xmjMnVOhM4IKNDTx1fICBcaXRDgMjCXa29WsbTaVkFOJjSwLvM8ZsAc4D3iUiW8Zt8zJgk/11LfBNABGpBz4OnIvVGujjIuIUm3wT+Ies/S6b3akoU9ETsazLjZmuFpbdZiiW+wIVjiYy2+XKeMhZapFIsb9riA1NoQlPKzYvr6ZvOEHHYH4L9Ydu3slPHzoyzTObmrgtPPgzXS3cxJLpkoggDpG4llooS5fJSi2aqqwcmsWQ89A/HOf9Nz2RqVtXFGVyhuMpQv7SdL9SlHLjlseP4XO7eOXpLVNue+HGRoyBBw7mdj08eLCHtIELtY2mUiKmFB7s3sKP2d+HsWqFx8tulwM/snsQPwjUikgL8FLgj8aYXmNMH/BH4DJ7XbUx5kG7nvhHWO2DlDmkN1Nq4YRLWk8UBvM4HrIDnmoqfAxGE6TSoxP1aDKFP7vUwusmkTLsOxFmQw47mBMwuSdPb+5EKs0vHz3KXXuKH6g/odTC48IYSKRKJzwMx2ff1eJjtz7F7TvbizUkRZkXkimrjCtvuKTd5qlzEeQ8PHK4j18+2sYTR/tLPRRFWRAMqeNBUQDrs/LWHcd54eYmaityd4HK5jkrawl63TyQJ+fh/v3dBO3QQUUpBdNK7rHbAJ0JPDRuVStwNOt1m71ssuVtOZbn+pnXish2Edne1TUvYeuLlt48GQ9TllrYGQ/GjLogILfjAaB7KJ6zDm1zSzUA+07kDpg82BUhkTJ0DEandV6F4DgefFmOB7DEk1KRCZecYcnHYDTBjx44wt1757zzoaIUlaj9fsxXarGYHA+Oo2y8Y0xRlNxE7IwHRVnM9BTw+Xbv/m66h2K85syVBR3T53Fxzrp67jsw0fGwp32QO/d0cs66+sy9sKLMNwX/5YlIJfAr4D3GmHlLCDTGfMcYs80Ys62pKX97GGVquofieFxCtS04OE8U8oVLjim1qLDKMrJvnmOJ1JhwuOwWPxubJgoPNUEvQa8778V2r+2EmKwUY6ZkhAe3NV6n5KKUwY6ZdpozdDw8dWwAyP//pyjlipPdMFlXC2BRdLYYsgXG/hENy1SUQojEU+p4UBY1Dxzo4exP38n//vXgpNvd8vgxaoJeXri58PnPhRsb2N85lHmI93RHmHf99DFe9j9/ZXAkwdsuXDuboSvKrCjoyi4iXizR4afGmJtzbHIMWJX1eqW97Bhw8bjlf7KXr8yxvTKHjMQt+6KTveB1uwh63WNcDNmMcTw4wsNItuNhYlcLh3zJu9VBD4MjuSfKe+xWmz2RGMlUGo+7eIrseMeDUyJSyoDJyCwdD0+22cKD1o4rCwznfZevq4XT8ndROB7s66g6HhSlMKxwSc14UBYnsWSKj/zfTtIGvnznM1x+RmvG5ZfNUCzJHbtO8DdnrRxT1jwVF2ywgiN/9vCzHOyK8Osnj1PhdfPPl2zk7c9bT01FadspKkubQrpaCPA9YI8x5ot5NrsNuNrubnEeMGCMacfqH/8SEamzQyVfAtxhrxsUkfPs418N3FqME1LyE08ZvOMm85UBT96Ja7bwUBO0JgLZLTWjydylFl63sLq+IucxqwNeBvMIHftsx4MxFL2VXjxlTXSy22lC6YIdjTEZx0N8hmPYaQsPYRUelAWG08kln+PB63ZRV+FdJI4H63o3MKLCg6IUgna1UBYz3/7zQQ52RfjEq7YQS6b4rzv25dzu90+dIJpIc+VZU3ezyGZLSzW1FV6+fOcz3Lmng3e+YAP3fuAS3veSk1V0UEpOIVf2C4E3AztFZIe97MPAagBjzLew+sS/HNgPDANvs9f1ish/AI/Y+33SGNNrf/9PwA+AIPA7+0uZQxKpdKbEwKEq4Mmb8eAIEiH/qONhYLzjwTvR8bC2IZTXrVAdzC887D0RpiboZWAkQcdglOU1gZzbzYTYuK4WjnpcqlaW0UQap6HGTMWPJ4/1AzCU5/epKOXKSNzJeMj/FKepyr/IHA9aaqEohRCJJzPtvhVlMXGoO8LX7tnPK05v4a0XrqOtb4Tv3XeIN5+/hq2tNWO2veXxNtY0VHDWNIMgXS7h31+6mba+Yf7+eesypYuKUg5MeWU3xtwLyBTbGOBdedZdD1yfY/l2YGthw1SKQTyZxuse+19Z5ffkfWIejiYIet143S5qgzkyHsY5HhzhIV+ZBUB1wJPTzdA/HKd9IMorTm/ht0+2FyVg8tmeYaoCHupCvhzhkta/0RJlPDhuB5GZiR+9kThHe0cQyR8OqijlihPqmi9cEqych8XgeHCur1pqoShTk0yliSbSY0o3FWUxYIzh//3fU/jdLj7+yi0A/POLNnHz48f45K938/N3nJcphW4fGOH+Az28+5JNE1rTF8Ibzl1d1LErSrHQWNMlRCKVnlBqURXw5s14GIolqbSDKGvGCQ+JVJpU2ozJeAh6rW0nFR7yOB722p0uXnCSFaDTUYQJx1XffZDP2xa20XDJ8nA8ROzJSE3QO6OAy512sOSWlmrNeFAWHE7GQ75SC3AcDwvfJeC81/u11EJRpiRiB8+q40FZbNz2xHHu3d/Nv112Ms3VlqO3JujlfS85iYcP9/LbrNbot+44jjHwmjOnV2ahKOWOCg9LiFzCQ6Xfk7crwmA0mWm56XG7qPJ7MsnszsQh2yq9rNqP3+Ni29r6vGOoDngZzHEDvrfdynd43sZGRKBrlo6H3kicY/0jHOsfASCeGldqUeKMBydYsr7CN6MxPHm0H4Dz1jcwHE+RSptiDk9R5hSnq8VkpRaLxfHgCIMD6nhQlCkZjo+WeCrKQsEYw4dv2cl1NzzG/s6JLeMHRhL8x2/2cPrKGt547pox615/9mo2L6/iM7fvJZpIYYzhlseOcdbqWtY2hubrFBRlXlDhYQkRT5kJvXsnzXiIJqnK+vCvqfBmbp6dEoVsq3RDpZ8nPv6SjGshF9VBD4PRJMaMnSjv6whTV+GlpSZAY6V/1i01ndac3fbEZUKpheN4KFFXC+fmqj7kI267R6bDk8cGWN8UosXOwVDXg7KQcFrITlZq0VTlZySRyjgGFiqZjAdtp6koU+K837XUQllI/PrJdm546Fl+/9QJXvKlv/D+m56grW84s/7zv99LbyTGf77mNNyusaUTbpfw8VedyrH+Eb77l4Psbh9kX0eY15y1cvyPUZQFjwoPS4h4MpUpNXCoCngzk9ZHDvdy9fUPZ8oPwtEEVYHRBNzaCm/GLpyvHd5kTzDBcjyk0obh+NgJ/572MJuXVyMiLKv20xGeneNh34nR1pww6mwol64Wjp20PmR1C5luZ4sn2/o5vbUm40hR4UFZSORyTI3HCcRa6AGTmvGgKIUzFNNSC2Vh0T8c55O/3sXpK2u4/0OX8PcXruO2J47zwv/6E5+4bRd/3N3BDQ8/y1svWDchQNLh/A0NXHbqcr7xpwN8688H8bqFV57WMs9noihzjwoPS4hEyuD1jFVanXaaqbThm386wF+e7uLpE0OANZl1JrYAtUFfJpk9lpx64pCLajsrIjvnIZ027DsRZnNLFQDLqgLTcjz0DMX46P/tHPNkNCM8DMUxxkzIeHDGHS2R48EZqyM8TCdromMwSsdgjNNX1lLpt36f+cplFKUcKUR4cPqaL/RyC+e9GUumS3a9UZSFwnBMSy2UhcV/3r6HvuEEn7nyNJqrAnz0lVv40/sv5rXPXcmPHzzCP/xoO8uqArz3JSdNepwPv/wUUmnDr584zgtPbqbOvj9UlMWECg9LiEQqPcHxUG0LC4e6h/jTvk4Anu6wJu3h6NiWVjUV3kw7zUyphWd6f0LVtoNicGR0ovxs7zAjiRSbl1vCQ3N1gK5pOB7u3d/NTx58lj/t68osc8Iqk2nDwEhiQqmFk/UwF46HPz/dNabtaC4c4aEuIzwUPo6dbVaw5OkrazLhn0MxfZqazf7OId7108dKFh6qTE5hjgfrvbHQHQ+RWDIToqmuB0WZnEwbb58KD0r5c/+Bbn6xvY23X7SOU1eMuhlW1Ab5zJWn88d/fT5vOm81X379GVO6eFY3VPD2i9YBcOVZGiqpLE5UeFhCWO00J4ZLAvzogSOkjVVr9rQdjDMUTY4ttQhmCw8zdTxYPy/b8eCIBJuXVwPQbKfZJ1KFTcY7bXfEgwd7AMtB8XRHOOMm6B6KZ8IlJwgPOTpKjM+fmA49QzHe+v2H+dzv9066nVNqUl/hyzuOfDzZ1o/bJZy6oibz/6ctNcdy/4FufruznWd7hqfeWJl3ChEuF4PjIZU2ROIpVtYFAaYUJBVlqRPJhEtqxoNS3kQTKT5yy1Osrq/gPS/K7WZY31TJp644jfPWNxR0zHe/aBNfvepMXrJleTGHqihlgwoPS4h4Ko13QrikJSz88tE2zllbz8amSp7pGCKdNgzFR9tpgp3xMJzAGJOZOPhn7HjIFh4GEYGTltmlFnaboUInHF1DY4WHtr4RhuMpLthgXeh7hmKjGQ9TlFo8eLCHLR+7g0/ctou+yPTD4PZ1hDEGbn382KS5C5H4zEstDnZHWFUXJOhza8ZDHhwhpk+fMJclI4kUXrfgcee/ftRX+KwONwu4pabzPneEB6dUTVGU3EQWQMaDiFwmIvtEZL+IfDDH+veKyG4ReVJE7hKRNVnrUiKyw/66LWv5OhF5yD7mz0VEffZlztfu3s+h7giffs1WgkUKQw143bzqOStwjQugVJTFggoPS4hcpRaOsDAcT/HabSvZtKySpzvCDMWTGDNaigFWxkPSfoI3c8fDxIyHo70jLK8OZC7cy6qtJ50dBbbU7LS3e6ZziO6hWKajxYUbGwHb8ZC0zl3Euph7XIJLJpY4/PD+wxgMP3rgMC/4wj386tG2aZ3f07Z7IxJP8esnjufdLhJL4nZJRjiITsPx0D+cyJRoODdnmvEwFkfY0oleeRJNpDKdZfLhcbtoCPkWtOPBeV+urKsAyITzKoqSm0xXizIVHkTEDXwdeBmwBbhKRLaM2+xxYJsx5nTgl8Dns9aNGGPOsL9enbX8c8CXjDEbgT7gmjk7CWXW7DsR5lt/PsCVZ7Vy0ab8ndwURRmLCg9LiETS5OhqYX24V/jcvOK0Fk5eVkVb30hmMj8+4wGsyVx0puGS9s/LznjoHoplbNUw6njozDHhaB8Y4WjvWPt8ZzhGyBYtHjrYm8moON+2tvVEYpbwkOXOEBH8HvcYx0PPUIw793TwpnPX8Lt/eT7rGkN87NanSE+j1eXTnUPUBL2cvKyKGx56Nu92kViKCp878/ubjuOhbzieKdGoVMdDTgaj2kmgnIkmUgQKeELUWOlf0BkPziQqU2qhf4+KMikZ4WGa9xbzyDnAfmPMQWNMHLgRuDx7A2PMPcYY50blQWDSvohiPRG5BEukAPghcEUxB60Uj1Ta8MGbn6Q66OWjrxivOSmKMhkqPCwhrFKLsfatKltYeMVpLYT8HjbZ5Q6PPdtvrR+X8QBWCUSmRts7vT+hqhylFl3hWKZ1HkCz7XjozOF4eN8vnuBff75jzLLOcIzzNzQS8rl58GAPe0+EWVkXZGVdEBEn4yE1Rnhwxp7tePi/HcdJpAx/u20VJy+v4nVnryIST9FeoPMCLMfDycuqeMO5q9l5bCATBDme4XiSkM+TJTwU7njoi8SptYUHJ4BLMx7GErYdNX3qeChLool0QdeOhkofPQtYeHBaabY6pRYj+veoKJMRiacI+dzlbDVvBY5mvW6zl+XjGuB3Wa8DIrJdRB4UkSvsZQ1AvzHG+SDPe0wRudbef3tXV1euTZQ5ZGA4wad/u4fHn+3n/73ylEy5rKIohaHCwxIikSNcck1DiCvOWME7XrABgJOWVQLw2JE+gDEZD2esrsXvcXHDQ8/OuNTC53ER9LrHlFp0D8UyCfYADSE/LmFCS01jDDuPDXC4JzJmeVc4xoraANvW1vPgwR6rNefyKjxuF/UVPrqHYplSi2z8HnfGaWCM4abtR3nOyhpOtrtrbGyyfhfP2A6KqTDGsK8jzEnLK7nizFYCXhc3PHwk57aReIoKvzuru8Z0HA8J6mz3idslhHxudTyMQzMeyptCSi0AaoLejHtlIeKUWiyrDuBxiTpwFGUKIrFk2ZZZTBcReROwDfhC1uI1xphtwBuAL4vIhukc0xjzHWPMNmPMtqYmtfjPF0d7h/n/fr2L8z97F9ffd4grz2zlijO084SiTJfFcXVXCiKeI+PB53Hx5defmXm9piGEz+PisWct4aEqS3horgrwxnPX8MMHDmfyGAqZPIynOujJlFqk04aeSHyM48HtEpqq/BMyHo71jxCOJgljT1y8VqnEwEiC5io/LTVBPvf7vbgEXnLqMmD0iWnQ68bvneh4cJwbTx0bZO+JMJ+6YmtmveP+2N85xMUnN095XicGo4SjSU5eVkVN0MurTl/BrTuO85FXbJkQlBWJWa1KnTEV2tUimkgxkkiN6e9cGfBoxsM4HGFLMx7Kk5FEqqAwruqAd0F3gnAEwaqAxwrnXcDnoijzwVAsWdbBksAxYFXW65X2sjGIyKXAR4AXGGMyT1GMMcfsfw+KyJ+AM4FfAbUi4rFdDzmPqcw/T7b1852/HOT2ne24RHj1c1bw9ovWs2VFdamHpigLkrK+uivFJZFKTyg3GI/bJWxoqmRPuxXQmB0uCfDOi9dzw8NHuPFhy2k4fjJfCNUB7+jEcCRBKm3GCA9gPSHsGJfxsLd91HlwvH+E9U2VmeC5pip/pitG2sDJdmtOq0Y8zrJq/6SOh19sP4rf4+JVz1mRWV8f8tEQ8rG/c6ig89pnB0s643jRKcu46dE2DnVFOG1lzZhth+2MB79neqUWTulAXUWW8OD3qONhHKOOBxUeypFpOR4W8GTdEQQr/R6qg17NeFCUKRiOp8q9leYjwCYRWYclDrwey72QQUTOBL4NXGaM6cxaXgcMG2NiItIIXAh83hhjROQe4LVYmRFvAW6dl7NRMnSFYzx1bMAqkz02wFPHBmgfiFLl9/APF63nrReupaUmWOphKsqCRoWHJUIylSZtmFBqkYuTl40KD5V+75h1zVUB3nTuGv733kOITL+dJlidLRzhwQmOyw6XdH5OW9/YEElnTADH+6Osb6rMBFA2VwXY2lpDyOcmEk+x2S6XaKj0s7Otn7oK7wTRxe910TMU5+v37OdXj7Xxsq3LqQmOPd8NzZU8U6Dw8EyHtZ0jPFRnOoZMFAUi8STLqwPTLrXoi1i/N6fUAqAy4M3Ukk+XoVjSEnEaQ5O2NlxojGY86ESvHIkm0pkON5NRHfQSS6YzDqeFhiMIVvo91Aa9mvGgKFMwFEtS4SvfW1NjTFJErgPuANzA9caYXSLySWC7MeY2rNKKSuAmu5PWs3YHi1OAb4tIGqvU+bPGmN32oT8A3Cgin8LqivG9eT2xJcyjR/p4988e51j/SGbZ+qYQ56yrZ9uaOq44s3VM3pmiKDOnfK/uSlFJpKzODIUID06JAYwttXB4xws28JOHrOwCpz3ldKgOeOgesm7Au23hYLzjobnanyn3cNh7IkzQ62YkkeJYvyVKZDsevG4X29bWc/+BbtY1hgBoCPnoGYqzqn6i2yPgcfPw4V62H+njok2NvO8lJ08Y66bmSn7zZDvGmCnPdV9HmKYqf6YMwqlTHY5PFBWG4ykq/J6M8FBoO02ndCC71KLK72EoOrMJ9mdu38NPH3qWoNfNaa01vOfFm7hgQ+OMjlVOhDNdLXSiV45EEymax4mNuci03x1JLGjhIeT3UFvhK7hFsKIsVYbjSZqrAqUexqQYY24Hbh+37GNZ31+aZ7/7gdPyrDuI1TFDmUd6I3He9dPH8HqEj77iFLa21nDqimoVGhRljphyFioi14tIp4g8lWd9nYjcIiJPisjDIrLVXn6yiOzI+hoUkffY6z4hIsey1r28qGelTCCesia2U5VawOgTe5dYbTbH01Tl558u3sgpLTOrcct2PHRlHA9jk4GXVQXojcTHOAH2nBjkgg0NuASO9Vs38F1h619nEvPPl2zkY6/ckhFYmqr8hGNJwtHkhFKL125byRvOXc3v33MRP77mXFbVV0wY68bmSgZGEplxTsbTHVZHCwenxWckh+PBqmN1459mO83eIpdanBiI0lIT4O/OXsXeE4N8/77DMzpOOZFIpTNijzoeypNCHQyOA2lwhsJaqRmKJQl4XXjdLsvxoH+PijIpkViKUHlnPCiLhHTa8L5f7KA3Euebb3wub79oPeetb1DRQVHmkEK81T8ALptk/YeBHcaY04Grgf8BMMbsM8acYYw5A3guMAzckrXfl5z1tnqszCFxO0PA557aoeB0tqj0e/I+5X/3izZx8z9eMKOxVAdG67a78jgeltktNZ31I/EUh7sjbG2tYVl1gGN9liWuMxzDJVZJBcC2tfW8+fy1meM02M6A9oGRCaLL67at4j9fcxqbl+cXUDY1jwZMTkY6bXi6I5wRbSDL8RDL4Xiw7aQBz/TCJZ2J9NhSi5mHSw5GE6xpqOATrz6VS09Zxo6j/RhjZnSscsH5XQS9bvqH4wv+fBYj0USaYAHCg1OutFADJsPRZKZcraZiYQdlzgVPHRvg1h2aoaeMMhRLZkR7RZlLvvvXg9yzr4v/90rL6aAoytwzpfBgjPkL0DvJJluAu+1t9wJrRWTZuG1eBBwwxuTuLajMOQnb8VBIqcWqugoCXteUqu9MyizA7moRTWKMoXsojtctE7IVllVbVksnw+HpjjBpA6e0VLGiNshxuxavczBGQ6Ufd56e344g0RmOzSiPYpMtwkwlPBztGyaaSGdEG8jveEinDcMJq1e5x+3C7ZKCwyX7I5bjoXac42GmGQ/haJJq+//5zNW1dIVjY+ocFyJOmcXq+goSKUMkR6mLUlpGEikCBQTTZhwPIwszPHUolsyUq9UGfQzFkplrsQLf/PMBPnbrrlIPQykjhmNJdTwoc86jR/r4/B37ePlpy3nTeWtKPRxFWTIUI03uCeBKABE5B1iD1Qoom9cDPxu37Dq7PON6O+k3JyJyrYhsF5HtXV1dRRju0mQ6woPLJWxqrsqZ71AMqgNeUmnDcDxF91CMhpB/gojRbDsenu2xshz2nrCCJU9pqaa1NpiZHHcNxWiqzF8r3lhpTdCNKazMZDzNVX6q/J5McGQ+Mh0tlmc5Hny5Mx6iyRTGjDoi/B7XtEotKv2eMedSFbBKLWbyZH9wJJGpoz9jlfU2fPzZ/mkfp5xwbPlO6UxfZOnmPIjIZSKyT0T2i8gH82zzOhHZLSK7ROSG+RhXoaUWzt/mQnUKRGLJTEJ/bcXCPpe54HB3hIGRhIoxCmCJ8pG4llooc0v/cJx3/+xxWmuDfPZvTp/xQzRFUaZPMYSHz2L1H94B/DNWGm9mFiUiPuDVwE1Z+3wT2ACcAbQD/53v4MaY7xhjthljtjU1NRVhuEuTxDQyHgD+8eINXPO8dXMyluqsuu3uodiEjhZg5UysqAnw4wePYIxhT3uYkM/NqroKVtQGaR8YIZ02dIajGZEiF9klHOMzHgpBRNi4rHJKx4PT+WJT86jjwedx4XULkXFuhEzgnO2IsISHQsMlE5kJjEOl34MxowJHIpXmL0938a0/H+Bff76Dmx9ry3u8wejoE9nNLVX4PS52HO0vaCzliiM8rLaFh6VaVy8ibuDrwMuwnGlXiciWcdtsAj4EXGiMORV4z1yPK502xJLppZHxEE1SaU+inPftUv17HI8xhsPdEWBpi4PKKMMJ6zNMSy2UucIYw/tvepLOcJSvveHMjONTUZT5YdaysjFmEHgbgFiy4SHgYNYmLwMeM8Z0ZO2T+V5Evgv8ZrbjUCbHmdgW4ngAePlpLXM2lmz7dHcex4LX7eKdF2/gY7fu4sGDvexpH+Tk5VW4XEJrXZBEytA1FKNzMMaWSUIuGypHSxJm4ngAS0y4e+/kbps97YO01gYnlKdU+DwTHA9O5kMo43hwTyPjIT4mWBKsjAewa2P9Hr5/3yH+8/a9AHhcwp72Qa48a7wJCVJpw1BstNTC63ZxWmsNj4/rJrLQGC21sPptL+EWhucA++20dETkRuByYHfWNv8AfN0Y0weQ3XN+rnCuRQU5Huy/zYEFOlkPx5K01lp/hzUL3L1RbLqGYpkyqO6hOM3V5d3JQJl7hrO6wCjKXPC9ew9x554OPv6qLZy+srbUw1GUJcesHQ8iUmu7GgDeDvzFFiMcrmJcmYWIZM9qXwPk7JihFA+nnabPU3pLmTOZGIwm6ArHJgRLOrxu2yqaqvx89e5n2HsizGZbYGittW5Qj/YO0z0Um7T1VoXPk+nMMVPhYWNzJd1DsbytGR840MPvnjrBBRsaJqwL+dwTHA9O5oNTiuH3uogWWGrRF4mPaaUJZJ6oOhPuA50RGit97PjYi7nmonUc7IqQzGFldkIYq7PyNc5cXctTxwczYaRT0TkY5Vt/PkA6XT4BjhnhocEutVigk9Yi0AoczXrdZi/L5iTgJBG5T0QeFJGcQcLFLHmL2k81C8l48HlcBL3uhet4iCVGMx5swXBg6QphYzhil9GB1dJOURw3YKUKD8oc8NSxAT73+728ZMsy3nrB2lIPR1GWJIW00/wZ8ABwsoi0icg1IvJOEXmnvckpwFMisg/L3fAvWfuGgBcDN4877OdFZKeIPAm8EPjXIpyLMgmZUgt36S2M1UHrpqJ/OEHPUJzGHKUWYD0Rfcfz13P/gR4GRhKcYucntNZaE8qdxwZIG3KWamTjuB5meu6TdbZo6xvmXTc8xtqGCj72qi0T1lf4czge4o7jIavUYhpdLerGlVpUZTkeANr6h1lVX0FthY+TmquIp9IczrrJd3Amc9lZHmeuriOeTLOnfXDC9uNJptL8008f47O/28vB7slLUeaT8IRSi9FJzbt/9ji/f6q9JOMqUzzAJuBiLJH4uyJSO36jYpa8jdjCQyFdLcC6XixUl4DVGtDOeAhqqUU2h+wyC4CeyNTtipXFT8R2A+Zq460osyGeTPP+m56gtsLH51+ruQ6KUiqmlJWNMVdNsf4BrKdmudZFgAmPgY0xby50gEpxiGdKLUp/sXUcD0d7h0mmTV7HA8Abzl3NN/50gN5InFNsx8MK2/HgZBE0TyU8hPwc7Z3YTrNQNtq5Dc90DrFtbX1m+Ug8xTt+/CiJZJrvXL0tZxeQkM+dEQQcnNeO4yHgdRccLpmz1MJu1+c4GI71jXCabSF02ns+0xHOnIeDIzxk1ziescra7/Fn+3iO/X0+/ueuZ9h+xCrLGCijrgNOB4SVdU64pHWe4WiC2544jt/j4rKtc1dKVEYcA1ZlvV5pL8umDXjIGJMADonI01hCxCNzNahRx0Nhk4uaoHfhdrXIaqepGQ9jOZwtPAyp40EZdQOq40EpNl+/Zz97T4T536u3jekKpijK/FKMcEllARB3ulrMcPJdTBxrv/OUvLEy/4dAhc/DP128gUq/h5Ntx0NVwEt1wDMqPEwSLmkd31o/U+GhtTZIwOua0Nnipw8dYdfxQf7nqjPY0FSZc18r42HspMnJeKgc09ViasdDIpUmHE3mEB4cx0OCdNpwrH+ElXVWXfnG5kpE4OkcXTmcyZzjQAFoqQmwrNo/ZcDk/fu7+do9+zl1hSUGhefBCt8ZjnL51+6lrW+ieyObcDRBhc9NwOumyu+hz3Y8HO629jsxGJ3zsZYJjwCbRGSdXQ73euC2cdv8H5bbARFpxBKRDzKHRBNOxkNh78fqgHdBOh5iyRTxVDrjKKoKeBGB/gV4LnPB4Z4IaxoqcLtEHQ8KQKYsUTMelGKy6/gAX79nP685s5VLtywr9XAUZUlT+lmoMi8kkk6pRen/y50b8YNd1hOvydphAlzzvHU88KFLxjgKWusqMjXCTZWTh5I5woZ/hsKDyyVsbK5kf9fYyfvu9kGWVfu5ZHP+D7KQ352xjzqMZjw4pRbugoQH50lpXSh3qUU4mqQzHCORMplAu6DdCeTpzvCE44VzOB5EhDNW1fL4JMJDNJHiPT/fwbrGEJ+58jTA6o4x1+xsG+CJtoEJ7T6fOjbAgaz/m3BWp47akDdTanGox/p7ax9YGsKDMSYJXAfcAewBfmGM2SUinxSRV9ub3QH0iMhu4B7g34wxPXM5rpEZOB4WovDgOJAcYdDtEktEyZMVs9Q43D3M+sYQdRU+zXhQgKyOT34ttVCKg1Vi8SR1IR8fz1EOqyjK/FL6WagyL4yGS5b+v9zrdlHhc2cmi1NlNIjIhDIGJ2ASpnY8NMxSeAAr52F/x9jJ+4HOoQnlC+PJ7XgY+1THcjxMXWrhTKDH2wRHHQ/JjBvAcTyAVW7x9ImJwoMjFoxvJ3Xm6jqO9AznnQw8cbSfznCMD1y2mWV2Ev18OB66wtZT0Y5xjoX33/QE//Gb0UYNg9FE5u+lrsKXCZd0rN0dS0R4ADDG3G6MOckYs8EY82l72ceMMbfZ3xtjzHuNMVuMMacZY26c6zHFZlJqsQDDJXMF5dVWeNXxgN1KsyfCmoYQDSEf3VpqoZCdf6SOB6U4fONP+9nTPsh/vuY0LbFQlDKg9LNQZV6Ip6wP9ELbac411QEvHYPWRHKyjId8OE/0qwKeKScwsy21AKtk4fhANDPBNsawv3MoEzyZj5DfnWkZ5+C8zjgevK6M/XwyHCGgftyHp3OTNhRNcqx/BBjNNwA4aVklh7ojEzpVDNoToOxSC4CzVtcBcOeeDnLx8KFeROC8dQ1j3BbTxZjpdcJwhIcT44SDtr4R2vpGMq/D0STVWZ0E+jOlFpbwEI4lJ+RuKPOH08GlUOGheqE6HnLYxmuDXs14wHovD8dTrGsM0VCpjgfFQkstlGKy+/ggX7t7P1ecsYIXa4mFopQF5TELVeacRNKa5JVDuCSMTnY9Lsn0t58OK2zhYSq3BECDIzzMQnTZZDsbDnSN2vUj8RQbCnE8jG+nGUvidknGgWGVWkzteHCe3NeO62rh87jwe1y248GagDvCDFiOh2TaesKYTTiaO8hr25o6nrOyhi/+4ekJbg2Ahw/3cvKyKmoqvAS9bjwumeB4SKbSk7bYfNcNj3H2p+/ivb/Ywa07jhXUvrPTcTyER+vBw9EEQ7Ek7f0jGSEjPMbx4M383g5lnf948UKZP0bi1v914V0tvAzFkmXVsrUQnFKL7K4xNRU+dTww2tFibWOI+pAKD4pFJni5wGuDouQjkRrtYvHxV51a6uEoimKjwsMSwQmXLIdSCxi19zdU+nC5pi+GtNqlBFN1tABoDNntNGdTapHVHQJGW2tuzBMq6RDyuRlOpMZMmobjKUI+d6adU6HtNJ0n93WhiXbBqoCHsF1q0VjpI5jVjmzTMmuMT48rFRmMJgj53HjGCTIul/DRV27hxGCU7/xlbM5gIpXm0SN9nLvO6u5hlcF4JnQdeNn//JVv/vlAzvMwxnDvM934PS7u2dvJv9y4gxseOjLl+WdKLbJEA0dAiMRThO2b1uyMB6vUYtTxsKEpNGY/Zf4Z7WpRaLikB2Nm5qopJblKLWqCmvEAZPJ51jZU2KUWGi6pWJ+NAa9rwmeSokyXb9xzgN3tg/zna7bmvGdSFKU06NV9iZBIlU+4JIx2tphJmQWMOh6aqyYPlgRYVV+ByKjzYSasqgvi87gygkNGeJjK8eC3Jk3RLEdDJJYcYyW12mkWUGoxnLvUAqzJzVDUcjy0ZpVZAGxoqsQlTMh5GBxJZP4fxnP22npeftpyvv3ng2Mm6buODzIcT3HOutEuuVUB7xjHQypt2N81xCOHe3Meu3sozsBIgmuet47tH31xQV00ALqGHMfD6HiygyLb+63vszMeaiu8hKNJeoZi9A0nOG99g73faGmGMr8474VCHQ+OI2qh5TxkhIfAuFILdTxwqCeCxyW01gZpqPQTjiYLcj0pi5uhWFJbaSqzIp02fOWuZ/jyXU9z+RkreMmpy0s9JEVRsiiPWagy5zg3deWT8WDdXMxUeFhZW7jjYVV9Bfe872Kev6lxRj8LwON2sb4xxDOO8NA1RE3QO2krUBitVc3ubDEcT2XyHWA64ZIJ/B7XGDeDQ2XAw1AsybG+kTHBkmAJG2sbQhNaamY7A3LxwctOIZU2fOGOfZllDx+yGh6cva4us6w66BnzNDocTWAMYzpNZJMt2rhdwmmtNew8NpB3HA7ZGQ9OWUW2KHLcFhMGo8lMKY/TevSJtn6AjPAwPqBSmT9G7IwT/zRKLYAFl/OQL1xyYCSx4MpGis3h7gir6yvwuF3U208jtdxCicSSVPhUeFBmxsBwgrf/aDtf/OPTXP6cFXz2ytNLPSRFUcZRHrNQZc5xHA9lIzzM0vHQWOnn0lOWcdFJTQVtv7YxlCltmCmbllXxTOdoqcXG5sopjxmyRYLsrIShcY4HS3hITxm22BeJZybS46n0exgcSdDWP5IRZcaOvXJCS83BaGJCR4tsVjdU8LYL1/Krx9p40p64P3yol/WNoTFOkyr/2K4DTnheW99IxlafjdOW1MnH2Npaw8HuyKSBj8YYusIxfG7rd+WUdox3PMSSKeLJdOa8nDwMpwXn5uVV1FV4l0xLzXLEcfcUWmqRcTwsNOEhR4ZKTdC7IMtGis3hnmHWNlplT4542xPRcoulTiSWWhDBkiJymYjsE5H9IvLBHOvfKyK7ReRJEblLRNbYy88QkQdEZJe97u+y9vmBiBwSkR321xnzeEoLnl3HB3jV1+7lr8908cnLT+VLf3dGzoc0iqKUlvKYhSpzTjxVZuGS9sSwkHDIXLhcwv++ZRsvKFB4KAabmitp6xthOJ60WmlOke8AZJ7ejHU8JAllPdXxe90YM9ryNB99w/G8tYqVfi+He4aJJ9MTHA9gBUwe6Rke46wYjOYvtXB41yUbaQj5+OSvd5NKGx4+1Ms5dr6DQ1VgrOPByVQwZjRELpsDnUNU+NysqLHEi9NaazDGSqDORySeYiSRYnOLlbVxwnYstA+MUFfhxSXW9+FxgX5O+6wdR/sRsdwvy6oD6ngoIdFECpcUXvblXCsWouNBhDHuJufvsX9k6T7dN8ZwpCfCmgarJKw+ZH0G9GhLzSVPJJak0l/ek0URcQNfB14GbAGuEpEt4zZ7HNhmjDkd+CXweXv5MHC1MeZU4DLgyyJSm7XfvxljzrC/dszhaSwqfvloG1d+437iyTQ3Xns+V5+/dtYPmhRFmRtUeFgixJNpfG5X2VyMHSv8VKUK5cSm5kqMge2H++iJxKfMdwCrnSaMdTxYT3XGllrA2ByIXPQNJ6iryC0UVAU8mYC2leMyHsBya6TShoNdo0LAVKUWYE363v/Sk9l+pI8v/nEfg9FkDuHBO0Z4yK5hz1VucaBriA1No26R01prACYtt3DKLLba244KD1FW1lXQXBWgfSA62iI0q6sFwI5n+1lREyTgddNSE1DHQwkZiacIeN0FX4tqKhZmxkM4atWrZ59nrS30LeWWmp1ZrTTBChgGLbVQIBJfEKUW5wD7jTEHjTFx4Ebg8uwNjDH3GGOG7ZcPAivt5U8bY56xvz8OdALz9/RkEfKft+/h/Tc9wVmr6/jNu5/Hc9fUTb2ToiglQ4WHJUIilS4btwPM3vFQCpzuEL976gQwdbAkZDke4mMdD9k3V47wMFVni77h/KUW2QJCaw7Hw8l2V47szhaDI5OXWji8btsqtrRU8/V7rC4V44WH6qBnjA1+IGtSdaBzouPBKVNxaK4O0Fzl56lJhIdOW2jYusISHhzHwomBKMtrArTUBnI6HpzfVziWzEx0ltcEtatFCYkmLeGhUJw8mIXoeKgaZxt3Sn8W2rkUk0wrzQZbeAg5pRYqPCx1IgsjXLIVOJr1us1elo9rgN+NXygi5wA+ILv906ftEowviUjOmyMRuVZEtovI9q6urumPfhHxx90dfOcvB3njuav58TXnzLh0V1GU+UOFhyVCIpXGWyatNGH2GQ+lYE1DCI9L+OPuwoWHjOMhNlnGg7XNVAGTfZF4ZuIynuybtdYcGQ9rG63OHoe7rYcwxhgGC3A8ALhdwsdftSVz7PGOiqqAl6F4MhOY55RaVAU8ExwPQ7Ek7QPRTFtLh6kCJp2OFltbq4HRlprtAyOsqAmwoiZIe380S3gYm/Hg/A4AllcH6InECwr0VIpPNJEuuKMFWH/bLll4k/Xx3Wtg9O9xKXe2ONJjCQ+OEFgd8OJ2CT3aUnPJM94NuNARkTcB24AvjFveAvwYeJsxxnni8CFgM3A2UA98INcxjTHfMcZsM8Zsa2paumaJvkicD9+yk1Naqvn4q07VFqyKskDQd+oSIZFKl00rTYBta+t4xWktnL6yptRDKRiv28W6xhDdQ3GCXnfOCf54QuMcD+m0oW84QX1odELst0P2JmupmU4bBkYSmQT48Tgt++pDvpzhXH6Pm6ZKP8f6LeFhJJEilTZTZjw4nLu+gXc8fz1vuWDNhHXVAatl6JBdTuLYyM9YVZvpYOFwsCt3G9KtrTUc6Boikidg0im1WFlXQV2Fl45wlEgsyWA0yfKaIMtrAhwfGMnY8R1BpdLvweOynD7OE9YWO1uic1AnOqVgJJHK/M0XgohQHfRmAkUXCkOx5JhWmgA1Qev9OzC8dJ/uH+oexuuWzPvQ5RLqQz4ttVAWSleLY8CqrNcr7WVjEJFLgY8ArzbGxLKWVwO/BT5ijHnQWW6MaTcWMeD7WCUdSh4+ftsu+iJx/vtvn4OvjB6qKYoyOfpuXSLEkumy6WgB0FwV4OtvPCvzZHqh4JRbrG8K4XJNXbpSMa6rxWA0QSptMoFqkOV4mKTUYjCaIG1Gw+nG41i6JxNDVtQGOd5vOQWcSVwhpRYOH3r5KVz7/A0TljvHcMotBkYSVAc8nLSsioPdQ2NaB2a30swmEzDZnjtgsiscw+MSaoNellUHODEQy+Q8tNQEaKkJEE2kOdprCSuOoCIimd/ZaKmFNeE5oQGTJSGWSBHwTO+pZk3Qu+AcD07GQzY1mvHA4e4Iq+xWmg4NIR/dGi65pDHGEIkviFKLR4BNIrJORHzA64HbsjcQkTOBb2OJDp1Zy33ALcCPjDG/HLdPi/2vAFcAT83lSSxkfrezndueOM67X7SJLSuqSz0cRVGmQfnMRJU5JZEyqgoXgY3NVfa/U5dZABn3gdPVwqljzu14yG/9d54G5guXdJ6s5upo4dBaF+RY/wjABGfAbHCO4ZQ59A3Hqa3wsaGpkmgizfGBkcy2+zuH8LiENQ3jSi1s58vOttzlFl3hGI2VflwuyXSlaLdFlOU1AVbYgss+O8Mi+7yc39naccKDBkyWhpFEatptzmqC3gUXLjkUm1jK5PO4CPncS7rU4nBPhHXj3v8NlT56tZ3mkiaaSJM2lH07TWNMErgOuAPYA/zCGLNLRD4pIq+2N/sCUAncZLfGdISJ1wHPB96ao23mT0VkJ7ATaAQ+NU+ntKDoGYrx0f97itNaa/jHiyc+CFEUpbyZ8govItcDrwQ6jTFbc6yvA64HNgBR4O+NMU/Z6w4DYSAFJI0x2+zl9cDPgbXAYeB1xpi+2Z+Oko9EsrxKLRYqm2zBoZBWmmAFR7pk1PHQmxEe/GO2gclLLfrsJ6STtdOEKYSH2iB/3N2BMYawPYkrtNRiMhzXiiM89A8nqK3wZnIcDnRFMrkQB7qGWN1QMcF9s8wOmMyX89A1FKO52vqdLa8OsKd9kHZb0GipCWR+h093hBGBSl+28ODDJbDKHkPG8ZAliCjzRzSRJjCNUguwXDULzfEwlMPxAJZraak6HowxHO6JcMGGxjHL60N+nuzrL82glLJgyC6zWwgZD8aY24Hbxy37WNb3l+bZ7yfAT/Ksu6SYY1yMGGP4f7c+RTia5L/+9jll5eJVFKUwCnnX/gCr33A+PgzssPsVXw38z7j1L7R7Em/LWvZB4C5jzCbgLvu1ModY4ZLl09ViofKclbV4XMKZqwtr2SQihHyeUceDbSduyBIQnFKLaCK/46F/2HE85BMepi61aK0NEk+m6R6KZ5VazP7pktMa1Sm16B9JWI4HW6Q5kJXzsL9zKK9oM1nAZOdgjCY7iHRZtZ/uoRhtfSP261HHwzMdQ1T6PGPKYJqq/axpCGUcP1V+DyGfmxMD+oS1FERnWGoxuMCEh1zhkuCUjSzNsoKOwRjRRJp1jWMDahtCPnq11GJJ44jzofLPeFBKxG+ebOf2nSd4z4s3cfLyqlIPR1GUGTCl8GCM+QvQO8kmW4C77W33AmtFZNkUh70c+KH9/Q+x6tmUOSSeKq+Mh4XK6oYKtn/0Up63qXHqjW0q/O4cjods4WFqx8POYwOIwOr6ipzrV9QGEIFTWvLXOzqT8+P92SGMRXQ8xGzhYThObdBLQ8hHbYU309kikUpzpGc4b5mKEzC5J0fOQ9dQLNN6dVlNgLSBp44N0BDyEfC6aaz043EJsWR6govjg5dt5utvOCvzWkRYVhPgxKA6HkrBSCJFYJqlFtVBDwMLKFwynTYMxSe20wSrs8VSdTxkWmk2jiu1CPkIx5LaaWYJM+p4UOFBmUhnOMr/u/UpzlhVy7UXrS/1cBRFmSHFmIk+AVwJmb7Ea7BSfgEM8AcReVRErs3aZ5kxpt3+/gSQV6jQnsXFIV5m4ZILmXwBj/kI+TyZrhZOHXO28BAooKvF3Xs7OXNVbd6uFmsaQjz84Us5d31D3mM4bohj/SMM2mURjlthNozPeHBKLUSEDU2VGeHhSM8wybTJKzy84vQWqgNeXvnVe/nEbbsYsCdnqbShJ1t4qLJKJXYc7c+UTbjt7Ifs8Tisqq+YEEDVUhPghGY8lIRYIj1tx0P1Ast4GE6kMIYJXS3AFh4WmHujWDitNNeOy3ior7Sua9rZYuniuAIXQqmFMv987P92MRxP8V9/+xxtnakoC5hivHs/C9SKyA7gn4HHsTIdAJ5njDkLeBnwLhF5/vidjTEGS6DIifYsLg6JVDrzZF2ZXyr8bobtpzk9kTghn5uAd/TmarSrRe6nfZ3hKE+2DXDJ5uZJf44zMc9Ha7bjwZ74TKerRT6cif7giNWxYzCayIgzG5pCHOiyJhtOR4sNeUotTlpWxZ/efzGvP3sVP3zgMFd//2HAmoykzej5OWJDTySeackHo20yCwnMXF4dVOGhREQTqRllPMST6UnLkcqJIVuEc7JXsqkJLt2Mh0M9EXxuV8Z95dBgZ970aLnFkiUSV8eDkpvfP3WC3+86wb9eelLBwd6KopQns56JGmMGjTFvM8acgZXx0AQctNcds//txGoh5PQl7shqHdQCdI4/rlJctNSidFT4PJmbqr5IPPN0z8E/hePhT3stp88lm6eqYJqc6qCHSr+Htr4RwtEkPrdrjAAyU/weN36Pi3A0yeBIAmOg1i532NBUSVc4xm+ePM43/3zAWjbJjUNdyMenX3MaH3rZZp442s+RnghdYcslMprxMCo2LM8WHuzJTCHlI8tr/HSEY6TSeTVPZY4YSaQITvPvzmlDuVByHiYLynMyHizNfWlhtdIM4h7XirjBvib2qONhyRKJOWKdCg/KKIPRBB+/7SlOaanm7RetK/VwFEWZJbOeiYpIrd2bGODtwF+MMYMiEhKRKnubEPASRvsS3wa8xf7+LcCtsx2HMjmJpMHr1nDJUhDyuce008zuaAFZjoc8wsPdeztpqQlwSsvswpREhBW1AbvUIlGUMguHqoCXwWgyYyGvrRgVHgCuu+Fx2vtH+PRrthZ0Y/nSU5cDcOeeTrqGbOHBdjw0hHx47IlLS83ok9MVtghRSGDm8ppgpoRDmT+MMbbjYfqlFsCC6WzhCA+53De1FV4SKcNwfGG4N4rJ4e5h1o3Ld4DRsF1tqbl0iWjGg5KDL/x+H13hGJ+98jR9eKYoi4BC2mn+DLgYaBSRNuDjgBfAGPMt4BTghyJigF3ANfauy4BbRMT5OTcYY35vr/ss8AsRuQY4gtXbWJlDEqk0vmnWVSvFocLvIdI7DFhlA9lP7GE0XDKXjTyeTPPXZ7q4/MxW7PfSrGitDXK8fwS/x1WUMguH6oCHwWiCvnHdN87f0MBV56zivPUNvGxrS6azxFSsaQixqbmSu/Z0ZJ52O8KDyyU0V/k5PhDNU2pRgOPB/j/YeyJMc9b/x1+f6SLodbNtbX1B41SmRyJlSBsITjNcsmahCQ+TlFo4bqD+kcSSmmSl04YjvREuyhHMq6UWSibjYZrXBmXx8uiRXn7y0BHedsE6nrOqttTDURSlCEx512OMuWqK9Q8AJ+VYfhB4Tp59eoAXFThGpQhYpRbqeCgFIZ+b4ZgTLhln8/KxQYeTdbV4+FAvkXiKS06ePN+hUFbUBnn8aD+Nlf6CshAKpSroJRxNZgIha2zHQ8jv4TNXnj6jY166ZRnf/ctBTl9ZC4zNsFhWE+D4QDRPqcXU5/XcNXUsrw5w3Q2P8f23nc1Zq+v45p8P8F937OPCjY38+JpzZzRmZXJGbHFtunkzjotloQRMDtkdXnK5exw3UP9wfNL2t4uNjnCUaCLNmhyOh+qgB49LtNRiCaOOByWbeDLNh27eyYqaIO97yYQphqIoCxT1LS0R4sk0PrWplQQn48EYQ08knqlndhARfB5XzlZyd+/txO9xceHGwtt3TkZrXZD+4QQnBqIT2k7OhuqAh3A0Qf+INXGoLcKxLz2lmWTacMvjbVT6PVRk9Xd3Oltkl1o4jodCzqs+5OOX/3g+9SEfb/rfh7n6+of5/O/38fLTWvj2m58767EruXECVKdbarHQHA9Oh5dcIlhN0Hr/L5RzKRZOK811DROFBxGhPuTT0qclzFA8ic/jUju9AsC3/3yApzuG+I8rTlUxSlEWEfpuXiIkNFyyZIT8bobjKSLxFPFkOmdLTL/HRSxhOR4+dPOT3Lmnk83Lq9jTPsj5GxqmbU3Ph/OE9UDXUFHToasCHo73j9AXsSZTddNsOZqLM1bV0RDy0TEYm1AX7jgdlmeVSaxpCFHhc7O2oaKg46+sq+Cmd17AW65/mPv2d/Phl2/mHy5aX5SSFiU3UftvfLrhktWZcMlk0cc0F0z29NZxPAwssc4Wh7utcrO1jbnfnw2Vfm2nuYQZjqW0zEIBrPuTr969n1ee3jLrUG1FUcoLFR6WCImUKbi+XikuFT4PqbShvX8EII/w4CaWTGOM4Y5dHVQHPPRG4kRiKV5zZmvRxuIID8m0KWqpRXXAKrVwwiWL4aZwu4QXbm7ml4+2ZTpaOFx5Vit1Fb4xgkxN0MtDH37RtFLRm6r8/OofL6BjMMraHBZwpbiMLBHHw2RdLTKlFgvkXIrFEbuVZrZLKZuGkE9LLZYwkVhSn2wrpNOGD928k4DXxcdetaXUw1EUpcjoVX6JoO00S4fzFKetzxIeGnIIDwGvVWpxYjBKbyTOv7xoE2+5YC3GmKI+gW+tG73pL2apRVXAY2c8xKkOeCa0y5spl56yzBIeqsYKD6evrM1kP4wdx/TPKehzq+gwT0QzwsP0rkVet4sKn3vBtNMMxyzbuD9HoG+tXWrRv8QcD4e6I6xuqMh7bagP+XjWDuFVlh5DsaS20lT45WNtPHyol8/9zWk0VwWm3kFRlAWFzkSXAMYYO+NBLeSlwHmKc7TPuqnOW2qRTLP7+CAAp66wAiiLbftvrgpkWlEW0nayUKoCXkYSKbqGYtTlOL+ZctGmRgJeFytq9QZkMeA4HqZbagGWq2bBOB6iSaryTKICXhc+jyuTh7JUONwTYW2OfAeHhkqfllosYYbjKSq01GJJE0um+PIfn+Y5q2p53bZVpR6OoihzgAoPS4Bk2gBoqUWJyAgP9tM8p3VcNn6Pm1gixa7jg4jAKS3VE7YpBm6XZPIRZuIOyIcjYhztHSlKsKRDyO/h5n+8kH+6eGPRjrmUEJHLRGSfiOwXkQ9Ost3fiIgRkW1zOR7H8eCfgfBQE/QuoK4W+W3jIkJt0LukMh7SacORnmHW5cl3AMsJNhRL5mwrrCx+JnvPKEuDX2xv4/hAlPe9+CTNWlKURYrORJcAiZQV6KalFqXBeYpztNfOeKjM4XjwWo6HXccHWNcQmtMbsBV2zkN1sLiOB7BcHTVFCJbMZsuK6qK6KJYKIuIGvg68DNgCXCUiE4pmRaQK+BfgobkekxMuOd1SC7D+XheK4yEyhW28tsK7pEotTgxGiSXTrJnU8WAJsup6WJpM9Z5RFjfRRIqv372fbWvquGhTcbp4KYpSfuhMdAkQT6rwUEqySy18blfO5G6nq8Wu44OcsmJu3A4OKx3hoYiOByeosn84QV1F8Y6rzIpzgP3GmIPGmDhwI3B5ju3+A/gcEJ3rAUVnUWpRE/QumK4W4WiSyklKmWqDviVVanHYaaU5SZaKU4LWM7R0fi/KKFaphQoPS5UbH36WE4NR/lXdDoqyqNGZ6BIg7jgetNSiJIw6HoapD/lyfqj6PW46w1Ha+kYy+Q5zheN4KGqpRVZ5RTFLLZRZ0QoczXrdZi/LICJnAauMMb+d7EAicq2IbBeR7V1dXTMeUHSGXS1ggWU8xPJnPADULDHHw6EeS3iYLMS10XaC9URi8zImpbywwiU142EpEk2k+MafDnDOunou2NBQ6uEoijKH6Ex0CZBIWRkPfnU8lISQ/RRnMJrMGSwJluPhcI+VAXHqipo5HY/T2aK4pRajx6otcqmFMjeIiAv4IvC+qbY1xnzHGLPNGLOtqalpxj9zVsJD0LtguloMxaZyPCwcEaUYHOkZxudx0VKdPyS2PqSlFksVY4y201zC/PShZ+kMx3ivuh0UZdGjM9ElQMIptfDoBb0UVGQ9xWnIke8AYydiW+YoWNLh5Vtb+LeXnsxJzVVFO2Z22UatllqUC8eA7GjwlfYyhypgK/AnETkMnAfcNpcBkyN2xsOMuloEvYRjSVJ2WG45M9UkaqllPBzqjrCmvgLXJG12tdRi6RJPpUmmzYIRHqYK7RWR94rIbhF5UkTuEpE1WeveIiLP2F9vyVr+XBHZaR/zK7JEZuAj8RTf/NMBzl/fwHnr1e2gKIsdFR6WAHENlywpoay61ckcDwDNVX6aqiZ2vSgmNRVe3vXCjZNOAqaLCg9lySPAJhFZJyI+4PXAbc5KY8yAMabRGLPWGLMWeBB4tTFm+1wNKNPVYgZlXzV2CU94AXS2CE/SThMsV9BIIrVkOjgc7o5MWmYBVmccr1voUcfDlEQTqUxo9GIgErPeB7nyj8qNAkN7Hwe2GWNOB34JfN7etx74OHAuVgbPx0Wkzt7nm8A/AJvsr8vm+FTKgp88eITuoRj/+uKTSj0URVHmAZ2JLgGccEmfCg8lIfvpbl7hwU75n+t8h7miUkstyg5jTBK4DrgD2AP8whizS0Q+KSKvLsWYoskUPo9rRqKX07K13AMm48k0sWR60oR+JxNloZSOzIZ02nCkd3jSYEmw2ozWh3z0DGnGw1Rc9d0H+czte0s9jKIRiVnv6QXieJgytNcYc48xZth++SCW2wzgpcAfjTG9xpg+4I/AZSLSAlQbYx40xhjgR8AV83AuJSUSS/KtPx/gok2NnLOuvtTDURRlHlgQV3lldiQ0XLKkuFxChc/NcDxFQ17HgyVOzHW+w1zhdgkhn5tIPKXhkmWEMeZ24PZxyz6WZ9uL53o80XhqRmUWMOp4KPdsBGcSNVXGA0D/SILmSXIPFgPtg1HiyTRrJ2ml6dAQ8mvGwxQYY9jTPrioHiRE4gtKeMgV2nvuJNtfA/xukn1b7a+2HMsnICLXAtcCrF69ejrjLjt+9MAReiJx3nOpuh0UZamweD65lLyo46H0OG3CnAC18TjW84XqeIDRLhnqeFDyEU2kCXhndh3KuATKvNRiqICnt0450lLIeXBaaa5tqJhy24ZKH90qPEzK4EiSaCJN+8Ccd7+dNxaY46FgRORNwDbgC8U6ZrGCfkvNUCzJd/5ygBec1MRz19RNvYOiKIsCnYkuAZyuFprxUDpCdsBk/owHa/2WBSw8OF0y6jTjQclDNJmaUUcLWDiOB0d4mDTjIWhdB8r9XIrBoe6pW2k6NIR89Go7zUnpCFuCQ/vACOkFELRaCEN2xsMCaac5VWgvACJyKfARrNyc2BT7HmO0HCPvMRcL8WSa99z4OH3DCc12UJQlxpQzURG5XkQ6ReSpPOvrROQWO733YRHZai9fJSL32Mm+u0TkX7L2+YSIHBORHfbXy4t3Ssp4nFILn5ZalIxRx0Nu4eFFpzTz9uetY3X91E8Fy5WqgBeRUeeDooxnpAilFuWeizBUSKlFxvGw+J/uH+mJ4Pe4WF5ASUl9yK9dLabghO10SKQM3YskD2PYfs9U+BaE42HS0F4AETkT+DaW6NCZteoO4CX2fXMd8BLgDmNMOzAoIufZ3SyuBm6dj5OZbxKpNNfd8Bh37unkk5efyhmraks9JEVR5pFCrvI/AL6GFXaTiw8DO4wxrxGRzVhpvy8CksD7jDGPiUgV8KiI/NEYs9ve70vGmP+a3fCVQhjtarEkujOVJU5adz7hYWtrDVtbF2a+g0NVwEN1wIu7iN0ylMVFNJnGP0PhoXqhOB6itvAwieOhpmJhnEsxONIzzOopWmk6NFT6GI5b3T5m6oxZ7HQMjpZYHB+ILoqMkIxYtwBKLYwxSRFxQnvdwPVOaC+w3RhzG1ZpRSVwk90V81ljzKuNMb0i8h9Y4gXAJ40xvfb3/4R1vx3EyoT4HYuMRCrNu3/2OH/Y3cHHX7WFq89fW+ohKYoyz0x5lTfG/EVE1k6yyRbgs/a2e0VkrYgssxXcdnt5WET2YIXl7M5/KGUu0IyH0lNh31DlC5dcDKysC+rTSmVSrHDJmV2HQj43bpeUfcZD2Cm1mMTxUOX34HbJksh4aB+IsqI2WNC2zvWxJxKntcB9lhpjhIf+kUXxxHihZTxMFdprjLl0kn2vB67PsXw7sLWIwywrkqk0//rzHfzuqRN89BWn8LYL15V6SIqilIBizESfAK4EEJFzgDWMrVXDFi7OBB7KWnydXZ5xfVYf4wmIyLUisl1Etnd1dRVhuEuPTFcLFR5KhjNpqlnEHR8+/PJT+NHfn1PqYShlzGwyHkSE6oCn7F0ChUyiRKxrQf/I4hfq2gdGWFFb2FN5xxGmLTXzc2IwmimbPN4/UuLRFIdI3Mp4qPCpy2Uxkkob3nfTE/zmyXY+9LLNvP2i9aUekqIoJaIYM9HPArUisgP4Z+BxIOWsFJFK4FfAe4wxg/bibwIbgDOwXBH/ne/gCzHB9/Fn+/jqXc+UehgZNOOh9FQHvDSEfAXZjRcqFT4PdYvY0aHMnmgiRcAz88lFTdDL4EiyiCMqPoWUWoDVUnOxOx5iyRTdQ3Faagp0PFRaXX96tLNFXjoGY6xrCFHhc3O8f3F0tojEknhckunupCwejDH8201PcOuO4/z7ZSfzjhdsKPWQFEUpIbP2tdliwtsA7FCcQ8BB+7UXS3T4qTHm5qx9OpzvReS7wG9mO45y4ubHjvHjB49w7QvWZ7oVlJK4drUoOf/0wg1ceVbOttyKsmQYSaQIzuKpZnXQW/aOB6fUIjRFUF5NRfmfy2zpGLCcC8trCnM8ZEottGQrLx2DUZbVBEgZs3gcD7EkIb8HOw9BWUQ8eqSPmx8/xj9fspF/unhjqYejKEqJmfVMVERq7WRfgLcDfzHGDNoixPeAPcaYL47bpyXr5WuAnB0zFiqddrurrnDp7KKPHO6l135qpBkPpWdNQ4hz1zeUehiKUlKiiTSBGWY8gOV4KPfJ+lA0SaXfM6W7aSk4Ho4PWBPjFQU7HqxbCW2pmZ8TA1GWV/tpqQnQPrBIhId4KhPArCwuHnu2D4C3XLC2tANRFKUsKKSd5s+AB4CTRaRNRK4RkXeKyDvtTU4BnhKRfcDLAKdt5oXAm4FLcrTN/LyI7BSRJ4EXAv9azJMqNZ224NAxOPbmaTg+PxbhVNrwxv99iOvvPQRoqYWiKOVBNJGalQusOuAt+3DJoViioHT+2grfos94cCbGLQVmPFT6PfjcLnU85CGZStM9FGN5dYDW2iDHpllq0T8czzyQKCccx4Oy+Hji6AAr64I02mVUiqIsbQrpanHVFOsfAE7KsfxeIOcjH2PMmwsd4EKk0xYcOrPSp/uH45z/mbv5wt+ezitPXzGnP39gJEE8mc6kXyeS2k5TUZTSEy1CqcVgmTseIrEUIf/U51izFBwP9sS4pcBSCxGhodKnGQ956B6KkzbQXB3A7XLRPRQjlixczHv/TU8QiaX42bXnzfFIp8eQCg+Llh1H+zlzdW2ph6EoSpmgj8CLjDEmU2KR3fbqYHeEkUSKO3d35Nu1aDg21UypRSqNCLgXcbChoijlTSptSKTMrMIlq4MeBkeSGGOKOLLCGBhO8H+PH5tyu3AsSWVg6u41tRVewtEkSduRthg5MRClJuilYoq8i2zqQ76yfCpfDpyw7ymWVwcynUJODBTueth9fJC9Jwan3nCeGY4XJtYpC4vOcJRji6Tlq6IoxUGFhyIzMJIgbt9IdmRlPDghUA8c7Jnzm2bHptqTJTx43S4NblIUpWREE1azo9lmPMRTaaKJ+Z+s/3z7s7zn5zs40hOZdLuhaIKqQkot7Na6g9HcJXgnBqK84Av38OiR3ukPtkxoHxgp2O3gUB/yaTvNPDgPM5bXWKUWAMcKDJiMJlIcH4jSN5wou3KlSCw5ZRirsvB44ugAgAoPiqJkUOGhyGTnOmQ7HhzhoWMwxqHuyW9cZ0vfcHzMv4mkwa/BkoqilJARW3iYTalFTWayPv8Tp4Nd1nX74BTX76FYsuCMB7DK8HJxw8PPcqRnmIcOLVzh4Xh/lBW1hQVLOjRW+rXUIg/OPUVztZ8W+/daaEvNZ3uHR7/vGZ5ky/mn0PeMsrDYcbQPt0s4dUVNqYeiKEqZoLPRIuN0tHC7JJP1AHCsbwSn0uGBgz1zOgbnpq3Xdj4kUmm8GiypKEoJyTgeZhkuCZSks4UjPBzqmsrxUFi9uiOi9Oc4l0Qqzc8efhYov0nidDgxGC24laaD5XhQ4SEXJwaieFxCY8ifcZK0F+h4yH7gkS1ClAPD8RQVWmqx6Hji6ACbl1fNSmxWFGVxobPRIuOIDZuaK8c4Ho71R9nUXMWyaj8PHJhb4cERHMKxJLFkingyrcGSiqKUFKc8wj/LUgugJAGTjtPh8FSlFrEkVYEChIcKW0TJETD5h10ddIVj+D0ujixQ4SGaSNEbibNimsJDQ6WPkURq3rpALSQ6BmM0V/lxuYSA101jpS/TsnQqDmcJD+X2N6XhkouPdNrwxNF+LbNQFGUMKjwUGaeV5tbWmkwQFFilFq11Qc5f38CDB3vnNOehN8u62xdJkEiltZWmoiglxXE8BL2z62oB8+94GIwm6LZzByYrlTPGFF5qMcm5/OTBI6ysC/KSU5eX3dPpQmkfcDpaTK/UoiFklaCo62EiHYNRmqtHhZyWmmDBpRaHeyLUh3zUh3w82zu35Z7TIZFKE0+mqdSMh0XFwe4I4ViS56jwoChKFjobLTKd4Sghn5t1jSHC0WTmqc3xgRFW1AY4f0MD3UMx9ncOFeXnRRMpHjk8tgY4OxG8JxLLhEsqiqKUitFwyYWX8eCUV1QFPJmSi1yMJFKkDVQW4HjIl/GwvzPMAwd7eMO5q1nXUEH7wAjx5MLrfOGUAEw3XLIh5AfQzhY5ODEYZXmW8LCiNpDJj5qKw93DrG2oYHV9RVmJWcMx67pQoY6HRcWOo/0AnKnCg6IoWehstMh0hmM0VwcyNwedgzEisST9wwlW1AY5f30jULych18+2sbrvv3AmLKO3kg8kyfRG4lbjgcVHhRFKSEjRRAequ0Jfa7yhLnkYLclFL/gpCaOD4xkRJTxDNkdKgpxPDjnMj7j4ScPPovP7eJ121axuiFE2kBbX/lMFAsl43iYZrhkfaXteIhoZ4vxdIzLzLAcDyMFOSgP90RY2xhidX1FWZVaDMWd94zmACwmdhzto9LvYX1TZamHoihKGaGz0SLTNRijqcrPMlt46BiM0m7XYLbWBllVH6S1Nli0nIfD3RGMgba+0acevZE4q+srMt9bGQ/6X60oSulwMh6KU2oxv/X/h7oiuMQSHozJH843FCtcePC4XVQFPPRniSjD8SS/erSNl5+2nMZKP2sarOv4kTJ6Ql0ozufedB0PjbbjQUstxjIcTxKOJmmu9meWtdYGicRTeVuyOozEU7QPRFnbEGJNQwXH+8vHRTNsv2c042Fx8cTRAU5fWYPbpfliiqKMorNRm+6hGPft7867/tEjfbziK3+d8klbZzhKc5WfZfbNQUc4lhEFWmuDiAjnrW/gwYM9pNOzz3lwjn1iYKzjYWNzFWDdvCVSRjMeFEUpKaOlFjO/FnndLip87nkvtTjQHWFVfQUnL7euq/nKLaYjPADUVnjHZDzcuuM44ViSN523BoA1toC8EDtbHB+IUh/yTdvh4jgetNRiLM5n/NhSC6el5uTlFkfsTAfH8ZA2cKzAEo25xnnPhDTjYdEQTaTY0z6o+Q6KokxAZ6M2n/vdXt72/UfyWhYfPdLLruOD3LW3Y9LjdIZjNFcFMgFQnYPRTPiTc5Nw9to6+oYTRamzdG4enKdLxhh6InHWNVbgdonleEhpVwtFUUpLMUotwMp5mO9wyUNdEdY1hljbGALyd7bIlFoUkPEAUBv0ZTIejDH8+IEjbF5exXPX1AHQVOUn6HWXlTW+UE4MjM0jKJSQz43P48q0hVYsOuyOWdm/05Za6/uphAeno8W6hhBrGqy/4SNTdGeZLyJ2xoM6HhYPu44Pkkwb7WihKMoElozwcMvjbfzvXw/mXJdKG+7a20k8lSYSz127223bPu/ck194GIolGY6naK72Ux3wEPC66BiMcrx/BLdLaK6yXBDr7JvXYthnndpfp552OG61z2ys9FNX4aVHSy0URSkDYkUSHqoD3nltp5lOGw51R1jfWEl1wEtjpT8TNjme8AwcD07Gw+NH+9ndPsibz1+DiCUUi0jZhQEWyvF+K1B5uogIjSGfllqMw8lxyu5q0eo4HgYm72xx2Bau1jRWZMp3yuVvKhJ3Si0WTsaDiFwmIvtEZL+IfDDH+ueLyGMikhSR12Ytf6GI7Mj6iorIFfa6H4jIoax1Z8zfGRUXJ1hShQdFUcazJGajTx0b4N9/+STf/ktu4eGxZ/syts5wHgtvl90m88/7uoglc4sTnc6NQZUfEWFZdYCOwRjH+0dYXh3AY0/+nScOz87yiUMklqTPLv1wbJjOedSFfNRV+OizwyX9WmqhKEoJcTIeZlNqAfPveOgIRxlJpFjfZF231zeG8rbUnE64JNjnYl/Df/LAESr9Hq44o3XMNqsbKsqq/WGhtA9Ep91K06G+0qfhkuNw2nNnh0s2VvrxuKQgx0NDyEd1wEtzlR+/x1U25TuRBVZqISJu4OvAy4AtwFUismXcZs8CbwVuyF5ojLnHGHOGMeYM4BJgGPhD1ib/5qw3xuyYmzOYe5442k9LTSCTdaYoiuKw6Gejw/Ek777xcRIpQ1c4ljON/I+7R10M4TwhTd1DMTwuIRJPcX+eYMhOW5xorrIutsuqAnQMRjk27smP88FfiH12Z9tAXqdGdo2mU2rh2FMb7H7dTlcLdTwoilJKilVqUR30TBmmV0ycPIf1tlNtbWMFB/MID87T24JLLWzHQ28kzm92tnPlWa0TLOeO46GQzgXlwnA8ycBIIlMKMF0aQn7NeBhHx2CUSr9njKjldgnLawKZ1qX5ONQdyZQJOS6acgksjSy8cMlzgP3GmIPGmDhwI3B59gbGmMPGmCeByRI8Xwv8zhhTHv8RRWTH0X51OyiKkpNFPxv91G/3cKg7wt+ctRIYLUlwMMbwx90dVPism+HJHA8Xbmykwufmzt25yy0c4cEJlmyu9lulFgMjmXwHAJer8A/+nz50hE/fvienYHLMDpZc3xjKOB767Ju1+pCPBvupUSJlVHhQFKWkRBMpPC6Z9bWoOji/pRaOyOC0hVvXWEn3UCznZ0V4mo4HJ+Ph548cJZ5MZ0Ils1nTUEE0kc58viwEMq00p9nRwqFBSy0m0DEYHdPRwmFFbTCTI5WPwz0R1tpOS7D+psrG8WCXtxb6nikDWoGjWa/b7GXT5fXAz8Yt+7SIPCkiXxKRif/ZgIhcKyLbRWR7V1fXDH7s3NIzFOPZ3mENllQUJScF3QGKyPUi0ikiT+VZXycit9gXzIdFZGvWupy1cCKyTkQespf/XER8sz+dsfxh1wlueOhZrn3+el77XEt4ONY39snAga4hDnVHeNnWFgAG87Rp6x6K0VoX5AUnNXHnno6cHSlGSy1sx0N1gBODUdr7o5laTIc1DaGCPvjb+kbytm9z8h22ra2jIxwjlTYZx0N9luNBMx4URSk10UR61m4HsMoT5lV46BqiwufOCMpORs/h7onX5KFYEq9bCi5tq63wkjbw/fsOcc66ek5aVjVhG6c18kIKmGzvd4SHmZVaNGipxQTyhXWuqAlM2qFiOJ6kYzDGusaKzLLV9aGycdFEYklcMvsSrIWEiLQApwF3ZC3+ELAZOBuoBz6Qa19jzHeMMduMMduamprmfKzT5cm2AUDzHRRFyU2hV/ofAJdNsv7DwA5jzOnA1cD/wJS1cJ8DvmSM2Qj0AddMe/RTsLYxxJVntvK+F5/MyjrrBuhY/9ibtz/Y7oUrz7IE61xt2pKpND2ROI2Vfi49ZRkdgzGeOj4wYbuucAyfx0V10FLul1X7iSbSJNNmjOMB7CcOBXzwO+LC4RzW3ra+EXxuF6etrCWVtkpJeu2bNUt48NM/kiCaSGk7TUVRSspIIlUU4aE64CUcS5IqQjviQjjUbXW0cAIfHeHhYPfQhG2Hokkq/Z7MtlNRE/QCllvuzTncDpCVCVQEa3wyleaS//oTX7nrmVkfazKO26V/K2aa8RCyPjuH4/NXUlPudAzGcgsPtUE6BqN53w+OYOWUWoB1/zGSSGWyq2bD/fu7+cRtu2YsYgzFkoR8hb9nyoBjwKqs1yvtZdPhdcAtxpjMDacxpt1YxIDvY5V0LDgeP9qPS+C01ppSD0VRlDKkoNmoMeYvQO8km2wB7ra33QusFZFl5KmFE+sT5hLgl/b+PwSumNEZTMJJy6r44t+dgc/jYnlNAJdMdDz8cXcHp6+sYVOzZaPNlfHQOxzHGKu12SWbm3HJ2FwIB6uVpj/zAbosR/q0QyEf/Om0yTzJyNW+ra1/hNa6IK12HW37wAi9kQQ+t4tKv4eGkA9jrPH7tJ2moiw5Ckhff6+I7LbdaneJSO7ZbxGIJVJFearpTNbzlcUVm4N2K02HNQ0ViOR3PEynVr22wjL6NVb6eempy3Nu01obxCWzDyMG+NO+Lg52R/jRA4dJpCYrP58djuNhWU1Ot/iUNISs34uWW1ik04bOcHRMRwuHFbVBkvaDh1w4Dy2ySy1WF7GzxZfvfIYf3H+YfR3hGe0/HEstpHwHgEeATbZr14dVMnHbNI9xFePKLGwXBPb98RVATodxufPE0X5OWla10P5PFUWZJ4r1GPwJ4EoAETkHWIOlAuerhWsA+o0xyXHL5wyv28Wy6gBtWZbEznCUHUf7efEpy6gKODezE4UH5wO9qdJHXcjHtrX1eYSHaKZlJowVHsY7HjL22Uk++DvDVj4DwKEcN7ltfSO01gZZXm0du30gSm8kRl3Ii4hQb9+8GYOWWijKEqPA9PXHgW22W+2XwOfnajzRZJEcD7bwMB+dLWLJFG19w5l8B7DCMVfUBDmUy/EQS06rVr22wjqX15+9Kq8rzedxsaI2WJQwwJ9vP4rbJXQPxbl7b+esj5ePE4MjNFb68Htm9v/dUGkLDxowCVgPDxIpw/KcGQ/WfUa+cotDtmA1xvFQpPKdo73DPHzYeib1u50nZnSMoXiSigXUStO+b70Oq0xiD/ALY8wuEfmkiLwaQETOFpE24G+Bb4vILmd/EVmL5Zj487hD/1REdgI7gUbgU3N+MkXGGMMTbf08Z2VtqYeiKEqZUqzZ6GeBWhHZAfwz1s1s7p6T06SYQTqttcExjofHjvRhDFx0UhMBrwuPS3KWWmSEB1tUuPSUZvaeCE/4oO8cjGXyHWC88DD2SYVjn81VQuHglFmIwJEcT7uO9Y2wsi6YCfCyhIc49SFrnM5TIwCvllooylKjkPT1e7JS1R/EEoznhJF4imCRMh5gfoSHZ3uGSZvRjhYO6/K01ByKJqkqsKMFwOkra/jHizdwzfPWTbrd6vqKWU8SO8NR7t7byVsvWEtzlZ9fPHJ06p1myPH+mbfSBDKiec+Q5jyAFSwJ5GxP6DzUcDpbjedI9zCNlf4xglhrXdC6r5ilmHXL41aFwfqmEHfsmpnwEJmmWFcOGGNuN8acZIzZYIz5tL3sY8aY2+zvHzHGrDTGhIwxDcaYU7P2PWyMaTXGpMcd8xJjzGnGmK3GmDcZYyYqm2XOkZ5h+ocTnLG6ttRDURSlTCnKbNQYM2iMeZvdm/hqoAk4SP5auB4socIzbnmuYxctSKe1LjhGLNh7IowInLysChGhOujNad/ttu2ejZXWhP6Szc0A3DPuiVFnODYmddpxP1QFPBlHRWYsjn12kg/+Nlsk2bqiZoJAEU2krMDL2iC1FV4CXhcnBkbojcQzgkN95ajw4FPHg6IsNaabvn4N8LtcK4ohAFvhkrO/DlXbE/t8QcDFZLSjRW7hYXxd+3QdD36Pmw9ctpm6LJE4F04m0Gy45bFjpNKGq85ZzWufu5J79nVmJrTFpn1gZMYdLWD0s1YdDxYZ4SHH79QReI5P4njIDpYE6+9uRU1wVuU7xhhuefwY562v503nrmHviXBOMW4qhmMpQr6FJTwoudlxtB/QYElFUfJTlNmoiNRmdaV4O/AXY8wgeWrhjHW3dg9WH2OAtwC3FmMsk9FaG+TEwGgI074TYdY2hAjarTSrAp5JSy2cm6ENTZWsrq8YY1WNJlIMjCTGlFqE/B6q/J4J+Q6QZZ+d5CmW43i4cGMjxweiY1pqOgLKyvogIkJLTTDjeHBuYuuzbmY1XFJRlHyIyJuAbcAXcq0vhgBcrFKLmor5czwc7LImUutyOB4Go0l6x02Mp5vxUCir60P0RuIzzrUwxvCL7Ud57po6NjZX8rptq0gb+OWjbUUeqUX7QHRWwkO9ZjyMoWPQugfJFS5ZHfBQ6ffkbal5uHtsK02HQlt65+Pxo/0c6o5w5ZkreelWK5/k909N3/VgvWcWTqmFkp8dR/sJet2ZzDRFUZTxFNpO82fAA8DJItImIteIyDtF5J32JqcAT4nIPqx64n+B/LVw9j4fAN4rIvuxMh++V6yTykdrnRXC5Dw92HsizMlZ7cvyCQ/dQzEqfO7MDaWIcMnmZu7b382I3YPaESeySy2cn7mmYezTBoc1DZN/8Lf1WXWyp7RYY8x+4uW4IVprrWMvrw7QPhClJ8vxUFeRVWqh4ZKKstQoKH1dRC4FPgK82k5UnxNG4sXragG5OxAVm0PdQzRV+Sc41hwhYvwT3qHY9EotCmXNLMMAH3u2nwNdEV63zaqkWdsY4tx19dy0/WjRWyoOxZKEo0lacgjuhVLhcxPwujJdmpY6JwaiiIyWe2YjIqyoDeR0PERiSTrDsTH5Dg5rGioKaumdj1seO4bf4+Jlpy2ntTbI6Str+P0Myi0i8bkR65T5Z8fRfk5bWYNHHbaKouSh0K4WVxljWowxXrtu7XvGmG8ZY75lr3/Arnc72RhzpTGmL2vfCbVw9vKDxphzjDEbjTF/O5c3vA6O8+BY/wgj8RSHeyKcvDxLePDn7g/fFY5N+MC/ZHMzsWSaBw52A7C/0yrHax4X/vT1N57Fx191KrlY0xCa1OrY1jdCa11F5mlF9k2uk1XhtAltqQlwtHeYcDSZeVrkdbsytmQttVCUJceU6esicibwbSzRYe7SBoFYMl0cx8M8ZjyM72jhkFd4iM5NvboTRjzTieIvHjlKhc/NK05fkVn2um2rONwzzMOHJmtYNX3a7QnwbBwPIkJDyK+OB5uOwSgNIX/ekOiWmmCmhWk2TjesnI6Hhgp6InGGYtMvWYon0/z6yeO85NTlGVHusq3LeeJof96Sj3xEFl5XCyWLZCrNX5/p4t9/+QQ7jw1omYWiKJOypGajziT9WN8Iz3SGMQY2ZwkP1cH8jgenzMLh3PX1VPjc3L23k2gixX/8djettUHOXls/ZrsNTZUTOlo4rKmvoG84kffJXVvfMCvrgpmbhuych7a+YTwuyYRNtdQG6LRdF9n1wg32uDVcUlGWFoWkr2OVVlQCN4nIDhGZblu4ghmJpwgU4TpU4XPjdklOkbjYHOqOsKFp4qRtZV0Qj0vGCA/JVJqRRIpKv3fC9rPFcTzMxBofiSX5zZPHecVpLWNEkZef1kKV38PPtxc3ZPL4gOUonE24JFjlFprxYNExGGX5JK1JV9QGMy1Ms3FKOdc2TnRdrqm3/q5nImbds6+T/uEEV541Ghlzmd0Odrohk5FYkpBPSy0WEum04ZHDvXzs1qc47zN38ebvPcztO09w+XNW8I7nry/18BRFKWOWlMy8IsvxELd7mI9xPARyh0t2hWNsaBpbs+b3uHnexkbu2dtFhe9pDnZF+Mk1505Luc/YZ3uG2dpaM2ZdOm041j/CS7cup6bCS12Fl8NZNwjH+kdoqQ3gdlklFMuzbvKyu1nUh3wc6o5oO01FWYIYY24Hbh+37GNZ3186X2OJJlOZPJ3ZICLUBL1z7ngYGE7QE4nndDx43C5W11eMER4isf+/vTuPj7uuEz/++kwmyeS+m7M5W1p60JamF0c5VCwqBZFyiiyrIgu47rqHq4/1t+rqY9fHQxdEVJYV8UCRQ9CCeEERUI7epSe0TdM0V5M09znJzOf3x/f7nU6SmclMMlfS9/Px6KPNXPl8Z6bfme/7+z6Msrv0CJRaZDgSyU1LmtZkixf3tzDgdHHTmvnjLk9JSuCalSU8u7uRr2xe6ilhmanWnplnPIAxUnM6GQ+HW3p56JVjfHvLirBk2MyEc8zNQ9uOct2q0nEjWUPV2jtCSYDnsyTLwZkBJ8Oj48uZrPenvx4PAA2dAywpyQxpPc/tbiI/PZlLF+R7LqsuSOe8wnR+f6CVOy8OPKXF4nJrhkYl42G2uetnu3jp8GkciTbed34h11xQwuWLCmL+/00IEf/OqaPR1CQ7uWlJNHUP8W5rH45Em2esJQTu8eCrtvLKxfNo6h7ikdfquHVdOZcszJ90m0DKzTMOvr5MtvWNMOrSlOUYXw4q89MmZDwMjWtaWezVdMq7t4NVdiGlFkKIWJp4UDQTmQ47vT721eFU12GUz1Xn+z5gnDhSs2/ECISkR6hR3vzcVBo6Q58a8NTOU1QXpLG6ImfSdTfVzmd41M3z+5rDsUTAGKWpFBTNMPCQm5Y0rXGaz+xq5LfvtLCnoXtGvz8c7n/pPR7cdoyvvXBoRo9zunfY50QLi3VSZWKZQ33HAAUZyT4P7MutLJoQg1ndg05ePnKazStKJtXyb1pWzI76TjqCfN0Gncb/4dk2TvNcNuR0se3IaW6sLWPXv3+A7916IZuWFUnQQQgRlHPuaLQ0O4WmriGOtPZyXmGGJ2MAjLNK/c4x3O6zzbZGXW66BkcnlVoAXGGO1SzNTuGLVy8OeS2eD34fXyatiRZWeUhVXpqnXhOMchErKAHjv+TleY3RtLIfZKqFECJWtNbmOM3wfDmNRsaDZ6KFj1ILMAIP9WcGPJ8XnoyHCJRagFGaF+pBYl17Pzvqu7ixdj5KTW4wfEFZFouLMnhqR/jKLVp6hihI99+PIFgFGcl09DtxjrlDut+OeqNnxc768PauCNUbxzt4+NXjFGU6+PO77Rxq7p3W44yMuegccPqcaGGxAg8tPePLLerPDFDlI9sBjP9D2amJIZfvvPBOC6MuPa7MwrJpaRFuDX86dDqox7L+z6TKOM1Z43BrL24N7z+/UDJVhBAhO+eORkuzUzwZD94TLcA4i6Y19Hk1W7JSPX1lPBRmOvjq5qU8/PHVk7qeByM92U5+ehInOyZ/8FtTK+abgYeKvDRazJGazjE3p/uGx2U8ePeRyE2bnPEgpRZCiFgZMQ8eHYnh2Q9lpvhuBBxOJzoGSLApT0r6RFUFaQyPumk1pyT1WxkPESi1AKM0r7l7iFFX8AfiT+1sJMGmfB4kglG2sqV2PvsaezjSOr0D44lmOkrTsmp+Nk6Xm3cau4O+z8DIGAfNA/ztMQw8dA86+fyT+6jKS+PX915MerKdH7x6fFqP1WaO0izMDNTjwXi+myZmPJwZ9NnfwVKRm8qpEAMPz+5u5LzCdJb6KM84vziD8tzUoMdqWo0tZZzm7HGwqQeApRPKg4UQIhjn3NFoaU4K9R0DdPQ7x/V3gLNj2rz7PFhjMvO9sgi83XFRJcvLpr8DLs9NHZfJYLEyHqxxmdaXh5NnBvnN3ia0hhqvWck5qYmerIbslLNBkLOBBxmnKYSIjeFR48ymwx6mUosoBB7qOvopz031G7StmtD01yrTi1TaeHluKm59dqLRVMZcbn61u5ErFs2bNObZ20dXlZKYoHgyTFkPRuBhZo0lAdZW5QHwVt2ZoO+zu6ELl1tTlZ/G7pNdjIUQpAkXrTVfem4/Hf0jfOfmVRRlObhtXTm/faeZkwGmWPljjf8uDJDxYGU8ejeY7B8Zo93PKE1LeV5aSFk09R0D7G7o5voLy3xm0Cil2LSsiDeOdwSVkSSlFrPPweZeclITA/YcEUIIf869wEN2CmNmauziovERe2v+unefh/Z+44PcV8ZDOKyYn82ehm46J3TvbuwaIj89ydOMzWpw9qdDrXz5NwdYX53Lh5cXe26vlKI4y0F2auK4ukur7EJKLYQQsTJkBh7C0VwSoldqUR3goM0qwagzAw/W2duMiGU8mD2BgjxD/ep77bT3jXBjbVnA2+WmJXHVkiJ+vaeJkTHXjNaotabFbHw8U7lpSSwuyuDNEAIPO050YlPwqUurGHC6ONLaN+N1hOrpXY28uL+Vf7pqkeekxN9eUoXdZuOR1+pCfrzTZsZDoJ4ZyfYECjKSx/V4sAJi/kotAMpzjQzQYLNontvThFJw7coSv7fZtKyIUZdm25Gpyy2s/zNSajF7HGjuYVlpls/AkxBCTOWcOxr1LkmYmPGQ4cl4OBt46OgzAgK+ejyEw81rynG63Dyza/zZpsauIUq9ejhYXzq/9cf3SE+28+DNq8b1pwAoynSMK7OAsxkT2Sm+MzaEECLShkfDXGrhSKR3eBSt9dQ3nga3W3OiY8DnRAtLYYaDlMQET4PJAU/aeORKLQAagjxr/uSOU+SnJ3t6EQVy45r5dA2O8tKhthmtsXd4jAGnKyylFgDrq/PYdbIr6IDI9vpOlpRkcsUiY5t3RLncor5jgK9sPciG6rxxYwULMx18bHUZT+9qpK1v8tjLQKxSnsIAWStgTLZo7vEKPJjvk4oAgYeK3DRcbj2pKaUvWmue29PERTV5ATNaVpZlU5iZHFS5xdm+KBJ4mA2cY27ebe0LeQqKEEJYzrnAg9WsMS8taVIWg3WmyjuFt93szhypjIdFRRmsqczhF283jGtq2dg16FkrGGf4ctOSUAoeuGkV83ykXX7q0mr+7rKacZetqczhhc9eIh8UQoiYCXepRVZKIqMu7cmkCLfmniFGxtwBRyDabIqKvLMjNSNdajEvI5lkuy2o1Pj2vhG2HWnjYxeWBtXf55IF+ZRkOXhy58zKLVrN5obhKLUA2FCTx/Com32neqa8rXPMzZ6GbtZU5lKSnUJpdgo767vCso5gjLrcfO7JvSQm2Pj2jSuwTTgx8JmN1Yy53PzoL/UhPe7p3mGS7DayUwP3kSrJTvGZ8RCox0Moky12neyioXOQ61cFzqCx2RQfXFrEq++1e0op/LGulx4Ps8PRtj5GXZplJdLfQQgxPedc4MFqyLi4OGPSdZ5Si5HxPR4yku0RHRV027oK6s8M8sZxI6XU7dY0dQ+NCzwA3HlRJV/dvNTv2M4PLClkS+34We1KKZZJEyAhRAxZAQJHmEotMlOsIHFkRmpawYRAGQ8A1QVnxxxbaeORCjwoZTS6DKbU4rk9jYy59aTPA38SbIobVpfx+tH2SQ0KQ2GdcS8JQ6kFwLqqXJQKrs/D/qYeRsbcrK3MBaC2Moft9Z0Ry4qZ6MGXj7LvVDf/df3ycZmVlsr8ND60vJifv3WS3uHgy4RO9w5TlOmYMrW9OCuF5u5hz/bWnxmkMDM5YBlDhWey1tTvqV/tbiIlMYFNy4qmvO2mZUUMj7p59d32gLfrj3CWkAivg01G41ZfjUWFECIY51zgITs1kcLMZC4snzzTPDNlcqlFe/9IxLIdLJuWFZGTmsgvtp8EoK1vhFGXHjcuE+Cz71vIJzZURnQtQggRbpHIeAAi1ufBGqVZ42eUpqUqP42GzkFGXW76h8dITUqYVAIXThV5U08h0Frz1M5GVlfksGCe/4yNibbUzkdreGZn47TXZzU3DFfGQ3ZqEucXZfLm8akDD1ZZRa0ZeFhTmUt73wgNIU5tmI7tJzr53ivHuLG2jA959V6a6O7LaugbGeNnb54M+rFbe4YDTrSwlGQ7GBp10T1o/J+o7xigMkCZBRjlG0l225TvqeFRF799p5lNy4qCChKsrcwlJzWR3x8MXG4R6fIkEV4Hm3tIS0qY8n0lhBD+nHOBB6UUv/vcRu67csGk63w1l+zoG4lYfweLIzGBG1aX8ceDp/nN3ia+/JsDAJMyHoQQYjYaiUCPByCkM8ehONExQFpSwpRB58q8NMbcmsauIfpHxiJ+AFWeawQ6Ap3F33Oqm2Nt/WxZHTglfqL5ualsqM4zpyZNL0ugtWcImzLKQsJlfXUeuxu6PMErf3ac6KQ6P83zmq0xAxDbT0S2z8Ogc4x/fHIv5bmp/Mc1SwPedllpFhvPK+Cxv56Ycnssp3uHA060sFjZnFbWSf2ZwD1KwCiLKM9NnXLaxitH2ugdHuOjq3yPZZ3InmDjA0sK2Xa4LWB/DqvHQ2oEM0pF+Bxo7mVpSdakMiIhhAjWORd4AKNbdrKPM2/J9gSS7LZxX2ajkfEAcMvacsbcms/9ci876ju5Y0MF681xYkIIMZtFYqoFQM9gZAIPx9v7qS5InzK9vbrg7EjN/pExMiIceKjIS2XQ6fL0HvLl6Z2NpCQm8JEV/icP+LN5ZQl1HQMcMFOqQ9XcM8y8DMe4yUoztaEmj5ExN/tOdfu9jdut2XmyyxNsAFg4L52slMSI93l4cX8rTd1DfOOjy4MKPN1zeQ0d/U6eDqKfhtaa070jFAUReCi2Ag/dw/QNj9LR7wzYWNJiBB4CZzw8/vZJCjOTuXiB7zJPX65eVkzfyBhvHPOfrTIwYmQJyYFs/HO5NYeae6VfmBBiRs7JwEMgmQ77uLphI+Mh8hMhqgvSefCWVTxy+2q2f+n9fPXaZWH7ki6EELEU7lILqywukhkPU50tBqjKN0oZ6szAQ3qERmlayj2TLXwfKA45Xbywr5mrlxdNq9fE1cuKSExQbN3XNK31tfSEZ5Smt7WVRp+HQGM132vro2dolDVVZwMPNpuitiKHHScjm/Hw9M5TVOalclFNcCcK1lXlsqo8m/99rY6xKcZY9g6PMTTqCirjweqr0dIz5AkkVAVoLGkpz00NmEWz71Q3fz12hr+9uCqkMqKLFuSRnmwPON1iwBn5LKFIUEptUkq9q5Q6ppT6Nx/Xb1RK7VZKjSmlbphwnUsptdf8s9Xr8iql1NvmYz6plIqrUWQnOgYYGnVJzzAhxIxI4GGCDEcifeaX2eFRF73DY1HJeADYvKKEq5YWkWSXl0UIMXd4mkuGKaU6kj0ehkddNHUPebIZAslJTSTTYedERz/9w2MRHwtYkRt4CsEfDrbSNzLGltXBNZWcKDs1iY0LC3jhnZZxU5aC1dI9TEmY+jtYslITWVqSGbDB5A4zq2GtV8YDGP0e6toH6AiQIWLpHnTyny8cCuk91XBmkLdPdHLD6rIps2MsSinuuXwBjV1D/HZ/S8DbnrZGaQYxnjQ/LZmkBBtN3UOe5qiVQQTPrCyajn6nz+sffvU4GQ47t64rn/KxvCXbE7hy8Tz+eKgV55jvAMvAiGvWjdJUSiUA3wOuBpYAtyillky4WQPwN8AvfDzEkNZ6pflns9fl3wTu11ovALqAT4Z98TNwsNmYLCONJYUQMyFHuBNkOuyeHg/WaDBfoyuFEEIEZ9js8ZASpsDD2dHH4Z9qcfLMIFpPPdECjIPIqoJ06jsGjYyHCB9EleWkopT/KQRP7zrF/NwU1lXl+rw+GJtXltDSM+xp1hgsrTUtPcMUBXGQHKr1VXnsbuj22xdhx4lOCjOTmZ87PuixtspoIh1MucVjf63n0b+c4Cdv1Ae9rmd2nUIpuP7C0PppvG/xPBbOS+cHfz4esJ+GFXgIptTCZlMUZTlo7h72TFqpyA0u8ADQ0Dm5z8Px9n5+f7CVT2yoIMMReJynLx9bXUbX4CjP7fHdsNQqtZhl1gLHtNZ1Wmsn8EvgWu8baK3rtdbvAIFTWkzKiFpdCTxjXvQT4LqwrTgMDjb3kmS3hdSwVgghJpoy8KCU+pFSqk0pdcDP9VlKqeeVUvuUUgeVUneal1/hlU62Vyk1rJS6zrzux0qpE17XrQznRs2Ed8bDsbZ+ANnRCiHEDFgHjMlhai6ZmGAjLSkhIhkPde3Gfr+mILj9fnV+Gic6BuiLQsZDkt1GSVaKzykEpzoH+euxM2xZPX9GNfPvP78QR6KNrfuaQ7pfz9AoQ6MuiiMQeNhQk4dzzM2ehu5J12mt2VHfyZrK3ElZB8tKs0iy26YMojjH3PxiewMAP3mjPqjGj2635le7m7hkQb7P8ZmB2GyKuy+r4UhrH9uOtPm9nXXyI5ipFmCUW7R0D3HizABFmY6gyjXLzeCEr+kfj7xaR1KCjTsvrgrq90+0cWE+y0uz+N4rx32WlUSjIWsElALeDToazcuC5VBK7VRKvWV9JwbygG6ttRVJDfUxI+5AUw/nF2WQGMb+LUKIc08we5AfA5sCXH8vcEhrvQK4HPi2UipJa/2KlU6GEckdBP7odb9/8Uo32zudxUdChsNOr5nxcFQCD0IIMWPDoy6UguQwlpFlpST6DDxordnf2MOBpp5pPW5dCGnqYEy2aOoeomvQGfEeD4DfKQS/2t2IUsZZ5plIS7bz/vMLeXF/C6NT9CDw1myO0gz1IDwYtZW52Pz0eWjsGqKlZ5i1PrI8ku0JrCzLZucUgYc/HGylvW+Ez2ys5syAk+f2TN3j4s26MzR1D7GldnplLZtXllCancJ3tx3zm/XgKbUIMuuyJCuF5m6jx0NlEP0dwJiepdTk8p3WnmGe3dPITWvmT3uyl1KK+65cQEPnIM+/MzmQNeicfaUWYVChta4FbgUeUErVhHJnpdRdZuBiZ3t7e2RWOIHWmoPNvSwpkf4OQoiZmfJboNb6NSDQp7YGMsxUsXTzthPzX28Afqe1jvxA7RnKcNg9GQ9H2/ooynR4RrcJIYQI3fCoC4c9Ieg6+GBkpiR6mku63Jq36s7w1ecPcsk3X+Gah/7C9T94g6On+0J+3Lr2AQozk4M+IKoye0FE6yCqIi910tlpt1vzzK5GLq7J94xVnInNK0roGhzlL8c6gr5Pa68xxjESpRZZKYksLcny2efBymZYU+m7vGRNVQ4HmnsZdPovy/npm/WU56byhU2LWV6axf+9Xjdlj4und54iw2HnqiWFIWzJWYkJNu65ooa9p7r9Ps+ne0fITk0MujdKSXYKrb3DHG/vD6pUCIy+K0WZjkkNSx/9Sx1uDZ++tDqox/HnA+cXsrgog4e2HcM14TmdpaUWTYB3tKnMvCwoWusm8+864M/AKuAMkK2UsnYgfh9Ta/2I1rpWa11bUFAQ+uqnobFriJ6hUZaVSn8HIcTMhOP000PA+UAzsB/4nNZ64mmSm4EnJlz2DaXUO0qp+5VSfsPp0Y7uZjoSPT0ejrX1s7BQsh2EEGImhkfdOMJUZmHJTEnkeFs/X3jmHdZ+4yVufuQtfv52A+cXZ/CNjy4jI9nO5365129jO39OdPRTnR/8fr/a6wAvKhkPeal09DvpHzl7IP3WiTM0dg2xpXZm2Q6WyxYVkOmw8/ze4MstPBkPYW4uadlQk8deH30edtR3kumws6gww+f9aitzcbm1zzINgEPNveyo7+L29RXYbIpPb6ymrn0gYAlE7/AovzvQyuYVJTNqmHrD6jKKsxx856WjPrMeWnuHKcwIPpBTkp2CW0P34CiVQYzStJTnpo7rG9I96OQXbzdwzQXFzM8NLnPCH5tNce8VCzjePjBpwkU0+qJEwA5goTmFIgnj++3WKe4DgFIqx/q+q5TKBy7GyBjWwCsYJ+kA7gB+E/aVT9PZxpKS8SCEmJlwfBP8ILAXKAFWAg8ppTxhUaVUMbAc+IPXfb4ILAbWALnAF/w9eLSjuxmORAadLkZdbo619UuZhRBCzNDQqCtsjSUtBenJ1HUM8OL+Fi5ekM/3b7uQPV/+AD+8Yw23ravgv65fzqGWXh546b2QHreuY8CTxRAM75KMqGQ8WDX5Xmeon9nZSIbDzgeXFoXldyTbE9i0rIg/HGwNqt8BGGMc7TYVsSlQ66tzcbrc7D45vlHk9hOdRimGn74WqytyUAq/fR5+9lY9jkSbJ2jzoWVFlGan8MjrdX7X8sK+FkbG3NMus7Ak2xO45/Iadp7s4s3jk7M5TvcOBzXRwuI9yjTYUiEwsmi8Sy1+9uZJBpwu7r48pCoAvz60vJjqgjS+u+3ouEySQadr1vV4MPsw3IfxnfYw8JTW+qBS6mtKqc0ASqk1SqlGYAvwv0qpg+bdzwd2KqX2YQQa/ltrfci87gvA55VSxzB6Pjwava0K7GBzLwk2xeIi38E9IYQIVjgCD3cCz2rDMeAERlDBciPwnNbaU4yrtW4xbz8CPIbRJTguWN3S323tY9DpYuE82dEKIcRMDI+6wjZK0/KlD5/P459cx84vv58Hb1nFh5YXjzuIuWppETfVzufhV48HPaGha8BJ9+DouCyGqaQn2z0H29EqtYCzUwh6h0d58UAL18zw7PtEm1eUMuB0BTzz762le5jCTAcJM2hsGcgaH30ezvSPcLx9wG+ZBRhZjIuLMn2+B3oGR/n1nmauXVFKdmoSAPYEG397SRXbT3Sy91S3z8d8ZtcpFs5LZ0XZzM8Ab6mdT2FmMt95+eik6073DlMYQiDHu8wmlIyHirw0OvpHGHSOMeR08dgb9Vy5eB6Li8KTWp9gU9x7+QKOtPbxsvl+0loz4BwjbfaVWqC1flFrfZ7WukZr/Q3zsv+ntd5q/nuH1rpMa52mtc7TWi81L39Da71ca73C/PtRr8es01qv1Vov0FpvMb8fx4UDTT0snJce9n24EOLcE47AQwPwPgClVCGwCPA+VXALE8oszCwIa4TQdYDPiRmxYAUe9jQYZ1Uk40EIIWZmeNRNcpi/tJZmp3DJwnyS7f4f98vXLKE0J4XPP7V3XGmCP3UdRkPh6hAyHuDs6M1oBB6s1Herz8Nv32lheNTNjTM8+z7Rhpo88tOT2RpkuUWkRmlaMhyJLC8d3+dhhzkm0xqb6c+ayhz2NHRPapb59K5TDI26uH1DxbjLb1oznwyHnf/zkfVwrK2f3Q3dbKktC0vPEkdiAndfVsPbJzrHbduYy01730hIz6n3RBErQBWMcq/31FM7T9E54OTvwpTtYNm8soT5uSl8d5tRVjLodKE1sy7jYTbrGRrlh6/XBRzh6ovRWFL6OwghZi6YcZpPAG8Ci5RSjUqpTyql7lZK3W3e5D+Bi5RS+4GXgS9orTvM+1ZiNOF5dcLD/ty8/X4gH/h6WLYmDKxZ1bvNetCFEngQQogZGR51kRLmHg/BSE+2c/+NK2nqGuI/nz805e0PNfcChNTjwbi9GXiIQo+HrJREslMTPanxT+8M39l3bwk2xUcuKGbbu22eJp6BtPQMRWSUprf1NXnsPdXNkNMo/9hR30my3cby0uyA91tTmcug08Xhll7PZW635vG3TlJbkcOy0vHPXXqyndvWVfC7/S2Tmi4+s6uRBJviulXhm3Z4y9py8tOT+e62s1kPHf1O3Dr4iRZgfH/JcNgpyXKEdHbaClLUtQ/wyGt11FbkBMwimY7EBBv3XL6Adxp7eO1oBwNms08JPETPc7sb+fpvD/Ol5w5M2TzV0tY7TFvfCMukv4MQIgyCmWpxi9a6WGudaKaOPaq1flhr/bB5fbPW+iozbWyZ1vpxr/vWa61LJzab1Fpf6XX7j2ut+8O/adOTmWJ8CO5u6CI/PYmctKQYr0gIIWa3SJRaBKu2Mpe7L6vhyZ2n+OPBVp+36Rse5avPH+Q/th6kPDeVspzQGiRa9fQZydGZgFSRa0y2CPfZ94muWVGCc8zNHw74ft4sWmtaeoYjMkrT2/rqPEZdml1mn4cd9Z2snJ9N0hRjWmsrjYyI7SfOllu8drSd+jODk7IdLH9zUSUJNsWP/nrCc9mYy82zuxu5YlEB80Jo+jgVI+uhmr8eO+MZ/RnqKE1LeW4qNSGeMLEyHr7/52M0dQ9xzxXhzXawXH9hKcVZDr778lEGRozgUVqypO9Hyx0XVXLvFTU8sb2Bf3p6H2NBjMs9aAZjl0rGgxAiDKJ/CirOWaMzT54ZlDILIYQIg+Gx2AUeAP7h/eexpDiTLz67n/a+s6XTWmue39fM+779Kj9+o55b15Xz/H2XYE8I7aPxopo8ynNTmZ8b2QNvS3leGifPDEbk7Lu3C8uzKctJYeu+wOUWXYOjjIy5KQrxIDlUaypzSbAp3qzrYGBkjIPNvUGdmS/OSqEsJ4Wd9WcbU/70zZPkpydz9bJin/cpynKweUUpT+44RfegE4DXj3XQ1jfCDavDMz3E263ryslLS+LBbccAY6IFEPJz+j83ruRr1y4L6T7ZqUlkOuwcaOplUWEGVyyaF9L9g5VsN8pKdp7s4uXDpwFIS5KMh2hRSvEvH1zMP191Hs/taeKzT+yZcuqPNdFCSi2EEOEggYcJMrxSZaWxpBBCzNyQM/xTLUKRZLfxwM0r6RsZ44vPvoPWmrr2fm5/dDuffWIPhZkOfn3PxXz9uuVkpYaetXBBWTav/esVngaFkVaRm0pT9xC/isDZd29KKTavKOGN42fo6Pff6665ewiAkuzIBh7Sk+1mn4dOdjd04XJr1lQFVxKwtjKXHfWdaK1pODPIK++2ceva+QGzJT69sYqhURc/f7sBMKaH5KYlceXiwrBsj7fUJDuf3ljNa++1s6ehizYr4yErtCkhi4oyPD1HQlFhNqP8u8trIpI9Y7lpzXzy05P53itGgGUWjtOc9e67ciH//uHz+d2BVu5+fFfAyTUHmnqpyk/zlCELIcRMSOBhAu+d68JCyXgQQoiZMppLxvbj5rzCDL6waTEvHW7jrp/tYtMDr7OvsZuvXbuUX997MSvmZ8d0faEoz0vF5da0941ww+rwNpWcaPPKElxuzYv7W/zepqXHOEguzop8xseGmjz2nerm1XfbsSkjKyMYtZW5nBlwcqJjgMffPolNKW5d57vMwrK4KJON5xXw2F/raesd5k+HTnPtypIpSzum6/b1FeSkJvLgy0dp7R0mwabIS4vMeNKJlpZkUpWfxkcu8J0BEi6OxAQ+s7GarkGjb0iqBB5i4lOXVvP165ax7Ugbn/rJTgadvpvvHmzpkWwHIUTYSOBhAu+MhwUFEngQQoiZuveKBVyzoiTWy+DOiyq5eEEefzp0mg9fUMzL/3QZn9hQGbERkJFSYdbkG2ffI5MWb1lclMl5hekBp1u09BgZD8URzngAo8/DmFvzxPYGlpRkBn0m1pp88frRDp7ccYoPLi0MamLEXZdW09E/wmce34XT5WZLBAM9acl2PnVpNa+82862I+3My0iO2nvzK5uXsvW+i0MuM5qOW9eVk2NmFqVLj4eY+fj6Cr61ZQVvHO/g5kfemjRytmdwlFOdQ9JYUggRNhJ4mCAxweZJCV4gGQ9CCDFjt64rj1jdeChsNsUjt9fy+3+4lPtvWhmxEoVIs5pZXreyNGJn371tXlHCzpNdNJklFRO19AyTmKDIj8LZ+dqKHOw2xYDTFdLkhZqCdHJSE/nOy0fpGRrlExsqg7rfxQvyOL84kz0N3SwtyYz42d9PbKgg02HncEtvyI0lZ8KRmBC1dPq0ZDt3bawhwabIjVJGh/DthtVlfP+2C2nuHmLLw29y+6Nvs9scJ3+wxejvII0lhRDhIjluPmQ47CTZbRSkyweiEGL2UkptAr4DJAA/1Fr/94Trk4GfAquBM8BNWuv6aK8zmtKS7Swumt1fpAszHfzv7avZUJMXld93zYoSvvXH9/jv3x1hdXk2CTaFzaZIUMbfO+s7Kcx0YIvC2fm0ZDsXlGWxu6GbtSEEHpRSrK7I5aXDp1lUmMG6IHtDKKW4a2MV//jkPrZEoKnkRBmORD55STX3v/QehZlz9zvIZzZW86HlReTK5LCY27SsmI3nFfD4Wyd5+NU6rv/+G1y+qIBCMzArgQchRLhI4MGHDIed8tSkiDZYEkKISFJKJQDfAz4ANAI7lFJbtdaHvG72SaBLa71AKXUz8E3gpuivVoTqg0uLova7KvLSuKgmj+f3NfO8nwkXkS758HbJgnz2nuqmNoTAAxjlFi8dPs3tGypC+ny/dkUpdpuNq5aGv6mkL39zcSWPvXGCmjlc7mmzKU9DSxF7qUlGFspt6yr4yZv1PPJaHd2Do5RkOciTk3BCiDCRwIMPf/++hZ6xmkIIMUutBY5presAlFK/BK4FvAMP1wJfMf/9DPCQUkpprXU0Fyri388+uY7+4TFcWuNya9zm3y63RmuYF8Wz85+5rIYrFs+jICO033ndqlJO947wsQtDy1yw2VRUe5RkpSTy8ucvI00aL4ooS0u2c8/lC7h9fQU/f7uB4iD6oAghRLDkU82Ha1dGZia6EEJEUSlwyuvnRmCdv9torceUUj1AHtDhfSOl1F3AXQDl5eWRWq+IYwk2Na1Ro5GQlmxnVXlOyPebl+Hgyx9ZEoEVhZ+cZRaxlOFI5O7LamK9DCHEHCPNJYUQQgSktX5Ea12rta4tKCiI9XKEEEIIIcQsI4EHIYSYm5oA79l/ZeZlPm+jlLIDWRhNJoUQQgghhAgbCTwIIcTctANYqJSqUkolATcDWyfcZitwh/nvG4Bt0t9BCCGEEEKEm/R4EEKIOcjs2XAf8AeMcZo/0lofVEp9Ddiptd4KPAr8TCl1DOjECE4IIYQQQggRVhJ4EEKIOUpr/SLw4oTL/p/Xv4eBLdFelxBCCCGEOLdIqYUQQgghhBBCCCEiRgIPQgghhBBCCCGEiBgJPAghhBBCCCGEECJi1GxqYK6UagdOhni3fKAjAsuJB3N122S7Zpe5ul0Q/LZVaK0LIr2YeDDN/TDE1/skntYC8bUeWYt/8bQeWYtvsi8OLJ5eq0g7V7b1XNlOOHe2dbZvp9/98KwKPEyHUmqn1ro21uuIhLm6bbJds8tc3S6Y29sWbfH0XMbTWiC+1iNr8S+e1iNrEdNxLr1W58q2nivbCefOts7l7ZRSCyGEEEIIIYQQQkSMBB6EEEIIIYQQQggRMedC4OGRWC8ggubqtsl2zS5zdbtgbm9btMXTcxlPa4H4Wo+sxb94Wo+sRUzHufRanSvbeq5sJ5w72zpnt3PO93gQQgghhBBCCCFE7JwLGQ9CCCGEEEIIIYSIEQk8CCGEEEIIIYQQImLmdOBBKbVJKfWuUuqYUurfYr2e6VJKzVdKvaKUOqSUOqiU+px5ea5S6k9KqaPm3zmxXut0KKUSlFJ7lFIvmD9XKaXeNl+3J5VSSbFe43QopbKVUs8opY4opQ4rpTbMhddMKfWP5vvwgFLqCaWUYza+ZkqpHyml2pRSB7wu8/n6KMOD5va9o5S6MHYrn13ibT+slKpXSu1XSu1VSu2M8u8O+j0Xw/V8RSnVZD4/e5VSH4rSWuLmcy7AWqL+3Jj71+1KqX3mWr5qXh6TfW6A9fxYKXXC67lZGY31iODF2744nOJt3xop8bSfjKR42+9Fmpqjx0G+zNnAg1IqAfgecDWwBLhFKbUktquatjHgn7TWS4D1wL3mtvwb8LLWeiHwsvnzbPQ54LDXz98E7tdaLwC6gE/GZFUz9x3g91rrxcAKjG2c1a+ZUqoU+HugVmu9DEgAbmZ2vmY/BjZNuMzf63M1sND8cxfwgyitcVaL4/3wFVrrlTGYk/1jgn/PxWo9YPxfXmn+eTFKa4mnzzl/a4HoPzcjwJVa6xXASmCTUmo9sdvn+lsPwL94PTd7o7QeEYQ43heHy4+Jr31rpMTTfjKS4m2/F2lz9ThokjkbeADWAse01nVaayfwS+DaGK9pWrTWLVrr3ea/+zDenKUY2/MT82Y/Aa6LyQJnQClVBnwY+KH5swKuBJ4xbzJbtysL2Ag8CqC1dmqtu5kDrxlgB1KUUnYgFWhhFr5mWuvXgM4JF/t7fa4FfqoNbwHZSqniqCx0dpsz++FwCPE9F6v1xEQ8fc4FWEvUmfucfvPHRPOPJkb73ADrEfFtTu+L423fGinxtJ+MpHjb70XSXD0O8mcuBx5KgVNePzcSoy8O4aSUqgRWAW8DhVrrFvOqVqAwVuuagQeAfwXc5s95QLfWesz8eba+blVAO/CYmT71Q6VUGrP8NdNaNwHfAhowAg49wC7mxmsG/l+fObk/iYJ4fN408Eel1C6l1F0xXgvE5z7hPmWUFP0oFim78fQ5N2EtEIPnxkzD3Qu0AX8CjhPDfe7E9WitrefmG+Zzc79SKjla6xFBicd9caTF4741bOJpPxkJ8bbfi6AHmJvHQT7N5cDDnKOUSgd+BfyD1rrX+zptzEWdVWcdlFIfAdq01rtivZYIsAMXAj/QWq8CBpiQ+jZLX7McjMh6FVACpOE7VXvWm42vjwjKJVrrCzFSju9VSm2M9YIscfKe+wFQg5He2gJ8O5q/PJ4+53ysJSbPjdbapbVeCZRhnLleHI3fG+x6lFLLgC+a61oD5AJfiN0KhRgvTvatYRNP+8lIibf9XiTM8eMgn+Zy4KEJmO/1c5l52ayklErE2Mn8XGv9rHnxaSvd2/y7LVbrm6aLgc1KqXqMtL8rMfoiZJtp/DB7X7dGoNHrTNAzGIGI2f6avR84obVu11qPAs9ivI5z4TUD/6/PnNqfRFHcPW9m1g5a6zbgOYwvNLEUV/sErfVp8wufG/g/ovj8xNPnnK+1xPK5MX9/N/AKsIE42Od6rWeTmQKutdYjwGPE/v+VGC/u9sVREFf71nCJp/1kNMTbfi/M5vJxkE9zOfCwA1hodgZNwmiAtzXGa5oWs97nUeCw1vp/vK7aCtxh/vsO4DfRXttMaK2/qLUu01pXYrw+27TWt2HsYG4wbzbrtgtAa90KnFJKLTIveh9wiFn+mmGUWKxXSqWa70tru2b9a2by9/psBT6hDOuBHq+0RuFfXO2HlVJpSqkM69/AVcCBwPeKuLjaJ0zoXfJRovT8xNPnnL+1xOK5UUoVKKWyzX+nAB/AqOuOyT7Xz3qOeB30KIx65Fj/vxLjxdW+OEriat8aDvG0n4ykeNvvRcpcPg7yRxkZOXOTMkZdPYDRef9HWutvxHZF06OUugR4HdjP2RqgL2HUdT0FlAMngRu11nHRKCxUSqnLgX/WWn9EKVWNEfnLBfYAHzfPoswqyhgn9kMgCagD7sQI9s3q10wZY41uwuiuvAf4FEb92ax6zZRSTwCXA/nAaeA/gF/j4/UxP+wfwigrGQTu1FpHdRTjbBVP+2Fz3/Kc+aMd+EU01xPKey6G67kco5RAA/XAZ6IRZIunz7kAa7mFKD83SqkLMJqLJWB+fmitvxarz8kA69kGFAAK2Avc7dUcTsSBeNoXh1u87VsjJZ72k5EUb/u9aJiLx0G+zOnAgxBCCCGEEEIIIWJrLpdaCCGEEEIIIYQQIsYk8CCEEEIIIYQQQoiIkcCDEEIIIYQQQgghIkYCD0IIIYQQQgghhIgYCTwIIYQQQgghhBAiYiTwIIQQQgghhBBCiIiRwIMQQgghhBBCCCEi5v8DZDm2uDc2GHcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1296x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='47' class='' max='300', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      15.67% [47/300 06:43<36:13]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='20', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/20 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 046 \t Loss: 2.0392 \t Accu: 0.3025 \t Time: 8.61 ss\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-d6be6ad6debb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m#nn.utils.clip_grad_norm_(p, max_norm=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x7f1d47e5cc80> (for post_execute):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mflush_figures\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# ignore the tracking, just draw and close all figures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# safely show traceback if in IPython, else raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     39\u001b[0m             display(\n\u001b[1;32m     40\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             )\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-2>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2259\u001b[0m                         \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2260\u001b[0m                         \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2261\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   2262\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2263\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincluding\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m'Software'\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \"\"\"\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m         mpl.image.imsave(\n\u001b[1;32m    510\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"upper\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    404\u001b[0m              (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n\u001b[1;32m    405\u001b[0m               else nullcontext()):\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rasterizing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2736\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2737\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 2738\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   2739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2740\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msfig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubfigs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                          \u001b[0;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                 **kwargs)\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2923\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2925\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2927\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;31m# the actual bbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_label_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_label_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2350\u001b[0m                 \u001b[0;31m# use axes if spine doesn't exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m                 \u001b[0mspinebbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2352\u001b[0;31m             \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbboxes\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mspinebbox\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2353\u001b[0m             \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m             self.label.set_position(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36munion\u001b[0;34m(bboxes)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'bboxes' cannot be empty\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxmin\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxmax\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m         \u001b[0my0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymin\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymax\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'bboxes' cannot be empty\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxmin\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxmax\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m         \u001b[0my0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymin\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymax\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36mxmax\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;34m\"\"\"The right edge of the bounding box.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2704\u001b[0m     \"\"\"\n\u001b[1;32m   2705\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2706\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metric_dict       = logsys.initial_metric_dict(metric_list)\n",
    "master_bar        = logsys.create_master_bar(300)\n",
    "master_bar.set_multiply_graph(figsize=(9,3),engine=[['plot','plot','plot']],labels=[metric_list])\n",
    "accu = loss = -1\n",
    "for epoch in master_bar:\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    infiniter = DataSimfetcher(train_loader, device=device)\n",
    "    inter_b   = logsys.create_progress_bar(len(train_loader))\n",
    "    while inter_b.update_step():\n",
    "        image,label= infiniter.next()\n",
    "        bs,c,w,h = image.shape\n",
    "        optimizer.zero_grad()\n",
    "        binary     = preprocess_images(image)\n",
    "        logits     = model(binary).squeeze()\n",
    "        loss       = torch.nn.CrossEntropyLoss()(logits,label)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 100)\n",
    "        if torch.isnan(loss):raise \n",
    "        #nn.utils.clip_grad_norm_(p, max_norm=1)\n",
    "        optimizer.step()\n",
    "        g_norm=[(p.grad.norm()/p.norm()).item() for name,p in model.named_parameters() ] \n",
    "#        g_norm=[(p.grad.norm()/p.norm()).item() for name,p in model[1].named_parameters() if 'unit' in name]    \n",
    "#        g_norm+=[(p.grad.norm()/p.norm()).item() for name,p in model[2].named_parameters()] \n",
    "        losses.append(loss.item())\n",
    "        #lres.append(sum([(p.grad/p).norm() for p in model.parameters()]).log().item())\n",
    "        \n",
    "#         if inter_b.now%5==0:\n",
    "#             #print(g_norm\n",
    "#             master_bar.update_graph_multiply([[losses[-100:],g_norm,accues[-100:]\n",
    "#                                                #stdes[-100:],meanes[-100:]\n",
    "#                                               ]])\n",
    "        loss = loss.item()\n",
    "        master_bar.lwrite('Epoch: %.3i \\t Loss: %.4f \\t Accu: %.4f \\t Time: %.2f s' %(epoch, loss, accu,time.time() - start_time),end='\\r')\n",
    "        #master_bar.lwrite('Epoch: %.3i \\t Loss: %.4f \\t Std: %.4f Mean: %.4f \\t Time: %.2f s' %(epoch, loss, std,mean,time.time() - start_time),end='\\r')\n",
    "    \n",
    "    model.eval()\n",
    "    prefetcher = DataSimfetcher(test_loader, device=device)\n",
    "    inter_b    = logsys.create_progress_bar(len(test_loader))\n",
    "    labels     = []\n",
    "    logits     = []\n",
    "    with torch.no_grad():\n",
    "        while inter_b.update_step():\n",
    "            image,label= prefetcher.next()\n",
    "            binary     = preprocess_images(image)\n",
    "            logit      = model(binary).squeeze()\n",
    "            loss       = torch.nn.CrossEntropyLoss()(logit ,label)\n",
    "            labels.append(label)\n",
    "            logits.append(logit)\n",
    "    labels  = torch.cat(labels)\n",
    "    logits  = torch.cat(logits)\n",
    "    pred_labels  = torch.argmax(logits,-1)\n",
    "    accu =  torch.sum(pred_labels == labels)/len(labels)\n",
    "\n",
    "    accues.append(accu)\n",
    "    master_bar.update_graph_multiply([[losses[-100:],g_norm,accues[-100:]]])\n",
    "    accu = accu.item()\n",
    "    master_bar.lwrite('Epoch: %.3i \\t Loss: %.4f \\t Accu: %.4f \\t Time: %.2f s' %(epoch, loss, accu,time.time() - start_time),end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def sample(self, bs, random_start=False):\n",
    "    \"\"\"\n",
    "    Sample images/spin configurations\n",
    "    \"\"\"\n",
    "\n",
    "    device = self.tensors.device\n",
    "    samples = torch.empty([bs, self.n], device=device)\n",
    "\n",
    "    # if random_start = True, force s_1 = -1/+1 randomly\n",
    "    if random_start:\n",
    "        samples[:, 0] = torch.randint(2, size=(bs, ), dtype=torch.float, device=device)\n",
    "    else:\n",
    "        samples[:, 0] = 0.\n",
    "\n",
    "    for idx in range(self.n - 1):\n",
    "        if idx == 0:\n",
    "            # sample s_2 from p(s_2 | s_1)\n",
    "            embedded_data = torch.stack([samples[:, 0], 1.0 - samples[:, 0]], dim=1)  # (bs, 2)\n",
    "            mats          = torch.einsum('lri,bi->blr', self.tensors[0, :, :, :] , embedded_data)\n",
    "            left_vec      = mats[:, 0, :].unsqueeze(1)  # (bs, 1, D)\n",
    "            logits        = torch.einsum('blr, ri->bli', left_vec,(self.tensors[1, :, :, :] )[:, 0, :]).squeeze(1)\n",
    "            samples[:, 1] = torch.bernoulli(torch.softmax(logits, dim=1)[:, 0])\n",
    "        else:\n",
    "            # then sample s_3 from  p(s_3 | s_1, s_2) and so on\n",
    "            embedded_data = torch.stack([samples[:, idx], 1.0 - samples[:, idx]], dim=1)  # (bs, 2)\n",
    "            mats = torch.einsum('lri,bi->blr', self.tensors[idx, :, :, :] , embedded_data)\n",
    "            left_vec = torch.bmm(left_vec, mats)  # (bs, 1, D)\n",
    "            logits = torch.einsum('blr, ri->bli', left_vec,\n",
    "                                  (self.tensors[idx + 1, :, :, :] )[:, 0, :]).squeeze(1)\n",
    "            samples[:, idx + 1] = torch.bernoulli(torch.softmax(logits, dim=1)[:, 0])\n",
    "    return samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
