{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(3,1,14,14)\n",
    "model = nn.Sequential(torch.nn.Conv2d(1,10,kernel_size=5,stride=1),torch.nn.MaxPool2d(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 5, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(a).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# mnist_data = np.load('archive/tn-for-unsup-ml/data/binarized_mnist.npz')\n",
    "# train_data = torch.from_numpy(mnist_data['train_data'])\n",
    "# test_data = torch.from_numpy(mnist_data['test_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /media/tianning/DATA/DATASET/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c809b540dc4d95ad0d1fc45317523d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /media/tianning/DATA/DATASET/FashionMNIST/raw/train-images-idx3-ubyte.gz to /media/tianning/DATA/DATASET/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /media/tianning/DATA/DATASET/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7210d2136d4742d9b8e82bcd2d545c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /media/tianning/DATA/DATASET/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /media/tianning/DATA/DATASET/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /media/tianning/DATA/DATASET/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ddb024f2ef64559b44006cfe8198274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /media/tianning/DATA/DATASET/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /media/tianning/DATA/DATASET/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /media/tianning/DATA/DATASET/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c063adab1046a4b8e02ecafa738099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /media/tianning/DATA/DATASET/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /media/tianning/DATA/DATASET/FashionMNIST/raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from train_base import *\n",
    "\n",
    "stdmean =  torch.load('/media/tianning/DATA/DATASET/MNIST/statisitc_stdmean.pt')\n",
    "statisitc_std = stdmean[\"statisitc_std\"]\n",
    "statisitc_mean= stdmean[\"statisitc_mean\"]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #lambda x: (x - statisitc_mean)/(statisitc_std+1e-7),\n",
    "    #transforms.CenterCrop(24)\n",
    "])\n",
    "DATAPATH    = '/media/tianning/DATA/DATASET/'\n",
    "mnist_train = datasets.FashionMNIST(DATAPATH, train=True, download=True, transform=transform)\n",
    "mnist_test  = datasets.FashionMNIST(DATAPATH, train=False,download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader= torch.utils.data.DataLoader(dataset=mnist_train, batch_size=60000, shuffle=True)\n",
    "all_image = iter(train_loader).next()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltool.visualization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f80297df438>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(all_image[5,0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f802a806748>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(torch.sum(all_image[:,0]>0,0).numpy()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### the random initial for tensornetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "notice if use the unnormlized random initial,  the result will overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from models.model_utils import get_best_path,structure_operands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D=3\n",
    "L=W=H=5\n",
    "contract_engine = torch.einsum\n",
    "W = L if W is None else W\n",
    "H = L if H is None else H\n",
    "top_shape_list  =   [(D,D)]  + [  (D,D,D) for i in range(L-2)] + [  (D,D)]\n",
    "mid_shape_list  =[  [(D,D,D)]+ [(D,D,D,D) for i in range(L-2)] + [(D,D,D)] for _ in range(L-2)]\n",
    "bot_shape_list  =   [(D,D)]  + [  (D,D,D) for i in range(L-2)] + [(D,D)]\n",
    "tn2D_shape_list = [top_shape_list]+mid_shape_list+[bot_shape_list]\n",
    "#node_list,sublist_list,outlist =  create_templete_2DTN_tn(tn2D_shape_list,engine=rd_engine)\n",
    "path,sublist_list,outlist = get_best_path(tn2D_shape_list,store=\"models/arbitrary_shape_path_recorder.json\",type='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import opt_einsum as oe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9338), tensor(-0.0248))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_edge=(W-1)*H+(H-1)*W\n",
    "num_of_unit=W*H\n",
    "mean=0;std=np.power(3.0,-num_of_edge/num_of_unit/2)\n",
    "\n",
    "tensor_list     = [torch.normal(mean=mean,std=std,size=(1000,*l)) for t in tn2D_shape_list for l in t]\n",
    "assert len(tensor_list)==len(sublist_list)\n",
    "operands = structure_operands(tensor_list,sublist_list,outlist)\n",
    "out      = oe.contract(*operands,optimize=path)\n",
    "torch.std_mean(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "notice if use the unnormlized random initial,  the result will overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.9850e+09), tensor(38419800.))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_edge=(W-1)*H+(H-1)*W\n",
    "num_of_unit=W*H\n",
    "mean=0;std=1\n",
    "tensor_list     = [torch.normal(mean=mean,std=std,size=(1000,*l)) for t in tn2D_shape_list for l in t]\n",
    "\n",
    "assert len(tensor_list)==len(sublist_list)\n",
    "operands = structure_operands(tensor_list,sublist_list,outlist)\n",
    "out      = oe.contract(*operands,optimize=path)\n",
    "torch.std_mean(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Simple MPS layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     2,
     14,
     38,
     51,
     58,
     68
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class MPSLinear(nn.Module):\n",
    "    '''\n",
    "    For a naive Linear Layer(in_features,out_features,\n",
    "                             in_physics_bond = 2, out_physics_bond=2, virtual_bond_dim=2, \n",
    "                             bias=True,label_position='center',init_std=1e-10\n",
    "                                       ): \n",
    "        input  (B, in_features)\n",
    "        output (B, out_features)\n",
    "    For s simplest MPSLayer(in_features: int, out_features: int, \n",
    "                            in_physics_bond: int, out_physics_bond: int, virtual_bond_dim:int,\n",
    "                            bias: bool = True, label_position: int or str): \n",
    "        input  (B, in_features , in_physics_bond)\n",
    "        output (B, out_features,out_physics_bond)\n",
    "    '''\n",
    "    def __init__(self, in_features,out_features,\n",
    "                                       in_physics_bond = 2, out_physics_bond=1, virtual_bond_dim=2, \n",
    "                                       bias=True,label_position='center',init_std=1e-10):\n",
    "        super(MPSLinear, self).__init__()\n",
    "        if label_position is 'center':\n",
    "            label_position = in_features//2\n",
    "        assert type(label_position) is int\n",
    "        self.in_features   = in_features\n",
    "        self.out_features  = out_features\n",
    "        self.vbd           = virtual_bond_dim\n",
    "        self.ipb           = in_physics_bond\n",
    "        self.opb           = out_physics_bond\n",
    "        self.hn            = label_position\n",
    "        left_num           = self.hn\n",
    "        right_num          = in_features - left_num\n",
    "\n",
    "        bias_mat = torch.eye(self.vbd).unsqueeze(-1).repeat(1,1,self.ipb)\n",
    "        self.left_tensors = nn.Parameter(init_std * torch.randn(left_num         ,self.vbd,self.vbd, self.ipb)+ bias_mat)\n",
    "        self.rigt_tensors = nn.Parameter(init_std * torch.randn(right_num        ,self.vbd,self.vbd, self.ipb)+ bias_mat)\n",
    "        \n",
    "        bias_mat = torch.eye(self.vbd).unsqueeze(-1).repeat(1,1,self.opb)\n",
    "        self.cent_tensors = nn.Parameter(init_std * torch.randn(self.out_features,self.vbd,self.vbd, self.opb)+ bias_mat)\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_chain_contraction_fast(tensor):\n",
    "        size   = int(tensor.shape[0])\n",
    "        while size > 1:\n",
    "            half_size = size // 2\n",
    "            nice_size = 2 * half_size\n",
    "            leftover  = tensor[nice_size:]\n",
    "            tensor    = torch.einsum(\"mbik,mbkj->mbij\",tensor[0:nice_size:2], tensor[1:nice_size:2])\n",
    "            #(k/2,NB,D,D),(k/2,NB,D,D) <-> (k/2,NB,D,D)\n",
    "            tensor   = torch.cat([tensor, leftover], axis=0)\n",
    "            size     = half_size + int(size % 2 == 1)\n",
    "        return tensor.squeeze(0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_chain_contraction_memory_save(tensor):\n",
    "        size      = int(tensor.shape[0])\n",
    "        now_tensor= tensor[0]\n",
    "        for next_tensor in tensor[1:]:\n",
    "            now_tensor = torch.einsum(\"bik,bkj->bij\",now_tensor, next_tensor)\n",
    "        return now_tensor\n",
    "    \n",
    "    def get_chain_contraction(self,tensor):\n",
    "        size   = int(tensor.shape[0])\n",
    "        D      = int(tensor.shape[-1])\n",
    "        print(size)\n",
    "        print(D)\n",
    "        if D>30:\n",
    "            return self.get_chain_contraction_memory_save(tensor)\n",
    "        else:\n",
    "            return self.get_chain_contraction_fast(tensor)\n",
    "    \n",
    "    def forward(self, input_data):\n",
    "        # the input data shape is (B,L,pd)\n",
    "        # expand to convolution patch\n",
    "        embedded_data= input_data\n",
    "        left_tensors = torch.einsum('wijp,nwp->wnij',self.left_tensors,embedded_data[:,:self.hn])#i.e. (K,NB,b,b)\n",
    "        rigt_tensors = torch.einsum('wijp,nwp->wnij',self.rigt_tensors,embedded_data[:,-self.hn:])#i.e.(K,NB,b,b)\n",
    "\n",
    "        left_tensors = self.get_chain_contraction(left_tensors) #i.e. (NB,b,b)\n",
    "        rigt_tensors = self.get_chain_contraction(rigt_tensors) #i.e. (NB,b,b)\n",
    "\n",
    "        tensor  = torch.einsum('bip,oplt,bli->bot',left_tensors,self.cent_tensors,rigt_tensors)\n",
    "        # (NB,b,b) <-> (T,b,b,o) <-> (NB,b,b) ==> (NB,T,t)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     3,
     70
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensornetwork as tn\n",
    "from tensornetwork import contractors\n",
    "tn.set_default_backend(\"pytorch\")\n",
    "class MPSLinear_tn_loop(nn.Module):\n",
    "    '''\n",
    "    For s simplest MPSLayer(in_features: int, out_features: int,\n",
    "                            in_physics_bond: int, \n",
    "                            out_physics_bond: int, virtual_bond_dim:int,\n",
    "                            bias: bool = True, label_position: int or str):\n",
    "        input  (B, in_features , in_physics_bond)\n",
    "        output (B, out_features)\n",
    "    '''\n",
    "    def __init__(self, in_features,out_features,\n",
    "                       in_physics_bond = 2, out_physics_bond=1, virtual_bond_dim=2,\n",
    "                       bias=True,label_position='center',init_std=1e-10,**kargs):\n",
    "        super().__init__()\n",
    "\n",
    "        if label_position is 'center':\n",
    "            label_position = in_features//2\n",
    "        assert type(label_position) is int\n",
    "        self.in_features   = in_features\n",
    "        self.out_features  = out_features\n",
    "        self.vbd           = virtual_bond_dim\n",
    "        self.ipb           = in_physics_bond\n",
    "        self.opb           = out_physics_bond\n",
    "        self.hn            = label_position\n",
    "        \n",
    "        left_num           = self.hn\n",
    "        right_num          = in_features - left_num\n",
    "\n",
    "        bias_mat     = torch.eye(self.ipb,self.vbd)\n",
    "        left_end     = init_std * torch.randn(self.ipb,self.vbd) + bias_mat\n",
    "\n",
    "        bias_mat     = torch.eye(self.vbd, self.ipb)\n",
    "        right_end    = init_std * torch.randn(self.vbd, self.ipb)+ bias_mat\n",
    "\n",
    "        bias_mat     = torch.eye(self.vbd).unsqueeze(1).repeat(1,self.ipb,1)\n",
    "        left_tensors = init_std * torch.randn(left_num-1 ,self.vbd, self.ipb , self.vbd)+ bias_mat\n",
    "        rigt_tensors = init_std * torch.randn(right_num-1,self.vbd, self.ipb,self.vbd)+ bias_mat\n",
    "\n",
    "\n",
    "        bias_mat     = torch.eye(self.vbd).unsqueeze(1).repeat(1,self.out_features,1)\n",
    "        cent_tensors = init_std * torch.randn(self.vbd,self.out_features,self.vbd)+ bias_mat\n",
    "\n",
    "        mps_var      = [left_end] + list(left_tensors)  + [cent_tensors] + list(rigt_tensors) + [right_end]\n",
    "        self.mps_var = [nn.Parameter(v) for v in mps_var]\n",
    "        self.center  = left_num\n",
    "        for i, v in enumerate(self.mps_var):\n",
    "            self.register_parameter(f'mps{i}', param=v)\n",
    "\n",
    "    def contract_mps_with_input(self,input):\n",
    "        assert len(input) == len(self.mps_var)-1\n",
    "        mps_list_1   = self.mps_var\n",
    "        mps_nodes_1  = [tn.Node(v, name=f\"t{i}\") for i,v in enumerate(mps_list_1)]\n",
    "        mps_edges_1  = [mps_nodes_1[i][-1]^mps_nodes_1[i+1][0] for i in range(len(mps_nodes_1)-1)]\n",
    "        inp_nodes    = [tn.Node(v, name=f\"i{i}\") for i,v in enumerate(input)]\n",
    "        for i,input_node in enumerate(inp_nodes):\n",
    "            j = i if i < self.center else i+1\n",
    "            mps_physicd_edge = mps_nodes_1[j][0] if j==0 else mps_nodes_1[j][1]\n",
    "            inp_physics_edge = input_node[0]\n",
    "            tn.connect(mps_physicd_edge,inp_physics_edge,name=f\"p_{i}\")\n",
    "\n",
    "        ans = contractors.auto(mps_nodes_1+inp_nodes,\n",
    "                              output_edge_order=[mps_nodes_1[self.center][1]]).tensor\n",
    "        return ans\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        out = torch.stack([self.contract_mps_with_input(single_input) for single_input in inputs])\n",
    "        return out\n",
    "    \n",
    "class MPSLinear_tn_batch(MPSLinear_tn_loop):\n",
    "    def forward(self, inputs):\n",
    "        num        = len(self.mps_var)\n",
    "        mps_nodes  = [tn.Node(v, name=f\"t{i}\") for i,v in enumerate(self.mps_var)]\n",
    "        mps_edges  = [mps_nodes[i][-1]^mps_nodes[i+1][0] for i in range(num-1)]\n",
    "\n",
    "\n",
    "        inputs= inputs.permute(1,2,0)#(B,num,k)->(num,k,B)\n",
    "        out   = torch.diag_embed(inputs)#(num,k,B)->(num,k,B,B)\n",
    "        out   = out.permute(0,2,1,3)#(num,k,B,B)->(num,B,k,B)\n",
    "        out   = [v for v in out]\n",
    "        out[0]= torch.diagonal(out[0], dim1=0, dim2=-1).transpose(1,0)#(B,k,B) -> #(B,k)\n",
    "\n",
    "        inp_nodes=[tn.Node(v, name=f\"i{i}\") for i,v in enumerate(out)]\n",
    "        inp_edges=[inp_nodes[0][0]^inp_nodes[1][0]]+ [\n",
    "            inp_nodes[i][-1]^inp_nodes[i+1][0] for i in range(1,len(inp_nodes)-1)]\n",
    "\n",
    "        for i,input_node in enumerate(inp_nodes):\n",
    "            j = i if i < self.center else i+1\n",
    "            mps_physicd_edge = mps_nodes[j][0] if j==0 else mps_nodes[j][1]\n",
    "            inp_physics_edge = input_node[1]\n",
    "            tn.connect(mps_physicd_edge,inp_physics_edge,name=f\"p_{i}\")\n",
    "\n",
    "        ans = contractors.auto(mps_nodes+inp_nodes,output_edge_order=[inp_nodes[-1][2],mps_nodes[self.center][1]]).tensor\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = MPSLinear_tn_loop(28*28,10,in_physics_bond = 2, out_physics_bond=1, virtual_bond_dim=10,\n",
    "                  bias=False,label_position='center',init_std=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = MPSLinear_tn_batch(28*28,10,in_physics_bond = 2, out_physics_bond=1, virtual_bond_dim=10,\n",
    "                  bias=False,label_position='center',init_std=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_input = torch.randn(2,28*28,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### AMPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#from models.amps import AMPSShare\n",
    "class AMPSShare(nn.Module):\n",
    "    '''\n",
    "    This version may fast, but will cost much more memory\n",
    "    n        : the length of input tensor sequence\n",
    "    bond_dim : the virtual bond dim. The capacity of model.\n",
    "    phys_dim : the feature/class number\n",
    "    ------------------------------\n",
    "    Input:  any data/spin configurations, shape: (B, n ,phys_dim)\n",
    "    Output: prob_matrix of each sample, shape: (B, n, phys_dim), pass softmax to get probility.\n",
    "    -------------------------------\n",
    "    Weight Cost:\n",
    "        n * bond_dim * bond_dim * phys_dim\n",
    "    '''\n",
    "    def __init__(self, n=784, bond_dim=10, phys_dim=2,std=1e-8):\n",
    "        super(AMPSShare, self).__init__()\n",
    "        # Initialize AMPS model parameters, which is a (n, D, D, 2) tensor\n",
    "        self.register_buffer('bias_mat', torch.eye(bond_dim).unsqueeze(-1).repeat(1,1,phys_dim))\n",
    "        # bias_mat: which is realy important when n>>1\n",
    "        self.tensors = nn.Parameter(std * torch.randn(n, bond_dim, bond_dim, phys_dim)+self.bias_mat)\n",
    "        # Set attributes\n",
    "        self.n = n\n",
    "        self.bond_dim = bond_dim\n",
    "        self.std = std\n",
    "\n",
    "    def forward(self, embedded_data):\n",
    "\n",
    "        bs = embedded_data.shape[0]\n",
    "        # local feature map, x_j -> [x_j, 1-x_j]\n",
    "        #-> embedded_data = torch.stack([data, 1.0 - data], dim=2)  # (bs, n, 2)\n",
    "        ##logx_hat = torch.zeros_like(embedded_data)\n",
    "        ##logx_hat[:, 0, :] = F.log_softmax(self.tensors[0, 0, 0], dim=0)\n",
    "        prob_matrix = self.tensors[0, 0, 0].repeat((bs,1)).unsqueeze(1) # (bs,1,2)\n",
    "        mats = torch.einsum('lri,bi->blr', self.tensors[0] , embedded_data[:, 0, :])\n",
    "        left_vec = mats[:, 0:1, :]  # (bs,  D)\n",
    "        for idx in range(1, self.n):\n",
    "            # compute p(s_2 | s_1) and so on\n",
    "            logits = torch.einsum('br, ri->bi', left_vec.squeeze(1),self.tensors[idx,:,0,:])\n",
    "            #(bs,D) <-> (D,2) ->(bs,2)\n",
    "            prob_matrix = torch.cat([prob_matrix,logits.unsqueeze(1)], dim=1)\n",
    "            #(bs, n-2, 2) + (bs,1,2) -> (bs, n-1, 2)\n",
    "            ##logx_hat[:, idx, :] = F.log_softmax(logits, dim=1)\n",
    "            mats = torch.einsum('lri,bi->blr', self.tensors[idx, :, :, :] , embedded_data[:, idx, :])\n",
    "            #(D,D,2) <-> (bs,2) ->(bs,D,D)\n",
    "            left_vec = torch.bmm(left_vec, mats)  # (bs, 1, D)\n",
    "        # compute log prob\n",
    "        return prob_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### PEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from models.tensornetwork_base import TN_Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     22,
     40,
     52,
     88,
     122
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class PEPS_einsum_uniform_shape(TN_Base):\n",
    "    def __init__(self, W,H,out_features,\n",
    "                       in_physics_bond = 2, virtual_bond_dim=2,\n",
    "                       bias=True,label_position='center',init_std=1e-10,contraction_mode = 'recursion'):\n",
    "        super().__init__()\n",
    "        #label_position at 'corner':\n",
    "        label_pos_x        = W\n",
    "        label_pos_y        = H\n",
    "        self.W             = W\n",
    "        self.H             = H\n",
    "        \n",
    "        self.out_features  = O = out_features\n",
    "        self.vbd           = D = virtual_bond_dim\n",
    "        self.ipb           = P = in_physics_bond\n",
    "        self.label_pos_x   = label_pos_x\n",
    "        self.label_pos_y   = label_pos_y\n",
    "        \n",
    "        self.bulk_tensors = nn.Parameter(self.rde2D((     (W-2)*(H-2),P,D,D,D,D),init_std))\n",
    "        self.edge_tensors = nn.Parameter(self.rde2D( (2*(W-2)+2*(H-2),P,D,D,D),init_std))\n",
    "        self.corn_tensors = nn.Parameter(self.rde2D(                 (3,P,D,D),init_std))\n",
    "        self.cent_tensors = nn.Parameter(self.rde2D(                 (O,P,D,D),init_std))\n",
    "    @staticmethod\n",
    "    def rde2D(shape,init_std,offset=2):\n",
    "        size_shape = shape[:offset]\n",
    "        bias_shape = shape[offset:]\n",
    "        if len(bias_shape) ==2 :\n",
    "            bias_mat   = torch.eye(*bias_shape)\n",
    "        elif len(bias_shape) == 3:\n",
    "            a,b,c   = bias_shape\n",
    "            bias_mat   = torch.kron(torch.ones(a),torch.eye(b,c)).reshape(a,b,c)\n",
    "        elif len(bias_shape) == 4:\n",
    "            a,b,c,d   = bias_shape\n",
    "            bias_mat   = torch.kron(torch.ones(a,b),torch.eye(c,d)).reshape(a,b,c,d)\n",
    "#         bias_mat   = torch.zeros(bias_shape)\n",
    "#         diag_idx   = [list(range(min(bias_shape)))]*len(bias_shape)\n",
    "#         bias_mat[diag_idx] = 1\n",
    "#         for i in range(offset):bias_mat=bias_mat.unsqueeze(0)\n",
    "        bias_mat   = bias_mat.repeat(*size_shape,*([1]*len(bias_shape)))\n",
    "        tensor     = init_std * torch.randn(*shape)+ bias_mat\n",
    "        return tensor                                    \n",
    "    def mpo_line(self,i,bulk_tensors,edge_tensors,corn_tensors,cent_tensors):\n",
    "        W=self.W\n",
    "        H=self.H\n",
    "        if i == 0:\n",
    "            return  corn_tensors[0],edge_tensors[0:W-2],corn_tensors[1]\n",
    "        elif i == H - 1:\n",
    "            return  corn_tensors[2],edge_tensors[-(W-2):],cent_tensors\n",
    "        else:\n",
    "            return  edge_tensors[W-4+2*i],bulk_tensors[(W-2)*(i-1):(W-2)*i],edge_tensors[W-4+2*i+1]\n",
    "    \n",
    "\n",
    "    @staticmethod                                  \n",
    "    def batch_contract_mps_mpo(mps_list,mpo_list):\n",
    "        # mps_list                                    --D--|--D--\n",
    "        # (D,D)-(D,D,D)-(D,D,D)-...-(D,D,D)-(D,D)          D\n",
    "        #  -b-    -c-  -b-   -c-  -b-     -b- \n",
    "        # |a         |a         |a          |a  \n",
    "        # the order i.e. 'abcd' counterclockwise and start from the down index. (so down index must a )\n",
    "        #  mpo_list                                           \n",
    "        # (P,D,P)-(D,P,D,P)-(D,P,D,P)-...-(D,P,D,P)-(D,P,P)  \n",
    "        #  |c            |c        |c           |b                        \n",
    "        #   -b-      -d-  -b-  -d-  -b-     -c-  \n",
    "        # |a            |a        |a           |a                                             \n",
    "        assert len(mps_list) > 2\n",
    "        assert len(mpo_list) > 2\n",
    "        stack_unit_mps = (len(mps_list)==3 and len(mps_list[0].shape)+ 2 == len(mps_list[1].shape))\n",
    "        stack_unit_mpo = (len(mpo_list)==3 and len(mpo_list[0].shape)+ 2 == len(mpo_list[1].shape))\n",
    "        mps_left,mps_rigt = mps_list[0],mps_list[-1]\n",
    "        mpo_left,mpo_rigt = mpo_list[0],mpo_list[-1]\n",
    "        new_mps_list= []\n",
    "        tensor = torch.einsum(\"  kab,kcda->kcbd\",mps_left,mpo_left).flatten(-2,-1)\n",
    "        new_mps_list.append(tensor)\n",
    "        if stack_unit_mps and stack_unit_mpo:\n",
    "            mps_inne = mps_list[1]\n",
    "            mpo_inne = mpo_list[1]                            \n",
    "            tensor = torch.einsum(\"lkabc,lkdeaf->lkdbecf\",mps_inne,mpo_inne).flatten(-4,-3).flatten(-2,-1)\n",
    "            new_mps_list.append(tensor)\n",
    "        else:\n",
    "            if stack_unit_mps:mps_inne = list(*mps_list[1:-1])\n",
    "            if stack_unit_mpo:mpo_inne = list(*mpo_list[1:-1])\n",
    "            for mps,mpo in zip(mps_inne,mpo_inne):\n",
    "                tensor =torch.einsum(\"kabc,kdeaf->kdebcf\",mps,mpo).flatten(-4,-3).flatten(-2,-1)     \n",
    "                new_mps_list.append(tensor)\n",
    "        tensor = torch.einsum(\"  kab,kcad->kcbd\",mps_rigt,mpo_rigt).flatten(-2,-1)      \n",
    "        new_mps_list.append(tensor)\n",
    "        return new_mps_list                                 \n",
    "    \n",
    "    @staticmethod\n",
    "    def batch_contract_mps_mps(mps_list,mpo_list):\n",
    "        # mps_list                                    --D--|--D--\n",
    "        # (D,D)-(D,D,D)-(D,D,D)-...-(D,D,D)-(D,D)          D\n",
    "        # (D,D)-(D,D,D)-(D,D,D)-...-(D,D,D)-(D,D,O)\n",
    "        #  -b-    -c-  -b-   -c-  -b-     -b- \n",
    "        # |a         |a         |a          |a                                \n",
    "        # \n",
    "        # |b            |b        |b        |b                        \n",
    "        #  -a-      -c-  -a-  -c-  -a-   -c- -a                     \n",
    "        assert len(mps_list) > 2\n",
    "        assert len(mpo_list) > 2\n",
    "        stack_unit_mps = (len(mps_list)==3 and len(mps_list[0].shape)+ 2 == len(mps_list[1].shape))\n",
    "        stack_unit_mpo = (len(mpo_list)==3 and len(mpo_list[0].shape)+ 2 == len(mpo_list[1].shape))\n",
    "        mps_left,mps_rigt = mps_list[0],mps_list[-1]\n",
    "        mpo_left,mpo_rigt = mpo_list[0],mpo_list[-1]\n",
    "        new_mps_list= []\n",
    "        tensor = torch.einsum(\"  kab,kca->kbc\",mps_left,mpo_left).flatten(-2,-1)\n",
    "        new_mps_list.append(tensor)\n",
    "        if stack_unit_mps and stack_unit_mpo:\n",
    "            mps_inne = mps_list[1]\n",
    "            mpo_inne = mpo_list[1]                            \n",
    "            tensor = torch.einsum(\"lkabc,lkdae->lkbdce\",mps_inne,mpo_inne).flatten(-4,-3).flatten(-2,-1)\n",
    "            new_mps_list.append(tensor)\n",
    "        else:\n",
    "            if stack_unit_mps:mps_inne = list(*mps_list[1:-1])\n",
    "            if stack_unit_mpo:mpo_inne = list(*mpo_list[1:-1])\n",
    "            for mps,mpo in zip(mps_inne,mpo_inne):\n",
    "                tensor =torch.einsum(\"kabc,kdae->kbdce\",mps,mpo).flatten(-4,-3).flatten(-2,-1)     \n",
    "                new_mps_list.append(tensor)\n",
    "        tensor = torch.einsum(\"  kab,okac->kobc\",mps_rigt,mpo_rigt).flatten(-2,-1)      \n",
    "        new_mps_list.append(tensor)\n",
    "        return new_mps_list                                                        \n",
    "    \n",
    "    @staticmethod\n",
    "    def flatten_image_input(batch_image_input):\n",
    "        bulk_input = batch_image_input[...,1:-1,1:-1,:].flatten(1,2)\n",
    "        edge_input = torch.cat([batch_image_input[...,0,1:-1,:],\n",
    "                                batch_image_input[...,1:-1,[0,-1],:].flatten(-3,-2),\n",
    "                                batch_image_input[...,-1,1:-1,:]\n",
    "                               ],1)\n",
    "        corn_input = batch_image_input[...,[0,0,-1],[0,-1,0],:]\n",
    "        cent_input = batch_image_input[...,-1,-1,:]\n",
    "        return bulk_input,edge_input,corn_input,cent_input\n",
    "    \n",
    "    def forward(self, input_data,contraction_mode='top2bot',batch_method='physics_index_first'):\n",
    "        # the input data shape is (B,L,L,pd)\n",
    "        if batch_method == 'physics_index_first':\n",
    "            bulk_input,edge_input,corn_input,cent_input = self.flatten_image_input(input_data)\n",
    "            bulk_tensors = torch.einsum(\"lpabcd,klp->lkabcd\",self.bulk_tensors,bulk_input)\n",
    "            edge_tensors = torch.einsum(\" lpabc,klp->lkabc\" ,self.edge_tensors,edge_input)\n",
    "            corn_tensors = torch.einsum(\"  lpab,klp->lkab\"  ,self.corn_tensors,corn_input)\n",
    "            cent_tensors = torch.einsum(\"   opab,kp->okab\"  ,self.cent_tensors,cent_input)\n",
    "        if contraction_mode == 'top2bot':\n",
    "            tensor     = self.mpo_line(0,bulk_tensors,edge_tensors,corn_tensors,cent_tensors)\n",
    "            for i in range(1,self.H-1):\n",
    "                #print(get_mps_size_list(tensor))\n",
    "                mpo    = self.mpo_line(i,bulk_tensors,edge_tensors,corn_tensors,cent_tensors)\n",
    "                #print(get_mps_size_list(mpo))\n",
    "                #print(\"=============\")\n",
    "                tensor = self.batch_contract_mps_mpo(tensor,mpo)    \n",
    "                #tensor = right_mps_form(tensor)\n",
    "                #tensor,scale = approxmate_mps_line(tensor,max_singular_values=100)                                            \n",
    "            mps    = self.mpo_line(self.H-1,bulk_tensors,edge_tensors,corn_tensors,cent_tensors)\n",
    "            \n",
    "            #print(get_mps_size_list(mps))\n",
    "            tensor_left,tensor_inne,tensor_rigt = self.batch_contract_mps_mps(tensor,mps)\n",
    "            tensor_inne = self.get_batch_chain_contraction_fast(tensor_inne)     \n",
    "            tensor  = torch.einsum('ka,kba,kob->ko',tensor_left,tensor_inne,tensor_rigt)\n",
    "            return tensor       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class PEPS_einsum_uniform_shape_6x6_fast(PEPS_einsum_uniform_shape):\n",
    "    def __init__(self, out_features,**kargs):\n",
    "        super().__init__(6,6,out_features,**kargs)\n",
    "        \n",
    "    def forward(self,input_data):\n",
    "        bulk_input,edge_input,corn_input,cent_input = self.flatten_image_input(input_data)\n",
    "        bulk_tensors = torch.einsum(\"lpabcd,klp->lkabcd\",self.bulk_tensors,bulk_input)\n",
    "        edge_tensors = torch.einsum(\" lpabc,klp->lkabc\" ,self.edge_tensors,edge_input)\n",
    "        corn_tensors = torch.einsum(\"  lpab,klp->lkab\"  ,self.corn_tensors,corn_input)\n",
    "        cent_tensors = torch.einsum(\"   opab,kp->okab\"  ,self.cent_tensors,cent_input)\n",
    "        #corner_contraction\n",
    "        W=H=6;\n",
    "        L=4              ;corn_index = [0,1,2,3]\n",
    "        L=2*(W-2)+2*(H-2);edge_index1=[0,(W-2)+1,W-2+2*(H-3),L-1] # [0,5,10,15] for 6x6\n",
    "        L=(W-2)*(H-2)    ;bulk_index = [0,W-3,(W-2)*(H-3),L-1]# [0,3,12,15] for 6x6\n",
    "        L=2*(W-2)+2*(H-2);edge_index2=[(W-2),(W-2)-1,L-(W-2),L-(W-2)-1] # [4,3,12,11] for 6x6\n",
    "        corner123_contraction = torch.einsum(\"lkab,lkcdb,lkefcg,lkgah->lkhedf\",\n",
    "                                       corn_tensors[corn_index[:3]],\n",
    "                                       edge_tensors[edge_index1[:3]],\n",
    "                                       bulk_tensors[bulk_index[:3]],\n",
    "                                       edge_tensors[edge_index2[:3]],\n",
    "                                      ).flatten(-4,-3).flatten(-2,-1)\n",
    "        corner4_contraction = torch.einsum(\"okab,kceb,khicg,kfga->okfhei\" ,\n",
    "                                       cent_tensors,\n",
    "                                       edge_tensors[edge_index1[-1]],\n",
    "                                       bulk_tensors[bulk_index[-1]],\n",
    "                                       edge_tensors[edge_index2[-1]],\n",
    "                                      ).flatten(-4,-3).flatten(-2,-1)\n",
    "\n",
    "        L=2*(W-2)+2*(H-2);egde_index = [1,W-4,W,W+1,-(W-2)-4,-(W-2)-3,L-3,L-2]\n",
    "        # [1,2,6,7,8,9,13,14] for 6x6\n",
    "        L=(W-2)*(H-2);bulk_index = [1,W-4,W-2,W-2+W-2-1,L-(W-2)-(W-3)-1,L-(W-2)-1,L-3,L-2]\n",
    "        # [1,2,4,7,8,11,13,14] for 6x6\n",
    "        edge_fast_contraction = torch.einsum(\"lkabc,lkefah->lkebfch\" ,\n",
    "                                               edge_tensors[egde_index],\n",
    "                                               bulk_tensors[bulk_index],\n",
    "                                              ).flatten(-4,-3).flatten(-2,-1)\n",
    "\n",
    "        L=(W-2)*(H-2);bulk_index = [W-1,2*(W-2)-2,L-W-(W-2)+3,L-(W)]# [5,6,9,10] for 6x6\n",
    "        edge_index1 = [0,3,4,7]\n",
    "        edge_index2 = [2,1,6,5]\n",
    "        corner123_contraction = torch.einsum(\"lkab,lkcdb,lkefcg,lkgah->lkhedf\" ,\n",
    "                                       corner123_contraction,\n",
    "                                       edge_fast_contraction[edge_index1[:3]],\n",
    "                                       bulk_tensors[bulk_index[:3]],\n",
    "                                       edge_fast_contraction[edge_index2[:3]],\n",
    "                                      ).flatten(-4,-3).flatten(-2,-1)\n",
    "\n",
    "        corner4_contraction = torch.einsum(\"okab,kcdb,kefcg,kgah->okhedf\",\n",
    "                                       corner4_contraction,\n",
    "                                       edge_fast_contraction[edge_index1[-1]],\n",
    "                                       bulk_tensors[bulk_index[-1]],\n",
    "                                       edge_fast_contraction[edge_index2[-1]],\n",
    "                                      ).flatten(-4,-3).flatten(-2,-1)\n",
    "        tensor  = torch.einsum(\"kab,kbc->kac\",corner123_contraction[0],corner123_contraction[1])\n",
    "        tensor  = torch.einsum(\"kab,kbc->kac\",tensor,corner123_contraction[2])\n",
    "        tensor  = torch.einsum(\"kab,okba->ko\",tensor,corner4_contraction)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = PEPS_einsum_uniform_shape_6x6_fast(10,in_physics_bond = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### naive contractor: face dimenstion explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# tensor = torch.randn(8,8,6,6,6,6)\n",
    "# while tensor.shape[0]>2:\n",
    "#     print(tensor.shape)\n",
    "#     lu_tensor = tensor[0::2,0::2]\n",
    "#     ld_tensor = tensor[0::2,1::2]\n",
    "#     ru_tensor = tensor[1::2,0::2]\n",
    "#     rd_tensor = tensor[1::2,1::2]\n",
    "#     tensor     = torch.einsum(\"xyabcd,xyhdij,xycefg,xyigkl->xyahbefkjl\",\n",
    "#                             lu_tensor,\n",
    "#                             ld_tensor,\n",
    "#                             ru_tensor,\n",
    "#                             rd_tensor).flatten(4,5).flatten(-4,-3).flatten(2,3).flatten(-2,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### cotengra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensornetwork.contractors.opt_einsum_paths.utils import *\n",
    "from opt_einsum.paths import greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import opt_einsum as oe\n",
    "import tensornetwork as tn\n",
    "tn.set_default_backend(\"pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import opt_einsum as oe\n",
    "import tensornetwork as tn\n",
    "tn.set_default_backend(\"pytorch\")\n",
    "    from tensornetwork.contractors.opt_einsum_paths.utils import *\n",
    "tensor = torch.randn(16,16,2,2,2,2).cuda()\n",
    "\n",
    "node_array = []\n",
    "W,H = tensor.shape[:2]\n",
    "for i in range(W):\n",
    "    node_line = []\n",
    "    for j in range(H):\n",
    "        node = tn.Node(tensor[i][j],name=f\"{i}-{j}\")\n",
    "        node_line.append(node)\n",
    "    node_array.append(node_line)\n",
    "\n",
    "for i in range(W):\n",
    "    for j in range(H):\n",
    "        if j==H-1:tn.connect(node_array[i][j][2],node_array[i  ][0  ][0],f\"{i}{j}<->{i}{0}\")\n",
    "        else:     tn.connect(node_array[i][j][2],node_array[i  ][j+1][0],f\"{i}{j}<->{i}{j+1}\")\n",
    "        if i==W-1:tn.connect(node_array[i][j][3],node_array[0  ][j  ][1],f\"{i}{j}<->{0}{j}\")\n",
    "        else:     tn.connect(node_array[i][j][3],node_array[i+1][j  ][1],f\"{i}{j}<->{i+1}{j}\")\n",
    "\n",
    "node_list = [item for sublist in node_array for item in sublist]\n",
    "nodes = node_list\n",
    "input_sets = [set(node.edges) for node in nodes]\n",
    "output_set = get_subgraph_dangling(nodes)\n",
    "size_dict = {edge: edge.dimension for edge in get_all_edges(nodes)}\n",
    "\n",
    "operands = []\n",
    "for node,edge_label in zip(node_list,input_sets):\n",
    "    operands+=[node.tensor,[edge.name for edge in edge_label]]\n",
    "\n",
    "path,info = oe.contract_path(*operands)\n",
    "\n",
    "small_cores =[node.tensor for node in node_list]\n",
    "import tqdm as tqdm\n",
    "import cotengra as ctg\n",
    "\n",
    "sf = ctg.SliceFinder(info, target_size=2**27)\n",
    "inds_to_slice, cost_of_slicing = sf.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tqdm as tqdm\n",
    "import cotengra as ctg\n",
    "\n",
    "sf = ctg.SliceFinder(info, target_size=2**27)\n",
    "inds_to_slice, cost_of_slicing = sf.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67108864\n",
      "2.9753197715379116\n"
     ]
    }
   ],
   "source": [
    "print(cost_of_slicing.size    ) # the new largest intermediate\n",
    "print(cost_of_slicing.overhead)  # theoretical 'slowdown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/262144 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 15/262144 [00:00<30:05, 145.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 30/262144 [00:00<44:00, 99.28it/s] \u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 41/262144 [00:00<47:41, 91.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 51/262144 [00:00<49:42, 87.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 60/262144 [00:00<50:56, 85.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 69/262144 [00:00<51:48, 84.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 78/262144 [00:00<52:24, 83.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 87/262144 [00:00<53:13, 82.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 96/262144 [00:01<53:42, 81.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 105/262144 [00:01<53:43, 81.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 114/262144 [00:01<53:46, 81.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 123/262144 [00:01<53:46, 81.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 132/262144 [00:01<53:47, 81.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 141/262144 [00:01<53:47, 81.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 150/262144 [00:01<53:49, 81.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 159/262144 [00:01<53:48, 81.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 168/262144 [00:01<53:57, 80.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 177/262144 [00:02<54:10, 80.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 186/262144 [00:02<54:04, 80.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 195/262144 [00:02<54:04, 80.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 204/262144 [00:02<54:00, 80.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 213/262144 [00:02<54:03, 80.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 222/262144 [00:02<54:02, 80.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 231/262144 [00:02<53:58, 80.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 240/262144 [00:02<53:56, 80.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 249/262144 [00:02<54:02, 80.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 258/262144 [00:03<54:13, 80.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 267/262144 [00:03<54:05, 80.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 276/262144 [00:03<54:01, 80.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 285/262144 [00:03<54:05, 80.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 294/262144 [00:03<54:06, 80.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 303/262144 [00:03<54:04, 80.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 312/262144 [00:03<54:07, 80.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 321/262144 [00:03<54:03, 80.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 330/262144 [00:04<54:05, 80.68it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7c7e88620acd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSlicedContractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msmall_cores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontract_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# 100%|██████████| 512/512 [00:55<00:00,  9.30it/s]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-7c7e88620acd>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSlicedContractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msmall_cores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontract_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# 100%|██████████| 512/512 [00:55<00:00,  9.30it/s]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/cotengra/slicer.py\u001b[0m in \u001b[0;36mcontract_slice\u001b[0;34m(self, i, **kwargs)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \"\"\"\n\u001b[1;32m    585\u001b[0m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sliced_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/opt_einsum/contract.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *arrays, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_contract_with_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_constants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_constants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_contract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_constants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_constants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/opt_einsum/contract.py\u001b[0m in \u001b[0;36m_contract\u001b[0;34m(self, arrays, out, backend, evaluate_constants)\u001b[0m\n\u001b[1;32m    696\u001b[0m                               \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                               \u001b[0mevaluate_constants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_constants\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m                               **self.einsum_kwargs)\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_contract_with_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_constants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/opt_einsum/contract.py\u001b[0m in \u001b[0;36m_core_contract\u001b[0;34m(operands, contraction_list, backend, evaluate_constants, **einsum_kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;31m# Contract!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0mnew_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtmp_operands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;31m# Build a new view if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/opt_einsum/sharing.py\u001b[0m in \u001b[0;36mcached_tensordot\u001b[0;34m(x, y, axes, backend)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcached_tensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'numpy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcurrently_sharing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# hash based on the (axes_x,axes_y) form of axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/opt_einsum/contract.py\u001b[0m in \u001b[0;36m_tensordot\u001b[0;34m(x, y, axes, backend)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \"\"\"\n\u001b[1;32m    373\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensordot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/opt_einsum/backends/torch.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(x, y, axes)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_TORCH_HAS_TENSORDOT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mxnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(a, b, dims)\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0mdims_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m         \u001b[0mdims_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims_b\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcartesian_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sc = sf.SlicedContractor([*small_cores])\n",
    "result = sum(sc.contract_slice(i) for i in tqdm.trange(sc.nslices))\n",
    "# 100%|██████████| 512/512 [00:55<00:00,  9.30it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import opt_einsum as oe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 8), (0, 7), (0, 7), (0, 6), (0, 5), (0, 4), (0, 3), (1, 2), (0, 1), (0, 9), (0, 8), (0, 8), (0, 7), (0, 6), (1, 5), (1, 4), (1, 3), (1, 4), (3, 13), (7, 12), (3, 11), (3, 10), (3, 9), (3, 8), (6, 7), (3, 6), (3, 5), (3, 4), (2, 6), (2, 10), (1, 11), (4, 11), (0, 13), (5, 12), (5, 12), (6, 12), (5, 12), (6, 11), (6, 11), (6, 12), (4, 12), (6, 13), (7, 14), (7, 13), (4, 12), (6, 11), (6, 11), (6, 10), (6, 10), (0, 11), (0, 11), (5, 10), (0, 9), (4, 9), (2, 9), (1, 8), (3, 7), (3, 7), (3, 9), (3, 9), (3, 10), (3, 10), (3, 9), (3, 8), (1, 7), (2, 6), (6, 7), (2, 6), (2, 5), (2, 5), (5, 17), (6, 18), (12, 21), (4, 23), (13, 22), (4, 21), (15, 23), (10, 23), (10, 22), (7, 27), (11, 27), (11, 27), (11, 26), (7, 29), (9, 29), (8, 28), (15, 29), (7, 28), (13, 29), (6, 31), (6, 30), (13, 29), (16, 29), (1, 20), (21, 26), (21, 25), (6, 24), (15, 30), (15, 29), (8, 28), (10, 27), (6, 27), (10, 26), (8, 25), (9, 24), (5, 23), (2, 21), (10, 25), (5, 24), (2, 23), (1, 33), (1, 21), (0, 31), (2, 19), (4, 21), (5, 10), (7, 9), (4, 20), (1, 19), (0, 20), (14, 15), (6, 10), (3, 9), (2, 9), (5, 15), (0, 13), (6, 9), (5, 8), (4, 13), (3, 13), (1, 8), (1, 12), (0, 6), (1, 10), (3, 9), (7, 8), (3, 7), (0, 6), (2, 5), (3, 4), (2, 3), (0, 2), (0, 1)]\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn(12,12,4,4,4,4)/2\n",
    "#tensor     = torch.randn(2,2,16,16,16,16)/10\n",
    "computer_vie_tn(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arbitary partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### generate json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from models.arbitary_shape.shapes_list import shape_24x24_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from mltool.visualization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [
     5
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "info_per_point = {}\n",
    "info_per_group = {}\n",
    "for i,line in enumerate(shape_24x24_1):\n",
    "    for j,val in enumerate(line):\n",
    "        info_per_point[(i,j)] = {'val':val}\n",
    "def search_for(pos,group=None):\n",
    "    i,j = pos\n",
    "    val = info_per_point[pos]['val']\n",
    "    if 'group' not in info_per_point[pos]:\n",
    "        if group is None:group=len(info_per_group)\n",
    "        info_per_point[pos]['group']=group\n",
    "        if group not in info_per_group:info_per_group[group]={'element':[],'neighbor':set()}\n",
    "        info_per_group[group]['element'].append((i,j))\n",
    "        for neighbor in [(i-1,j),(i+1,j),(i,j-1),(i,j+1)]:    \n",
    "            if (neighbor in info_per_point):\n",
    "                neighbor_val = info_per_point[neighbor]['val']\n",
    "                if ('group' not in info_per_point[neighbor]) and (val == neighbor_val):\n",
    "                    search_for(neighbor,group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i,line in enumerate(shape_24x24_1):\n",
    "    for j,val in enumerate(line):\n",
    "        search_for((i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "info_per_line={}\n",
    "for i,line in enumerate(shape_24x24_1):\n",
    "    for j,val in enumerate(line):\n",
    "        group_now = info_per_point[(i,j)]['group']\n",
    "        for neighbor in [(i-1,j),(i+1,j),(i,j-1),(i+1)]:\n",
    "            if neighbor in info_per_point:\n",
    "                neighbor_group = info_per_point[neighbor]['group']\n",
    "                if neighbor_group!=group_now:\n",
    "                    info_per_group[group_now]['neighbor']=info_per_group[group_now]['neighbor']|set([neighbor_group])\n",
    "                    line_tuple = [group_now,neighbor_group]\n",
    "                    line_tuple.sort() \n",
    "                    line_tuple= tuple(line_tuple)\n",
    "                    if line_tuple not in info_per_line:\n",
    "                        info_per_line[line_tuple]={\"element\":[]}\n",
    "                    linepos=[(i,j),neighbor]\n",
    "                    linepos.sort() \n",
    "                    info_per_line[line_tuple][\"element\"].append(linepos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "center = np.array([(0+23)/2,(0+23)/2]) \n",
    "for line,pool in info_per_line.items():\n",
    "    start_pos=np.array([a for a,b in pool['element']])\n",
    "    ended_pos=np.array([b for a,b in pool['element']])\n",
    "    start_pos=np.mean(start_pos,0)\n",
    "    ended_pos=np.mean(ended_pos,0)\n",
    "    centr_pos=(start_pos + ended_pos)/2\n",
    "    \n",
    "    info_per_line[line]['weight']    = np.linalg.norm(centr_pos-center)\n",
    "    info_per_line[line]['start_pos'] = list(start_pos)\n",
    "    info_per_line[line]['ended_pos'] = list(ended_pos)\n",
    "    info_per_line[line]['centr_pos'] = list(centr_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MAX_Dimension = 12\n",
    "MIN_Dimension = 3\n",
    "weight_list  = [val['weight'] for val in info_per_line.values()]\n",
    "max_distance = max(weight_list)\n",
    "min_distance = min(weight_list)\n",
    "Dimenstion_function = lambda x : np.floor((MIN_Dimension-MAX_Dimension)/(max_distance-min_distance)*(x-min_distance)+MAX_Dimension)\n",
    "\n",
    "for line,pool in info_per_line.items():\n",
    "    info_per_line[line]['D']    = Dimenstion_function(info_per_line[line]['weight'])\n",
    "\n",
    "for group in info_per_group.keys():\n",
    "    info_per_group[group]['neighbor']=list(info_per_group[group]['neighbor'])\n",
    "\n",
    "for group,info in info_per_group.items():\n",
    "    info_per_group[group]['element_idx']=np.ravel_multi_index(np.array(info['element']).transpose(),(24,24)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "arbitary_shape_state_dict={}\n",
    "arbitary_shape_state_dict['node']   =info_per_group\n",
    "arbitary_shape_state_dict['line']   =info_per_line\n",
    "arbitary_shape_state_dict['element']=info_per_point\n",
    "torch.save(arbitary_shape_state_dict,\"models/arbitary_shape/arbitary_shape_2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "heading_collapsed": true
   },
   "source": [
    "##### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "code_folding": [
     12
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "objects = []\n",
    "offsite = 0.5\n",
    "scalar  = 4\n",
    "for (g_l,g_r), pool in info_per_line.items():\n",
    "    start_pos=pool['start_pos']\n",
    "    ended_pos=pool['ended_pos']\n",
    "    D = pool['D']\n",
    "    x0,y0  = scalar*start_pos\n",
    "    x1,y1  = scalar*ended_pos\n",
    "    objects.append(go.Scatter(x=[x0,x1],y=[y0,y1],mode='lines', fill=\"toself\",\n",
    "                          text=f\"D={D}\",hoveron='points',hoverinfo='text'\n",
    "                             )\n",
    "                  )\n",
    "\n",
    "for group, pool in info_per_group.items():\n",
    "    xes,yes=np.array(pool['element']).transpose()\n",
    "    w = max(xes)-min(xes)\n",
    "    h = max(yes)-min(yes)\n",
    "    c_x = xes.mean()\n",
    "    c_y = yes.mean()\n",
    "    x0  = scalar*min(xes)-offsite\n",
    "    x1  = scalar*max(xes)+offsite\n",
    "    y0  = scalar*min(yes)-offsite\n",
    "    y1  = scalar*max(yes)+offsite\n",
    "    objects.append(go.Scatter(x=[x0,x0,x1,x1,x0],y=[y0,y1,y1,y0,y0],mode='lines',fill=\"toself\",\n",
    "                               hoveron='fills',hoverinfo='text',text=f\"G={group}\",\n",
    "                              ))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=2.0",
         "type": "scatter",
         "x": [
          12,
          12
         ],
         "y": [
          20,
          24
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=2.0",
         "type": "scatter",
         "x": [
          2,
          2
         ],
         "y": [
          28,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=2.0",
         "type": "scatter",
         "x": [
          2,
          2
         ],
         "y": [
          60,
          64
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=2.0",
         "type": "scatter",
         "x": [
          12,
          12
         ],
         "y": [
          68,
          72
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          4,
          8
         ],
         "y": [
          46,
          46
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          10,
          10
         ],
         "y": [
          28,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          10,
          10
         ],
         "y": [
          60,
          64
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          12,
          16
         ],
         "y": [
          36,
          36
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          12,
          16
         ],
         "y": [
          46,
          46
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          12,
          16
         ],
         "y": [
          56,
          56
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          20,
          20
         ],
         "y": [
          28,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          20,
          20
         ],
         "y": [
          40,
          44
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          20,
          20
         ],
         "y": [
          48,
          52
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          20,
          20
         ],
         "y": [
          60,
          64
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=2.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          4,
          4
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          14,
          14
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          20,
          20
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          26,
          26
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          32,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          38,
          38
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          46,
          46
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          54,
          54
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          60,
          60
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          66,
          66
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          72,
          72
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          78,
          78
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=2.0",
         "type": "scatter",
         "x": [
          24,
          28
         ],
         "y": [
          88,
          88
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          48,
          48
         ],
         "y": [
          8,
          12
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          48,
          48
         ],
         "y": [
          16,
          20
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          32,
          32
         ],
         "y": [
          20,
          24
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          32,
          32
         ],
         "y": [
          32,
          36
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          32,
          32
         ],
         "y": [
          40,
          44
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          32,
          32
         ],
         "y": [
          48,
          52
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          32,
          32
         ],
         "y": [
          56,
          60
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          32,
          32
         ],
         "y": [
          68,
          72
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          48,
          48
         ],
         "y": [
          72,
          76
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          48,
          48
         ],
         "y": [
          80,
          84
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          36,
          40
         ],
         "y": [
          26,
          26
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          36,
          40
         ],
         "y": [
          32,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          36,
          40
         ],
         "y": [
          38,
          38
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          36,
          40
         ],
         "y": [
          46,
          46
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          36,
          40
         ],
         "y": [
          54,
          54
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          36,
          40
         ],
         "y": [
          60,
          60
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          36,
          40
         ],
         "y": [
          66,
          66
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          44,
          44
         ],
         "y": [
          20,
          24
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          44,
          44
         ],
         "y": [
          28,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          44,
          44
         ],
         "y": [
          40,
          44
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          44,
          44
         ],
         "y": [
          48,
          52
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          44,
          44
         ],
         "y": [
          60,
          64
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          44,
          44
         ],
         "y": [
          68,
          72
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          48,
          52
         ],
         "y": [
          26,
          26
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          48,
          52
         ],
         "y": [
          32,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          48,
          52
         ],
         "y": [
          38,
          38
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=8.0",
         "type": "scatter",
         "x": [
          48,
          52
         ],
         "y": [
          46,
          46
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          48,
          52
         ],
         "y": [
          54,
          54
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          48,
          52
         ],
         "y": [
          60,
          60
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          48,
          52
         ],
         "y": [
          66,
          66
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          56,
          56
         ],
         "y": [
          20,
          24
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          56,
          56
         ],
         "y": [
          32,
          36
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          56,
          56
         ],
         "y": [
          40,
          44
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=7.0",
         "type": "scatter",
         "x": [
          56,
          56
         ],
         "y": [
          48,
          52
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          56,
          56
         ],
         "y": [
          56,
          60
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          56,
          56
         ],
         "y": [
          68,
          72
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          60,
          64
         ],
         "y": [
          26,
          26
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          60,
          64
         ],
         "y": [
          32,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          60,
          64
         ],
         "y": [
          38,
          38
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          60,
          64
         ],
         "y": [
          46,
          46
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=6.0",
         "type": "scatter",
         "x": [
          60,
          64
         ],
         "y": [
          54,
          54
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          60,
          64
         ],
         "y": [
          60,
          60
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          60,
          64
         ],
         "y": [
          66,
          66
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          66,
          66
         ],
         "y": [
          20,
          24
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          68,
          68
         ],
         "y": [
          28,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          68,
          68
         ],
         "y": [
          40,
          44
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=5.0",
         "type": "scatter",
         "x": [
          68,
          68
         ],
         "y": [
          48,
          52
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          68,
          68
         ],
         "y": [
          60,
          64
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          66,
          66
         ],
         "y": [
          68,
          72
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=2.0",
         "type": "scatter",
         "x": [
          68,
          72
         ],
         "y": [
          4,
          4
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          68,
          72
         ],
         "y": [
          14,
          14
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          68,
          72
         ],
         "y": [
          20,
          20
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          68,
          72
         ],
         "y": [
          72,
          72
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          68,
          72
         ],
         "y": [
          78,
          78
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=2.0",
         "type": "scatter",
         "x": [
          68,
          72
         ],
         "y": [
          88,
          88
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=2.0",
         "type": "scatter",
         "x": [
          82,
          82
         ],
         "y": [
          20,
          24
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          72,
          76
         ],
         "y": [
          36,
          36
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          72,
          76
         ],
         "y": [
          46,
          46
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=4.0",
         "type": "scatter",
         "x": [
          72,
          76
         ],
         "y": [
          56,
          56
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=2.0",
         "type": "scatter",
         "x": [
          82,
          82
         ],
         "y": [
          68,
          72
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          78,
          78
         ],
         "y": [
          28,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          78,
          78
         ],
         "y": [
          60,
          64
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=3.0",
         "type": "scatter",
         "x": [
          80,
          84
         ],
         "y": [
          46,
          46
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=2.0",
         "type": "scatter",
         "x": [
          88,
          88
         ],
         "y": [
          28,
          32
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "points",
         "mode": "lines",
         "text": "D=2.0",
         "type": "scatter",
         "x": [
          88,
          88
         ],
         "y": [
          60,
          64
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=0",
         "type": "scatter",
         "x": [
          -0.5,
          -0.5,
          24.5,
          24.5,
          -0.5
         ],
         "y": [
          -0.5,
          20.5,
          20.5,
          -0.5,
          -0.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=1",
         "type": "scatter",
         "x": [
          -0.5,
          -0.5,
          24.5,
          24.5,
          -0.5
         ],
         "y": [
          23.5,
          28.5,
          28.5,
          23.5,
          23.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=2",
         "type": "scatter",
         "x": [
          -0.5,
          -0.5,
          4.5,
          4.5,
          -0.5
         ],
         "y": [
          31.5,
          60.5,
          60.5,
          31.5,
          31.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=3",
         "type": "scatter",
         "x": [
          -0.5,
          -0.5,
          24.5,
          24.5,
          -0.5
         ],
         "y": [
          63.5,
          68.5,
          68.5,
          63.5,
          63.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=4",
         "type": "scatter",
         "x": [
          -0.5,
          -0.5,
          24.5,
          24.5,
          -0.5
         ],
         "y": [
          71.5,
          92.5,
          92.5,
          71.5,
          71.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=5",
         "type": "scatter",
         "x": [
          7.5,
          7.5,
          12.5,
          12.5,
          7.5
         ],
         "y": [
          31.5,
          60.5,
          60.5,
          31.5,
          31.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=6",
         "type": "scatter",
         "x": [
          15.5,
          15.5,
          24.5,
          24.5,
          15.5
         ],
         "y": [
          31.5,
          40.5,
          40.5,
          31.5,
          31.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=7",
         "type": "scatter",
         "x": [
          15.5,
          15.5,
          24.5,
          24.5,
          15.5
         ],
         "y": [
          43.5,
          48.5,
          48.5,
          43.5,
          43.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=8",
         "type": "scatter",
         "x": [
          15.5,
          15.5,
          24.5,
          24.5,
          15.5
         ],
         "y": [
          51.5,
          60.5,
          60.5,
          51.5,
          51.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=9",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          68.5,
          68.5,
          27.5
         ],
         "y": [
          -0.5,
          8.5,
          8.5,
          -0.5,
          -0.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=10",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          68.5,
          68.5,
          27.5
         ],
         "y": [
          11.5,
          16.5,
          16.5,
          11.5,
          11.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=11",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          68.5,
          68.5,
          27.5
         ],
         "y": [
          19.5,
          20.5,
          20.5,
          19.5,
          19.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=12",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          36.5,
          36.5,
          27.5
         ],
         "y": [
          23.5,
          32.5,
          32.5,
          23.5,
          23.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=13",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          36.5,
          36.5,
          27.5
         ],
         "y": [
          35.5,
          40.5,
          40.5,
          35.5,
          35.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=14",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          36.5,
          36.5,
          27.5
         ],
         "y": [
          43.5,
          48.5,
          48.5,
          43.5,
          43.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=15",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          36.5,
          36.5,
          27.5
         ],
         "y": [
          51.5,
          56.5,
          56.5,
          51.5,
          51.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=16",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          36.5,
          36.5,
          27.5
         ],
         "y": [
          59.5,
          68.5,
          68.5,
          59.5,
          59.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=17",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          68.5,
          68.5,
          27.5
         ],
         "y": [
          71.5,
          72.5,
          72.5,
          71.5,
          71.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=18",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          68.5,
          68.5,
          27.5
         ],
         "y": [
          75.5,
          80.5,
          80.5,
          75.5,
          75.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=19",
         "type": "scatter",
         "x": [
          27.5,
          27.5,
          68.5,
          68.5,
          27.5
         ],
         "y": [
          83.5,
          92.5,
          92.5,
          83.5,
          83.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=20",
         "type": "scatter",
         "x": [
          39.5,
          39.5,
          48.5,
          48.5,
          39.5
         ],
         "y": [
          23.5,
          28.5,
          28.5,
          23.5,
          23.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=21",
         "type": "scatter",
         "x": [
          39.5,
          39.5,
          48.5,
          48.5,
          39.5
         ],
         "y": [
          31.5,
          40.5,
          40.5,
          31.5,
          31.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=22",
         "type": "scatter",
         "x": [
          39.5,
          39.5,
          48.5,
          48.5,
          39.5
         ],
         "y": [
          43.5,
          48.5,
          48.5,
          43.5,
          43.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=23",
         "type": "scatter",
         "x": [
          39.5,
          39.5,
          48.5,
          48.5,
          39.5
         ],
         "y": [
          51.5,
          60.5,
          60.5,
          51.5,
          51.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=24",
         "type": "scatter",
         "x": [
          39.5,
          39.5,
          48.5,
          48.5,
          39.5
         ],
         "y": [
          63.5,
          68.5,
          68.5,
          63.5,
          63.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=25",
         "type": "scatter",
         "x": [
          51.5,
          51.5,
          60.5,
          60.5,
          51.5
         ],
         "y": [
          23.5,
          32.5,
          32.5,
          23.5,
          23.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=26",
         "type": "scatter",
         "x": [
          51.5,
          51.5,
          60.5,
          60.5,
          51.5
         ],
         "y": [
          35.5,
          40.5,
          40.5,
          35.5,
          35.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=27",
         "type": "scatter",
         "x": [
          51.5,
          51.5,
          60.5,
          60.5,
          51.5
         ],
         "y": [
          43.5,
          48.5,
          48.5,
          43.5,
          43.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=28",
         "type": "scatter",
         "x": [
          51.5,
          51.5,
          60.5,
          60.5,
          51.5
         ],
         "y": [
          51.5,
          56.5,
          56.5,
          51.5,
          51.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=29",
         "type": "scatter",
         "x": [
          51.5,
          51.5,
          60.5,
          60.5,
          51.5
         ],
         "y": [
          59.5,
          68.5,
          68.5,
          59.5,
          59.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=30",
         "type": "scatter",
         "x": [
          63.5,
          63.5,
          92.5,
          92.5,
          63.5
         ],
         "y": [
          23.5,
          28.5,
          28.5,
          23.5,
          23.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=31",
         "type": "scatter",
         "x": [
          63.5,
          63.5,
          72.5,
          72.5,
          63.5
         ],
         "y": [
          31.5,
          40.5,
          40.5,
          31.5,
          31.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=32",
         "type": "scatter",
         "x": [
          63.5,
          63.5,
          72.5,
          72.5,
          63.5
         ],
         "y": [
          43.5,
          48.5,
          48.5,
          43.5,
          43.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=33",
         "type": "scatter",
         "x": [
          63.5,
          63.5,
          72.5,
          72.5,
          63.5
         ],
         "y": [
          51.5,
          60.5,
          60.5,
          51.5,
          51.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=34",
         "type": "scatter",
         "x": [
          63.5,
          63.5,
          92.5,
          92.5,
          63.5
         ],
         "y": [
          63.5,
          68.5,
          68.5,
          63.5,
          63.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=35",
         "type": "scatter",
         "x": [
          71.5,
          71.5,
          92.5,
          92.5,
          71.5
         ],
         "y": [
          -0.5,
          20.5,
          20.5,
          -0.5,
          -0.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=36",
         "type": "scatter",
         "x": [
          71.5,
          71.5,
          92.5,
          92.5,
          71.5
         ],
         "y": [
          71.5,
          92.5,
          92.5,
          71.5,
          71.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=37",
         "type": "scatter",
         "x": [
          75.5,
          75.5,
          80.5,
          80.5,
          75.5
         ],
         "y": [
          31.5,
          60.5,
          60.5,
          31.5,
          31.5
         ]
        },
        {
         "fill": "toself",
         "hoverinfo": "text",
         "hoveron": "fills",
         "mode": "lines",
         "text": "G=38",
         "type": "scatter",
         "x": [
          83.5,
          83.5,
          92.5,
          92.5,
          83.5
         ],
         "y": [
          31.5,
          60.5,
          60.5,
          31.5,
          31.5
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "height": 900,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 900,
        "xaxis": {
         "fixedrange": true,
         "showgrid": false,
         "showline": false,
         "showticklabels": false,
         "zeroline": false
        },
        "yaxis": {
         "scaleanchor": "x",
         "scaleratio": 1,
         "showgrid": false,
         "showline": false,
         "showticklabels": false,
         "zeroline": false
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"0340e75a-b75d-42b7-bd95-945d9a681b86\" class=\"plotly-graph-div\" style=\"height:900px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0340e75a-b75d-42b7-bd95-945d9a681b86\")) {                    Plotly.newPlot(                        \"0340e75a-b75d-42b7-bd95-945d9a681b86\",                        [{\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=2.0\", \"type\": \"scatter\", \"x\": [12.0, 12.0], \"y\": [20.0, 24.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=2.0\", \"type\": \"scatter\", \"x\": [2.0, 2.0], \"y\": [28.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=2.0\", \"type\": \"scatter\", \"x\": [2.0, 2.0], \"y\": [60.0, 64.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=2.0\", \"type\": \"scatter\", \"x\": [12.0, 12.0], \"y\": [68.0, 72.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [4.0, 8.0], \"y\": [46.0, 46.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [10.0, 10.0], \"y\": [28.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [10.0, 10.0], \"y\": [60.0, 64.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [12.0, 16.0], \"y\": [36.0, 36.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [12.0, 16.0], \"y\": [46.0, 46.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [12.0, 16.0], \"y\": [56.0, 56.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [20.0, 20.0], \"y\": [28.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [20.0, 20.0], \"y\": [40.0, 44.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [20.0, 20.0], \"y\": [48.0, 52.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [20.0, 20.0], \"y\": [60.0, 64.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=2.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [4.0, 4.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [14.0, 14.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [20.0, 20.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [26.0, 26.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [32.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [38.0, 38.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [46.0, 46.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [54.0, 54.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [60.0, 60.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [66.0, 66.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [72.0, 72.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [78.0, 78.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=2.0\", \"type\": \"scatter\", \"x\": [24.0, 28.0], \"y\": [88.0, 88.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [48.0, 48.0], \"y\": [8.0, 12.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [48.0, 48.0], \"y\": [16.0, 20.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [32.0, 32.0], \"y\": [20.0, 24.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [32.0, 32.0], \"y\": [32.0, 36.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [32.0, 32.0], \"y\": [40.0, 44.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [32.0, 32.0], \"y\": [48.0, 52.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [32.0, 32.0], \"y\": [56.0, 60.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [32.0, 32.0], \"y\": [68.0, 72.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [48.0, 48.0], \"y\": [72.0, 76.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [48.0, 48.0], \"y\": [80.0, 84.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [36.0, 40.0], \"y\": [26.0, 26.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [36.0, 40.0], \"y\": [32.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [36.0, 40.0], \"y\": [38.0, 38.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [36.0, 40.0], \"y\": [46.0, 46.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [36.0, 40.0], \"y\": [54.0, 54.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [36.0, 40.0], \"y\": [60.0, 60.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [36.0, 40.0], \"y\": [66.0, 66.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [44.0, 44.0], \"y\": [20.0, 24.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [44.0, 44.0], \"y\": [28.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [44.0, 44.0], \"y\": [40.0, 44.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [44.0, 44.0], \"y\": [48.0, 52.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [44.0, 44.0], \"y\": [60.0, 64.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [44.0, 44.0], \"y\": [68.0, 72.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [48.0, 52.0], \"y\": [26.0, 26.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [48.0, 52.0], \"y\": [32.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [48.0, 52.0], \"y\": [38.0, 38.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=8.0\", \"type\": \"scatter\", \"x\": [48.0, 52.0], \"y\": [46.0, 46.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [48.0, 52.0], \"y\": [54.0, 54.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [48.0, 52.0], \"y\": [60.0, 60.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [48.0, 52.0], \"y\": [66.0, 66.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [56.0, 56.0], \"y\": [20.0, 24.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [56.0, 56.0], \"y\": [32.0, 36.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [56.0, 56.0], \"y\": [40.0, 44.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=7.0\", \"type\": \"scatter\", \"x\": [56.0, 56.0], \"y\": [48.0, 52.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [56.0, 56.0], \"y\": [56.0, 60.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [56.0, 56.0], \"y\": [68.0, 72.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [60.0, 64.0], \"y\": [26.0, 26.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [60.0, 64.0], \"y\": [32.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [60.0, 64.0], \"y\": [38.0, 38.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [60.0, 64.0], \"y\": [46.0, 46.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=6.0\", \"type\": \"scatter\", \"x\": [60.0, 64.0], \"y\": [54.0, 54.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [60.0, 64.0], \"y\": [60.0, 60.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [60.0, 64.0], \"y\": [66.0, 66.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [66.0, 66.0], \"y\": [20.0, 24.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [68.0, 68.0], \"y\": [28.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [68.0, 68.0], \"y\": [40.0, 44.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=5.0\", \"type\": \"scatter\", \"x\": [68.0, 68.0], \"y\": [48.0, 52.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [68.0, 68.0], \"y\": [60.0, 64.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [66.0, 66.0], \"y\": [68.0, 72.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=2.0\", \"type\": \"scatter\", \"x\": [68.0, 72.0], \"y\": [4.0, 4.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [68.0, 72.0], \"y\": [14.0, 14.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [68.0, 72.0], \"y\": [20.0, 20.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [68.0, 72.0], \"y\": [72.0, 72.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [68.0, 72.0], \"y\": [78.0, 78.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=2.0\", \"type\": \"scatter\", \"x\": [68.0, 72.0], \"y\": [88.0, 88.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=2.0\", \"type\": \"scatter\", \"x\": [82.0, 82.0], \"y\": [20.0, 24.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [72.0, 76.0], \"y\": [36.0, 36.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [72.0, 76.0], \"y\": [46.0, 46.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=4.0\", \"type\": \"scatter\", \"x\": [72.0, 76.0], \"y\": [56.0, 56.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=2.0\", \"type\": \"scatter\", \"x\": [82.0, 82.0], \"y\": [68.0, 72.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [78.0, 78.0], \"y\": [28.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [78.0, 78.0], \"y\": [60.0, 64.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=3.0\", \"type\": \"scatter\", \"x\": [80.0, 84.0], \"y\": [46.0, 46.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=2.0\", \"type\": \"scatter\", \"x\": [88.0, 88.0], \"y\": [28.0, 32.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"points\", \"mode\": \"lines\", \"text\": \"D=2.0\", \"type\": \"scatter\", \"x\": [88.0, 88.0], \"y\": [60.0, 64.0]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=0\", \"type\": \"scatter\", \"x\": [-0.5, -0.5, 24.5, 24.5, -0.5], \"y\": [-0.5, 20.5, 20.5, -0.5, -0.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=1\", \"type\": \"scatter\", \"x\": [-0.5, -0.5, 24.5, 24.5, -0.5], \"y\": [23.5, 28.5, 28.5, 23.5, 23.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=2\", \"type\": \"scatter\", \"x\": [-0.5, -0.5, 4.5, 4.5, -0.5], \"y\": [31.5, 60.5, 60.5, 31.5, 31.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=3\", \"type\": \"scatter\", \"x\": [-0.5, -0.5, 24.5, 24.5, -0.5], \"y\": [63.5, 68.5, 68.5, 63.5, 63.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=4\", \"type\": \"scatter\", \"x\": [-0.5, -0.5, 24.5, 24.5, -0.5], \"y\": [71.5, 92.5, 92.5, 71.5, 71.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=5\", \"type\": \"scatter\", \"x\": [7.5, 7.5, 12.5, 12.5, 7.5], \"y\": [31.5, 60.5, 60.5, 31.5, 31.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=6\", \"type\": \"scatter\", \"x\": [15.5, 15.5, 24.5, 24.5, 15.5], \"y\": [31.5, 40.5, 40.5, 31.5, 31.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=7\", \"type\": \"scatter\", \"x\": [15.5, 15.5, 24.5, 24.5, 15.5], \"y\": [43.5, 48.5, 48.5, 43.5, 43.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=8\", \"type\": \"scatter\", \"x\": [15.5, 15.5, 24.5, 24.5, 15.5], \"y\": [51.5, 60.5, 60.5, 51.5, 51.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=9\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 68.5, 68.5, 27.5], \"y\": [-0.5, 8.5, 8.5, -0.5, -0.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=10\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 68.5, 68.5, 27.5], \"y\": [11.5, 16.5, 16.5, 11.5, 11.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=11\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 68.5, 68.5, 27.5], \"y\": [19.5, 20.5, 20.5, 19.5, 19.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=12\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 36.5, 36.5, 27.5], \"y\": [23.5, 32.5, 32.5, 23.5, 23.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=13\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 36.5, 36.5, 27.5], \"y\": [35.5, 40.5, 40.5, 35.5, 35.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=14\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 36.5, 36.5, 27.5], \"y\": [43.5, 48.5, 48.5, 43.5, 43.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=15\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 36.5, 36.5, 27.5], \"y\": [51.5, 56.5, 56.5, 51.5, 51.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=16\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 36.5, 36.5, 27.5], \"y\": [59.5, 68.5, 68.5, 59.5, 59.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=17\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 68.5, 68.5, 27.5], \"y\": [71.5, 72.5, 72.5, 71.5, 71.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=18\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 68.5, 68.5, 27.5], \"y\": [75.5, 80.5, 80.5, 75.5, 75.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=19\", \"type\": \"scatter\", \"x\": [27.5, 27.5, 68.5, 68.5, 27.5], \"y\": [83.5, 92.5, 92.5, 83.5, 83.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=20\", \"type\": \"scatter\", \"x\": [39.5, 39.5, 48.5, 48.5, 39.5], \"y\": [23.5, 28.5, 28.5, 23.5, 23.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=21\", \"type\": \"scatter\", \"x\": [39.5, 39.5, 48.5, 48.5, 39.5], \"y\": [31.5, 40.5, 40.5, 31.5, 31.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=22\", \"type\": \"scatter\", \"x\": [39.5, 39.5, 48.5, 48.5, 39.5], \"y\": [43.5, 48.5, 48.5, 43.5, 43.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=23\", \"type\": \"scatter\", \"x\": [39.5, 39.5, 48.5, 48.5, 39.5], \"y\": [51.5, 60.5, 60.5, 51.5, 51.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=24\", \"type\": \"scatter\", \"x\": [39.5, 39.5, 48.5, 48.5, 39.5], \"y\": [63.5, 68.5, 68.5, 63.5, 63.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=25\", \"type\": \"scatter\", \"x\": [51.5, 51.5, 60.5, 60.5, 51.5], \"y\": [23.5, 32.5, 32.5, 23.5, 23.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=26\", \"type\": \"scatter\", \"x\": [51.5, 51.5, 60.5, 60.5, 51.5], \"y\": [35.5, 40.5, 40.5, 35.5, 35.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=27\", \"type\": \"scatter\", \"x\": [51.5, 51.5, 60.5, 60.5, 51.5], \"y\": [43.5, 48.5, 48.5, 43.5, 43.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=28\", \"type\": \"scatter\", \"x\": [51.5, 51.5, 60.5, 60.5, 51.5], \"y\": [51.5, 56.5, 56.5, 51.5, 51.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=29\", \"type\": \"scatter\", \"x\": [51.5, 51.5, 60.5, 60.5, 51.5], \"y\": [59.5, 68.5, 68.5, 59.5, 59.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=30\", \"type\": \"scatter\", \"x\": [63.5, 63.5, 92.5, 92.5, 63.5], \"y\": [23.5, 28.5, 28.5, 23.5, 23.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=31\", \"type\": \"scatter\", \"x\": [63.5, 63.5, 72.5, 72.5, 63.5], \"y\": [31.5, 40.5, 40.5, 31.5, 31.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=32\", \"type\": \"scatter\", \"x\": [63.5, 63.5, 72.5, 72.5, 63.5], \"y\": [43.5, 48.5, 48.5, 43.5, 43.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=33\", \"type\": \"scatter\", \"x\": [63.5, 63.5, 72.5, 72.5, 63.5], \"y\": [51.5, 60.5, 60.5, 51.5, 51.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=34\", \"type\": \"scatter\", \"x\": [63.5, 63.5, 92.5, 92.5, 63.5], \"y\": [63.5, 68.5, 68.5, 63.5, 63.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=35\", \"type\": \"scatter\", \"x\": [71.5, 71.5, 92.5, 92.5, 71.5], \"y\": [-0.5, 20.5, 20.5, -0.5, -0.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=36\", \"type\": \"scatter\", \"x\": [71.5, 71.5, 92.5, 92.5, 71.5], \"y\": [71.5, 92.5, 92.5, 71.5, 71.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=37\", \"type\": \"scatter\", \"x\": [75.5, 75.5, 80.5, 80.5, 75.5], \"y\": [31.5, 60.5, 60.5, 31.5, 31.5]}, {\"fill\": \"toself\", \"hoverinfo\": \"text\", \"hoveron\": \"fills\", \"mode\": \"lines\", \"text\": \"G=38\", \"type\": \"scatter\", \"x\": [83.5, 83.5, 92.5, 92.5, 83.5], \"y\": [31.5, 60.5, 60.5, 31.5, 31.5]}],                        {\"autosize\": false, \"height\": 900, \"hoverlabel\": {\"bgcolor\": \"white\", \"font\": {\"family\": \"Rockwell\", \"size\": 16}}, \"plot_bgcolor\": \"white\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"width\": 900, \"xaxis\": {\"fixedrange\": true, \"showgrid\": false, \"showline\": false, \"showticklabels\": false, \"zeroline\": false}, \"yaxis\": {\"scaleanchor\": \"x\", \"scaleratio\": 1, \"showgrid\": false, \"showline\": false, \"showticklabels\": false, \"zeroline\": false}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('0340e75a-b75d-42b7-bd95-945d9a681b86');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "axis = dict(showline=False, zeroline=False,showgrid=False,showticklabels=False,)\n",
    "fig.update_layout(showlegend=False,xaxis=axis,yaxis=axis,plot_bgcolor='white')\n",
    "fig.update_layout(\n",
    "         autosize=False,\n",
    "            width=900,\n",
    "            height=900,\n",
    "        hoverlabel=dict(\n",
    "        bgcolor=\"white\",\n",
    "        font_size=16,\n",
    "        font_family=\"Rockwell\"\n",
    "        )\n",
    ")\n",
    "fig.update_xaxes(fixedrange=True)\n",
    "fig.update_yaxes(scaleanchor = \"x\",scaleratio = 1,)\n",
    "#if show_name: self.depoly_label(fig)\n",
    "for obj in objects:fig.add_trace(obj)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4db68ba8d0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(np.array(shape_24x24_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from models.tensornetwork_base import TN_Base\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import opt_einsum as oe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rdetemp(shape,non_contracting_index=None):\n",
    "    tensor     = torch.rand(*shape)\n",
    "    if non_contracting_index:\n",
    "        if isinstance(non_contracting_index,int):non_contracting_index=[non_contracting_index]\n",
    "        assert isinstance(non_contracting_index,list)\n",
    "        real_order = list(range(len(shape)))\n",
    "        for _id in non_contracting_index:real_order.remove(_id)\n",
    "        tensor = tensor.permute(*non_contracting_index,*real_order)\n",
    "        rshape = tensor.shape\n",
    "        tensor = tensor.flatten(len(non_contracting_index),-1)\n",
    "        tensor = tensor/tensor.norm(dim=-1,keepdim=True)\n",
    "        tensor = tensor.reshape(*rshape)\n",
    "        out_order = np.argsort(non_contracting_index+real_order).tolist()\n",
    "        tensor = tensor.permute(*out_order)\n",
    "    else:\n",
    "        tensor     = tensor/tensor.norm()\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rdepossible(shape,non_contracting_index=None):\n",
    "    tensor     = torch.rand(*shape)\n",
    "    if non_contracting_index:\n",
    "        if isinstance(non_contracting_index,int):non_contracting_index=[non_contracting_index]\n",
    "        assert isinstance(non_contracting_index,list)\n",
    "        real_order = list(range(len(shape)))\n",
    "        for _id in non_contracting_index:real_order.remove(_id)\n",
    "        tensor = tensor.permute(*non_contracting_index,*real_order)\n",
    "        rshape = tensor.shape\n",
    "        tensor = tensor.flatten(len(non_contracting_index),-1)\n",
    "        tensor = tensor/tensor.norm(dim=-1,keepdim=True)\n",
    "        tensor = tensor.reshape(*rshape)\n",
    "        out_order = np.argsort(non_contracting_index+real_order).tolist()\n",
    "        tensor = tensor.permute(*out_order)\n",
    "    else:\n",
    "        tensor     = tensor/tensor.norm()\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class PEPS_einsum_arbitrary_partition_optim(TN_Base):\n",
    "    def __init__(self,out_features=10,in_physics_bond = 2, virtual_bond_dim=\"models/arbitary_shape/arbitary_shape_1.json\",\n",
    "                       bias=True,label_position='center',init_std=1e-10,contraction_mode = 'recursion',seted_variation=10):\n",
    "        super().__init__()\n",
    "        if isinstance(virtual_bond_dim,str):\n",
    "            arbitary_shape_state_dict = torch.load(virtual_bond_dim)\n",
    "        else:\n",
    "            arbitary_shape_state_dict = virtual_bond_dim\n",
    "        assert isinstance(arbitary_shape_state_dict,dict)\n",
    "        \n",
    "        \n",
    "        info_per_group = arbitary_shape_state_dict['node']\n",
    "        info_per_line  = arbitary_shape_state_dict['line']\n",
    "        info_per_point = arbitary_shape_state_dict['element']\n",
    "        \n",
    "        num_of_tensor   = len(info_per_group)\n",
    "        list_of_virt_dim= [t['D'] for t in info_per_line.values()]\n",
    "        list_of_phys_dim= [len(t['element']) for t in info_per_group.values()]\n",
    "        divider         = np.prod([np.power(t,1/num_of_tensor) for t in list_of_phys_dim+list_of_virt_dim])\n",
    "        solved_var      = np.power(seted_variation,1/num_of_tensor)/divider\n",
    "        solved_std      = np.sqrt(solved_var)\n",
    "        print(solved_std)\n",
    "        \n",
    "        center_group    = 0\n",
    "        damgling_num    = len(info_per_group)\n",
    "        info_per_group[center_group]['neighbor'].insert(0,damgling_num)\n",
    "        info_per_line[(center_group,damgling_num)]={'D': out_features}\n",
    "\n",
    "        self.info_per_group=info_per_group\n",
    "        self.info_per_line =info_per_line\n",
    "        self.info_per_point=info_per_point\n",
    "\n",
    "        operands = []\n",
    "        sublist_list=[]\n",
    "        outlist  = [list(info_per_line.keys()).index((center_group,damgling_num))]\n",
    "        ranks_list=[]\n",
    "        for group_now in range(len(info_per_group)):\n",
    "            group_info= info_per_group[group_now]\n",
    "            neighbors = group_info['neighbor']\n",
    "            ranks = []\n",
    "            sublist=[]\n",
    "            for neighbor_id in neighbors:\n",
    "                line_tuple = [group_now,neighbor_id]\n",
    "                line_tuple.sort()\n",
    "                line_tuple= tuple(line_tuple)\n",
    "                D = int(info_per_line[line_tuple]['D'])\n",
    "                idx = list(info_per_line.keys()).index(line_tuple)\n",
    "                ranks.append(D)\n",
    "                sublist.append(idx)\n",
    "            tensor = np.random.randn(*ranks)\n",
    "            operands+=[tensor,[*sublist]]\n",
    "\n",
    "            ranks_list.append(ranks)\n",
    "            sublist_list.append(sublist)\n",
    "        operands+= [[...,*outlist]]\n",
    "        path,info = oe.contract_path(*operands,optimize='random-greedy-128')\n",
    "\n",
    "        self.path         = path\n",
    "        self.sublist_list = sublist_list\n",
    "        self.outlist      = outlist\n",
    "    \n",
    "        # assume all element for the tensornetwork is indenpendent. \n",
    "        # The bond (include physics) list is l0,l1,l2,...,ln\n",
    "        # All element follow normal distribution X - sigma(0,alpha)\n",
    "        # where alpha is the variation we need to calculated.\n",
    "        # the output after contracting is also a tensor (may 1-rank scalar, 2-rank matrix, etc)\n",
    "        # the element of the output follow the composite normal distribution Y - sigma(0,beta)\n",
    "        # where beta = l0 x l1 x l2 x ... x ln x alpha^(# of tensor)\n",
    "        \n",
    "        unit_list = []\n",
    "        for i in range(len(sublist_list)):\n",
    "            shape = ranks_list[i]\n",
    "            P        = len(info_per_group[i]['element'])\n",
    "            control_mat = self.rde2D((P,*shape),0,physics_index=0,offset= 2 if i==center_group else 1)\n",
    "            bias_mat    = torch.normal(0,solved_std,(P,*shape))\n",
    "            bias_mat[control_mat.nonzero(as_tuple=True)]=0                           \n",
    "            unit_list.append(control_mat+bias_mat)\n",
    "            #unit_list.append(rdetemp((P,*shape),1 if i==center_group else None))\n",
    "            #unit_list.append()\n",
    "        assert len(unit_list)==len(sublist_list)\n",
    "\n",
    "        self.unit_list = [nn.Parameter(v) for v in unit_list]\n",
    "        for i, v in enumerate(self.unit_list):\n",
    "            self.register_parameter(f'unit_{i}', param=v)\n",
    "\n",
    "    def forward(self,input_data):\n",
    "        #input data shape B,1,W,H\n",
    "        assert len(input_data.shape)==4\n",
    "        input_data  = input_data.flatten(-3,-1)\n",
    "\n",
    "        _input = []\n",
    "        for i,unit in enumerate(self.unit_list):\n",
    "            patch_idx  = self.info_per_group[i]['element_idx']\n",
    "            batch_input= input_data[...,patch_idx] # B,P\n",
    "            batch_unit = torch.tensordot(batch_input,unit,dims=([-1], [0]))\n",
    "            #print(f\"{batch_input.norm()}-{unit.norm()}->{batch_unit.norm()}\")\n",
    "            _input.append(batch_unit)\n",
    "\n",
    "        operands=[]\n",
    "        for tensor,sublist in zip(_input,self.sublist_list):\n",
    "            operand = [tensor,[...,*sublist]]\n",
    "            operands+=operand\n",
    "        operands+= [[...,*self.outlist]]\n",
    "        return self.einsum_engine(*operands,optimize=self.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "arbitary_shape_state_dict = torch.load(\"models/arbitary_shape/arbitary_shape_2.json\")\n",
    "info_per_group = arbitary_shape_state_dict['node']\n",
    "info_per_line  = arbitary_shape_state_dict['line']\n",
    "info_per_point = arbitary_shape_state_dict['element']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.468471462094461"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(np.prod([t['D']*1.0 for t in info_per_line.values()]),1/len(info_per_line.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pattern=[]\n",
    "for i in range(24):\n",
    "    lines=[]\n",
    "    for j in range(24):\n",
    "        lines.append(info_per_point[i,j]['group'])\n",
    "    pattern.append(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc643eb32e8>"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05547900085248762\n"
     ]
    }
   ],
   "source": [
    "model = PEPS_einsum_arbitrary_partition_optim(virtual_bond_dim=\"models/arbitary_shape/arbitary_shape_1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.randn(10,1,24,24)\n",
    "model(a).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep model (with nonlienar layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### the random set for tensornetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tensornetwork_base import TN_Base\n",
    "import torch.nn as nn\n",
    "from models.model_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_recorder={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class PEPS_uniform_shape_symmetry_deep_model(TN_Base):\n",
    "    def __init__(self, W=6,H=6,out_features=16,\n",
    "                       in_physics_bond = 2, virtual_bond_dim=2,nonlinear_layer=nn.Sigmoid(),\n",
    "                       normlized_layer_module=nn.Identity,\n",
    "                       init_std=1e-10,bias=False,set_var=1):\n",
    "        super().__init__()\n",
    "        assert (W % 2 == 0) and (H % 2 == 0) and (W == H)\n",
    "        \n",
    "        num_of_edge     = (W-1)*H+(H-1)*W\n",
    "        num_of_unit     = W*H\n",
    "        solved_var      = np.power(set_var,1/num_of_unit)*np.power(1/virtual_bond_dim,num_of_edge/(num_of_unit))/in_physics_bond\n",
    "        solved_std      = np.sqrt(solved_var)\n",
    "        print(solved_std)\n",
    "        random_engine   = lambda shape:torch.normal(0,solved_std,shape)\n",
    "    \n",
    "        self.W             = W\n",
    "        self.H             = H\n",
    "        self.out_features  = out_features\n",
    "        O                  = np.power(out_features,1/4)\n",
    "        assert np.ceil(O) == np.floor(O)\n",
    "        self.O             = O = O.astype('uint')\n",
    "        assert isinstance(virtual_bond_dim,int)\n",
    "        self.D             = D = virtual_bond_dim\n",
    "        self.P             = P = in_physics_bond\n",
    "\n",
    "        self.LW = LW = W//2\n",
    "        self.LH = LH = H//2\n",
    "        self.bias = bias\n",
    "        tn2D_shape_list= [ [(O,4,D,D)]+[  (4,D,D,D)]*(LH-1) ]+ \\\n",
    "                         [ [(4,D,D,D)]+[(4,D,D,D,D)]*(LH-1)]*(LW-1)\n",
    "        tn2D_shape_list= [l for t in tn2D_shape_list for l in t]\n",
    "        unit_list      = [random_engine((P,*l)) for i,l in enumerate(tn2D_shape_list)]\n",
    "        #unit_list      = [rdetemp((P,*l),non_contracting_index=1 if i==0 else None) for i,l in enumerate(tn2D_shape_list)]\n",
    "        self.unit_list = [nn.Parameter(v) for v in unit_list]\n",
    "        for i, v in enumerate(self.unit_list):\n",
    "            self.register_parameter(f'unit_{i//LW}-{i%LW}', param=v)\n",
    "        \n",
    "        self.edge_contraction_path = []\n",
    "        self.edge_r_idx_per_round  = []\n",
    "        self.edge_d_idx_per_round  = []\n",
    "        self.cent_idx_per_round    = []\n",
    "        self.bias_list = []\n",
    "        \n",
    "        self.normlized_layers = nn.ModuleList([normlized_layer_module(int(O*4),affine=True) for _ in range(LW)])\n",
    "        #self.normlized_layers= nn.ModuleList([nn.Identity() for _ in range(LW)])\n",
    "        self.nonlinear_layer = nonlinear_layer \n",
    "        self.first_corn_idx  = np.ravel_multi_index([[0,0,1,1],[0,1,1,0]],(LW,LW)).tolist()\n",
    "        \n",
    "        \n",
    "        \n",
    "        L=1\n",
    "        if bias:\n",
    "            bias_tensor = random_engine((O,4,D**(L+1),D**(L+1)))\n",
    "            self.bias_list.append(nn.Parameter(bias_tensor))\n",
    "        for L in range(2,LW):\n",
    "            tn2D_shape_list = [[(D,D,D)]+[(D,D,D,D)]*(L-1)]\n",
    "            path,sublist_list,outlist = get_best_path(tn2D_shape_list,store=path_recorder,type='sub')\n",
    "            self.edge_contraction_path.append([path,sublist_list,outlist])\n",
    "            \n",
    "            point = np.array([(j,L) for j in range(L)]).transpose()\n",
    "            \n",
    "            self.edge_r_idx_per_round.append(np.ravel_multi_index(point,(LW,LW)).tolist())\n",
    "\n",
    "            point = np.array([(L,j) for j in range(L)]).transpose()\n",
    "            self.edge_d_idx_per_round.append(np.ravel_multi_index(point,(LW,LW)).tolist())\n",
    "            self.cent_idx_per_round.append(np.ravel_multi_index([L,L],(LW,LW)).tolist())\n",
    "            if bias:\n",
    "                bias_tensor = random_engine((O,4,D**(L+1),D**(L+1)))\n",
    "                self.bias_list.append(nn.Parameter(bias_tensor))\n",
    "        if bias:\n",
    "            for i, v in enumerate(self.bias_list):\n",
    "                self.register_parameter(f'bias_unit_{i}', param=v)\n",
    "    def forward(self,input_data):\n",
    "        #input data shape B,W,H,P\n",
    "        \n",
    "        input_data  = input_data.flatten(1,2).permute(1,0,2)#(L,B,P)\n",
    "        #print([\"{:.4f}\".format(t.norm().item()) for t in input_data])\n",
    "        #print([\"{:.4f}\".format(t.norm().item()) for t in self.unit_list])\n",
    "        batch_unit  = [torch.tensordot(_input,unit,dims=([-1], [0])) for _input,unit in zip(input_data,self.unit_list)]\n",
    "        #print([\"{:.4f}\".format(t.norm().item()) for t in batch_unit])\n",
    "        corn_tensors= [batch_unit[idx] for idx in self.first_corn_idx]\n",
    "        #print([t.shape for t in corn_tensors])\n",
    "        corn  = self.einsum_engine(\"kolab,klcdb,klefcg,klgha->kolhedf\",*corn_tensors).flatten(-4,-3).flatten(-2,-1)\n",
    "        \n",
    "        if self.bias:corn=corn+self.bias_list[0]\n",
    "        corn = self.nonlinear_layer(corn)\n",
    "        corn = self.normlized_layers[0](corn.flatten(1,2)).reshape(corn.shape)\n",
    "        #corn = self.normlized_layers[0](corn)\n",
    "        for i in range(len(self.cent_idx_per_round)):\n",
    "            path,sublist_list,outlist = self.edge_contraction_path[i]\n",
    "            edge_tensors= [torch.stack([batch_unit[id1],batch_unit[id2]]) for id1,id2 in zip(self.edge_r_idx_per_round[i],self.edge_d_idx_per_round[i])]\n",
    "            L = len(edge_tensors)\n",
    "            operands    = structure_operands(edge_tensors,sublist_list,outlist)\n",
    "            edge1,edge2 = self.einsum_engine(*operands,optimize=path).flatten(-2*L,-L-1).flatten(-L,-1)\n",
    "            cent_tensor = batch_unit[self.cent_idx_per_round[i]]\n",
    "            corn = self.einsum_engine(\"kolab,klcdb,klefcg,klgha->kolhedf\",corn ,edge1,cent_tensor,edge2).flatten(-4,-3).flatten(-2,-1)\n",
    "            if self.bias:corn=corn+self.bias_list[i+1]\n",
    "            corn = self.nonlinear_layer(corn)\n",
    "            corn = self.normlized_layers[i+1](corn.flatten(1,2)).reshape(corn.shape)\n",
    "            #corn = self.normlized_layers[i+1](corn)\n",
    "        # corn now is a tensor (B,4,0,D^(L/2),D^(L/2))\n",
    "        #corn   = self.einsum_engine(\"xmkab,xnkbc->xkmnac\",corn[:,:,[0,2]],corn[:,:,[1,3]]).flatten(-4,-3)\n",
    "        #corn   = self.einsum_engine(\"xmab,xnba->xmn\",corn[:,0],corn[:,1]).flatten(-2,-1)\n",
    "        corn   = self.einsum_engine(\"xiab,xjbc,xkcd,xlda->xijkl\",corn[:,:,0],corn[:,:,1],corn[:,:,2],corn[:,:,3]).flatten(-4,-1)\n",
    "        corn   = corn/self.D**((self.H+self.W)/2)\n",
    "        return corn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def rdetemp(shape,non_contracting_index=None):\n",
    "    tensor     = torch.randn(*shape)\n",
    "    if non_contracting_index:\n",
    "        if isinstance(non_contracting_index,int):non_contracting_index=[non_contracting_index]\n",
    "        assert isinstance(non_contracting_index,list)\n",
    "        real_order = list(range(len(shape)))\n",
    "        for _id in non_contracting_index:real_order.remove(_id)\n",
    "        tensor = tensor.permute(*non_contracting_index,*real_order)\n",
    "        rshape = tensor.shape\n",
    "        tensor = tensor.flatten(len(non_contracting_index),-1)\n",
    "        tensor = tensor/tensor.norm(dim=-1,keepdim=True)\n",
    "        tensor = tensor.reshape(*rshape)\n",
    "        out_order = np.argsort(non_contracting_index+real_order).tolist()\n",
    "        tensor = tensor.permute(*out_order)\n",
    "    else:\n",
    "        tensor     = tensor/tensor.norm()\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Contractor Test perodic condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D=4;L=H=W=5;B=10;\n",
    "tn2D_shape_list = [[(D,D)]+[(D,D,D)]*(H-1)]+[[(D,D,D)]+[(D,D,D,D)]*(H-1)]*(W-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path,sublist_list,outlist = get_best_path(tn2D_shape_list,store=path_recorder,type='sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tensornetwork as tn\n",
    "import opt_einsum as oe\n",
    "import os,json\n",
    "from tensornetwork.network_components import get_all_nondangling,get_all_dangling\n",
    "from tensornetwork.contractors.opt_einsum_paths.utils import get_subgraph_dangling,get_all_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equation   = \"kab,kcdb,kefcg,kgha->khedf\"\n",
    "tensor_l   = [torch.randn(B,D,D) ,torch.randn(B,D,D,D),torch.randn(B,D,D,D,D),torch.randn(B,D,D,D)]\n",
    "oe.contract_path(equation, *tensor_l)[0]\n",
    "path = oe.contract_path(equation, *tensor_l)[0]\n",
    "oe.contract(equation,*tensor_l,optimize=path).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rd_engine(*x,**kargs):\n",
    "    x =  torch.randn(*x,device='cpu',**kargs)\n",
    "    x/=  torch.norm(x).sqrt()\n",
    "    x =  torch.autograd.Variable(x,requires_grad=True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path_recorder={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from models.model_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tn2D_shape_list = [[(D,D)]+[(D,D,D)]*(H-1)]+[[(D,D,D)]+[(D,D,D,D)]*(H-1)]*(W-1)\n",
    "path,sublist_list,outlist = get_best_path(tn2D_shape_list,store=path_recorder,type='sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tensor_list     = [rd_engine(B,*l) for t in tn2D_shape_list for l in t]\n",
    "operands=[]\n",
    "for tensor,sublist in zip(tensor_list,sublist_list):\n",
    "    operand = [tensor,[...,*sublist]]\n",
    "    operands+=operand\n",
    "operands+= [[...,*outlist]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oe.contract(*operands,optimize=path).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### test_the_TRG_on_even_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Contractor2D/test_the_TRG_on_even_number.py\n"
     ]
    }
   ],
   "source": [
    "# #%%writefile Contractor2D/test_the_TRG_on_even_number.py\n",
    "# import torch\n",
    "# from Contractor2D.utils import apply_SVD\n",
    "\n",
    "# tensor = torch.randn(4,4,2,2,2,2)\n",
    "\n",
    "# print(uniform_shape_tensor_contractor_tn(tensor))\n",
    "\n",
    "# truncate= None\n",
    "# lu_tensor = tensor[0::2,0::2]\n",
    "# ld_tensor = tensor[0::2,1::2]\n",
    "# ru_tensor = tensor[1::2,0::2]\n",
    "# rd_tensor = tensor[1::2,1::2]\n",
    "# lu_lu,lu_rd = apply_SVD(lu_tensor,left_bond=[0,1],right_bond=[2,3],truncate=truncate)# abk ,kcd\n",
    "# rd_lu,rd_rd = apply_SVD(rd_tensor,left_bond=[0,1],right_bond=[2,3],truncate=truncate)# abk, kcd\n",
    "# ld_ld,ld_ru = apply_SVD(ld_tensor,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# bck, kda\n",
    "# ru_ld,ru_ru = apply_SVD(ru_tensor,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# bck, kda\n",
    "# tensor1     = torch.einsum(\"whicd,whjac,whbak,whdbl->whijkl\",\n",
    "#                             lu_rd,\n",
    "#                             ld_ru,\n",
    "#                             rd_lu,\n",
    "#                             ru_ld)\n",
    "# tensor2     = torch.einsum(\"whicd,whjac,whbak,whdbl->whijkl\",\n",
    "#                            rd_rd,\n",
    "#                            ru_ru.roll(-1,1),\n",
    "#                            lu_lu.roll(shifts=(-1, -1), dims=(0, 1)),\n",
    "#                            ld_ld.roll(-1,0))\n",
    "\n",
    "# print(tensor1_and_tensor2_contractor_tn(tensor1,tensor2))\n",
    "\n",
    "# #print(torch.einsum(\"abcd,cdab->\",tensor1[0,0],tensor2[0,0]))\n",
    "# left,right  = apply_SVD(tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)# ABK,KCD\n",
    "# lower,uppe  = apply_SVD(tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "# # new_tensor  = torch.einsum(\"whicd,whjac,whbak,whdbl->whijkl\",\n",
    "# #                            right,\n",
    "# #                            uppe,\n",
    "# #                            left.roll(shifts=-1,dims=0),\n",
    "# #                            lower.roll(shifts=1,dims=1))\n",
    "# new_tensor  = torch.einsum(\"whadi,whjba,whkcb,whdcl->whijkl\",\n",
    "#                            lower,\n",
    "#                            right.roll(-1,1),\n",
    "#                            uppe.roll(-1,1),\n",
    "#                            left.roll(shifts=(-1, -1), dims=(0, 1))\n",
    "#                            )\n",
    "# print(uniform_shape_tensor_contractor_tn(new_tensor))\n",
    "\n",
    "# torch.einsum(\"abn,nji,lkh,hdc,caw,wkj,ilm,mbd->\",\n",
    "#              lu_lu[0,0],lu_rd[0,0],\n",
    "#              rd_lu[0,0],rd_rd[0,0],\n",
    "#              ld_ld[0,0],ld_ru[0,0],\n",
    "#              ru_ld[0,0],ru_ru[0,0])\n",
    "\n",
    "# torch.einsum(\"abji,lkdc,jcak,dilb->\",\n",
    "#              torch.einsum(\"abn,nji->abji\",lu_lu[0,0],lu_rd[0,0]),\n",
    "#              torch.einsum(\"lkh,hdc->lkdc\",rd_lu[0,0],rd_rd[0,0]),\n",
    "#              torch.einsum(\"caw,wkj->jcak\",ld_ld[0,0],ld_ru[0,0]),\n",
    "#              torch.einsum(\"ilm,mbd->dilb\",ru_ld[0,0],ru_ru[0,0]))\n",
    "\n",
    "# torch.dist(torch.einsum(\"abn,nji->abji\",lu_lu[0,0],lu_rd[0,0]),lu_tensor)\n",
    "\n",
    "# torch.dist(torch.einsum(\"lkh,hdc->lkdc\",rd_lu[0,0],rd_rd[0,0]),rd_tensor)\n",
    "\n",
    "# torch.dist(torch.einsum(\"caw,wkj->jcak\",ld_ld[0,0],ld_ru[0,0]),ld_tensor)\n",
    "\n",
    "# torch.dist(torch.einsum(\"ilm,mbd->dilb\",ru_ld[0,0],ru_ru[0,0]),ru_tensor)\n",
    "\n",
    "# torch.dist(lu_tensor[0,0],tensor[0,0])\n",
    "\n",
    "# torch.dist(rd_tensor[0,0],tensor[1,1])\n",
    "\n",
    "# torch.dist(ld_tensor[0,0],tensor[0,1])\n",
    "\n",
    "# torch.dist(ru_tensor[0,0],tensor[1,0])\n",
    "\n",
    "# torch.einsum(\"abji,lkdc,jcak,dilb->\",\n",
    "#              torch.einsum(\"abn,nji->abji\",lu_lu[0,0],lu_rd[0,0]),\n",
    "#              torch.einsum(\"lkh,hdc->lkdc\",rd_lu[0,0],rd_rd[0,0]),\n",
    "#              torch.einsum(\"caw,wkj->jcak\",ld_ld[0,0],ld_ru[0,0]),\n",
    "#              torch.einsum(\"ilm,mbd->dilb\",ru_ld[0,0],ru_ru[0,0]))\n",
    "\n",
    "# torch.einsum(\"abcd,idjb,ckal,jlik->\",lu_tensor[0,0],ld_tensor[0,0],ru_tensor[0,0],rd_tensor[0,0])\n",
    "\n",
    "# torch.einsum(\"abcd,ciaj,ldkb,kjli->\",lu_tensor[0,0],ld_tensor[0,0],ru_tensor[0,0],rd_tensor[0,0])\n",
    "\n",
    "# tensor1 = tensor[0,0]\n",
    "# tensor2 = tensor[0,1]\n",
    "# tensor3 = tensor[1,0]\n",
    "# tensor4 = tensor[1,1]\n",
    "# torch.einsum(\"abcd,idjb,ckal,jlik->\",tensor1,tensor2,tensor3,tensor4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### check_the_brdc_coding_on_even_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Contractor2D/check_the_brdc_coding_on_even_number.py\n"
     ]
    }
   ],
   "source": [
    "# #%%writefile Contractor2D/check_the_brdc_coding_on_even_number.py\n",
    "# import torch\n",
    "# from Contractor2D.utils import apply_SVD\n",
    "\n",
    "# tensor     = torch.randn(8,8,2,2,2,2)/2\n",
    "# uniform_shape_tensor_contractor_tn(tensor)\n",
    "\n",
    "# lu_lu_origin,lu_rd_origin = apply_SVD(tensor[0::2,0::2],left_bond=[0,1],right_bond=[2,3],truncate=None)# abk ,kcd\n",
    "# rd_lu_origin,rd_rd_origin = apply_SVD(tensor[1::2,1::2],left_bond=[0,1],right_bond=[2,3],truncate=None)# abk, kcd\n",
    "# ld_ld_origin,ld_ru_origin = apply_SVD(tensor[0::2,1::2],left_bond=[1,2],right_bond=[3,0],truncate=None)# bck, kda\n",
    "# ru_ld_origin,ru_ru_origin = apply_SVD(tensor[1::2,0::2],left_bond=[1,2],right_bond=[3,0],truncate=None)# bck, kda\n",
    "\n",
    "# lu_lu,lu_rd = apply_SVD(bulk_tensor[0::2,0::2],left_bond=[0,1],right_bond=[2,3],truncate=None)# abk ,kcd\n",
    "# rd_lu,rd_rd = apply_SVD(bulk_tensor[1::2,1::2],left_bond=[0,1],right_bond=[2,3],truncate=None)# abk, kcd\n",
    "# ld_ld,ld_ru = apply_SVD(bulk_tensor[0::2,1::2],left_bond=[1,2],right_bond=[3,0],truncate=None)# bck, kda\n",
    "# ru_ld,ru_ru = apply_SVD(bulk_tensor[1::2,0::2],left_bond=[1,2],right_bond=[3,0],truncate=None)# bck, kda\n",
    "\n",
    "# print(lu_lu.shape)\n",
    "# print(rd_lu.shape)\n",
    "# print(ld_ld.shape)\n",
    "# print(ru_ld.shape)\n",
    "\n",
    "# lu_lu_should = lu_lu_origin[:,:]    ;lu_rd_should =lu_rd_origin[:,:]\n",
    "# rd_lu_should = rd_lu_origin[:-1,:-1];rd_rd_should =rd_rd_origin[:-1,:-1]\n",
    "# ld_ld_should = ld_ld_origin[:,:-1]  ;ld_ru_should =ld_ru_origin[:,:-1]\n",
    "# ru_ld_should = ru_ld_origin[:-1,:]  ;ru_ru_should =ru_ru_origin[:-1,:]\n",
    "\n",
    "# print(lu_lu_should.shape)\n",
    "# print(rd_lu_should.shape)\n",
    "# print(ld_ld_should.shape)\n",
    "# print(ru_ld_should.shape)\n",
    "\n",
    "# print(torch.dist(lu_lu_should,lu_lu),torch.dist(lu_rd_should,lu_rd))\n",
    "# print(torch.dist(rd_lu_should,rd_lu),torch.dist(rd_rd_should,rd_rd))\n",
    "# print(torch.dist(ld_ld_should,ld_ld),torch.dist(ld_ru_should,ld_ru))\n",
    "# print(torch.dist(ru_ld_should,ru_ld),torch.dist(ru_ru_should,ru_ru))\n",
    "\n",
    "# # right_edge == bulk_tensor[-1]\n",
    "# # down_edge  == bulk_tensor[:,-1]\n",
    "\n",
    "# rd_lu_r,rd_rd_r = apply_SVD(right_edge[1::2],left_bond=[0,1],right_bond=[2,3],truncate=None)# abk, kcd\n",
    "# ru_ld_r,ru_ru_r = apply_SVD(right_edge[0::2],left_bond=[1,2],right_bond=[3,0],truncate=None)# bck, kda\n",
    "# rd_lu_d,rd_rd_d = apply_SVD( down_edge[1::2],left_bond=[0,1],right_bond=[2,3],truncate=None)# abk, kcd\n",
    "# ld_ld_d,ld_ru_d = apply_SVD( down_edge[0::2],left_bond=[1,2],right_bond=[3,0],truncate=None)# bck, kda\n",
    "# rd_lu_c,rd_rd_c = apply_SVD(corn_tensor     ,left_bond=[0,1],right_bond=[2,3],truncate=None)# bck, kda\n",
    "\n",
    "# rd_lu_r_should=rd_lu_origin[-1,:-1];rd_rd_r_should=rd_rd_origin[-1,:-1]\n",
    "# ru_ld_r_should=ru_ld_origin[-1,:]  ;ru_ru_r_should=ru_ru_origin[-1,:]\n",
    "# rd_lu_d_should=rd_lu_origin[:-1,-1];rd_rd_d_should=rd_rd_origin[:-1,-1]\n",
    "# ld_ld_d_should=ld_ld_origin[:,-1]  ;ld_ru_d_should=ld_ru_origin[:,-1]\n",
    "# rd_lu_c_should=rd_lu_origin[ -1,-1];rd_rd_c_should=rd_rd_origin[ -1,-1]\n",
    "\n",
    "# print(rd_lu_r_should.shape)\n",
    "# print(ru_ld_r_should.shape)\n",
    "# print(rd_lu_d_should.shape)\n",
    "# print(ld_ld_d_should.shape)\n",
    "# print(rd_lu_c_should.shape)\n",
    "\n",
    "# print(torch.dist(rd_lu_r_should,rd_lu_r),torch.dist(rd_rd_r_should,rd_rd_r))\n",
    "# print(torch.dist(ru_ld_r_should,ru_ld_r),torch.dist(ru_ru_r_should,ru_ru_r))\n",
    "# print(torch.dist(rd_lu_d_should,rd_lu_d),torch.dist(rd_rd_d_should,rd_rd_d))\n",
    "# print(torch.dist(ld_ld_d_should,ld_ld_d),torch.dist(ld_ru_d_should,ld_ru_d))\n",
    "# print(torch.dist(rd_lu_c_should,rd_lu_c),torch.dist(rd_rd_c_should,rd_rd_c))\n",
    "\n",
    "# tensor1     = torch.einsum(\"whicd,whjac,whbak,whdbl->whijkl\",\n",
    "#                                     lu_rd_origin,\n",
    "#                                     ld_ru_origin,\n",
    "#                                     rd_lu_origin,\n",
    "#                                     ru_ld_origin)\n",
    "# tensor2     = torch.einsum(\"whicd,whjac,whbak,whdbl->whijkl\",\n",
    "#                            rd_rd_origin,\n",
    "#                            ru_ru_origin.roll(shifts=-1,dims=1),\n",
    "#                            lu_lu_origin.roll(shifts=(-1, -1), dims=(0, 1)),\n",
    "#                            ld_ld_origin.roll(shifts=-1,dims=0))\n",
    "\n",
    "# bulk_tensor1_should= tensor1[:-1,:-1]\n",
    "# rigt_tensor1_should= tensor1[-1,:-1]\n",
    "# down_tensor1_should= tensor1[:-1,-1]\n",
    "# corn_tensor1_should= tensor1[-1,-1]\n",
    "# bulk_tensor2_should= tensor2[:-1,:-1]\n",
    "# rigt_tensor2_should= tensor2[-1,:-1]\n",
    "# down_tensor2_should= tensor2[:-1,-1]\n",
    "# corn_tensor2_should= tensor2[-1,-1]\n",
    "\n",
    "# print(bulk_tensor1_should.shape)\n",
    "# print(rigt_tensor1_should.shape)  \n",
    "# print(down_tensor1_should.shape)  \n",
    "# print(corn_tensor1_should.shape)  \n",
    "# print(bulk_tensor2_should.shape)  \n",
    "# print(rigt_tensor2_should.shape)  \n",
    "# print(down_tensor2_should.shape)  \n",
    "# print(corn_tensor2_should.shape)  \n",
    "\n",
    "# bulk_tensor1 = torch.einsum(\"whicd,whjac,whbak,whdbl->whijkl\",lu_rd[:-1,:-1],ld_ru[:-1],rd_lu,ru_ld[:,:-1])\n",
    "# rigt_tensor1 = torch.einsum(\"wicd,wjac,wbak,wdbl->wijkl\",lu_rd[-1,:-1],ld_ru[-1]   ,rd_lu_r, ru_ld_r[:-1])\n",
    "# down_tensor1 = torch.einsum(\"wicd,wjac,wbak,wdbl->wijkl\",lu_rd[:-1,-1],ld_ru_d[:-1],rd_lu_d, ru_ld[:,-1])\n",
    "# corn_tensor1 = torch.einsum(\" icd, jac, bak, dbl-> ijkl\",lu_rd[-1,-1] ,ld_ru_d[-1] ,rd_lu_c, ru_ld_r[-1])\n",
    "# bulk_tensor2 = torch.einsum(\"whicd,whjac,whbak,whdbl->whijkl\",rd_rd,ru_ru[:,1:],lu_lu[1:,1:],ld_ld[1:])\n",
    "# rigt_tensor2 = torch.einsum(\"wicd,wjac,wbak,wdbl->wijkl\",rd_rd_r, ru_ru_r[1:],lu_lu[0,1:], ld_ld[0])\n",
    "# down_tensor2 = torch.einsum(\"wicd,wjac,wbak,wdbl->wijkl\",rd_rd_d, ru_ru[:,0],lu_lu[1:,0], ld_ld_d[1:])\n",
    "# corn_tensor2 = torch.einsum(\" icd, jac, bak, dbl-> ijkl\",rd_rd_c, ru_ru_r[0],lu_lu[0,0] , ld_ld_d[0])\n",
    "\n",
    "# print(bulk_tensor1.shape)\n",
    "# print(rigt_tensor1.shape)  \n",
    "# print(down_tensor1.shape)  \n",
    "# print(corn_tensor1.shape)  \n",
    "# print(bulk_tensor2.shape)  \n",
    "# print(rigt_tensor2.shape)  \n",
    "# print(down_tensor2.shape)  \n",
    "# print(corn_tensor2.shape)  \n",
    "\n",
    "# print(torch.dist(bulk_tensor1,bulk_tensor1_should))\n",
    "# print(torch.dist(rigt_tensor1,rigt_tensor1_should))  \n",
    "# print(torch.dist(down_tensor1,down_tensor1_should))  \n",
    "# print(torch.dist(corn_tensor1,corn_tensor1_should))  \n",
    "# print(torch.dist(bulk_tensor2,bulk_tensor2_should))  \n",
    "# print(torch.dist(rigt_tensor2,rigt_tensor2_should))  \n",
    "# print(torch.dist(down_tensor2,down_tensor2_should))  \n",
    "# print(torch.dist(corn_tensor2,corn_tensor2_should)) \n",
    "\n",
    "# computer_vie_tn(tensor)\n",
    "\n",
    "# truncate = None\n",
    "# bulk_left ,bulk_right= apply_SVD(bulk_tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)\n",
    "# rigt_left ,rigt_right= apply_SVD(rigt_tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)\n",
    "# down_left ,down_right= apply_SVD(down_tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)\n",
    "# corn_left ,corn_right= apply_SVD(corn_tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)\n",
    "# bulk_lower,bulk_uppe = apply_SVD(bulk_tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "# rigt_lower,rigt_uppe = apply_SVD(rigt_tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "# down_lower,down_uppe = apply_SVD(down_tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "# corn_lower,corn_uppe = apply_SVD(corn_tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "\n",
    "# bulk_tensor           = torch.einsum(\"whadi,whjba,whkcb,whdcl->whijkl\", bulk_lower[:-1,:-1],bulk_right[:-1,1:],bulk_uppe[:-1,1:],bulk_left[1:,1:])\n",
    "# rigt_bulk_tensor      = torch.einsum(\"hadi,hjba,hkcb,hdcl->hijkl\"     , rigt_lower[:-1]    ,rigt_right[1:]    ,rigt_uppe[1:]    ,bulk_left[0,1:])\n",
    "# down_bulk_tensor      = torch.einsum(\"hadi,hjba,hkcb,hdcl->hijkl\"     , down_lower[:-1]    ,bulk_right[:-1,0] ,bulk_uppe[:-1,0] ,bulk_left[1:,0])\n",
    "# bulk_rigt_tensor      = torch.einsum(\"hadi,hjba,hkcb,hdcl->hijkl\"     , bulk_lower[-1,:-1] ,bulk_right[-1,1:] ,bulk_uppe[-1,1:] ,rigt_left[1:])\n",
    "# bulk_down_tensor      = torch.einsum(\"hadi,hjba,hkcb,hdcl->hijkl\"     , bulk_lower[:-1,-1] ,down_right[:-1]   ,down_uppe[:-1]   ,down_left[1:])\n",
    "# bulk_down_corn_tensor = torch.einsum(\"adi,jba,kcb,dcl->ijkl\"          , bulk_lower[-1,-1]  ,down_right[-1]    ,down_uppe[-1]    ,corn_left)\n",
    "# corn_right_bulk_tensor= torch.einsum(\"adi,jba,kcb,dcl->ijkl\"          , corn_lower         ,rigt_right[0]     ,rigt_uppe[0]     ,bulk_left[0,0])\n",
    "# right_corn_down_tensor= torch.einsum(\"adi,jba,kcb,dcl->ijkl\"          , rigt_lower[-1]     ,corn_right        ,corn_uppe        ,down_left[0])\n",
    "# down_bulk_right_tensor= torch.einsum(\"adi,jba,kcb,dcl->ijkl\"          , down_lower[-1]     ,bulk_right[-1,0]  ,bulk_uppe[-1,0]  ,rigt_left[0])\n",
    "\n",
    "# left,right  = apply_SVD(tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)# ABK,KCD\n",
    "# lower,uppe  = apply_SVD(tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "# new_tensor_should  = torch.einsum(\"whadi,whjba,whkcb,whdcl->whijkl\",\n",
    "#                    lower,\n",
    "#                    right.roll(-1,1),\n",
    "#                    uppe.roll(-1,1),\n",
    "#                    left.roll(shifts=(-1, -1), dims=(0, 1))\n",
    "#                    )\n",
    "\n",
    "# print(bulk_tensor.shape)           \n",
    "# print(rigt_bulk_tensor.shape)      \n",
    "# print(down_bulk_tensor.shape)      \n",
    "# print(bulk_rigt_tensor.shape)      \n",
    "# print(bulk_down_tensor.shape)      \n",
    "# print(bulk_down_corn_tensor.shape) \n",
    "# print(corn_right_bulk_tensor.shape)\n",
    "# print(right_corn_down_tensor.shape)\n",
    "# print(down_bulk_right_tensor.shape)\n",
    "\n",
    "# bulk_tensor_should            = new_tensor_should[:-2, :-2]\n",
    "# rigt_bulk_tensor_should       = new_tensor_should[-1,:-2]\n",
    "# down_bulk_tensor_should       = new_tensor_should[:-2,-1]\n",
    "# bulk_rigt_tensor_should       = new_tensor_should[-2,:-2]\n",
    "# bulk_down_tensor_should       = new_tensor_should[:-2,-2]\n",
    "# bulk_down_corn_tensor_should  = new_tensor_should[-2,-2]\n",
    "# corn_right_bulk_tensor_should = new_tensor_should[-1,-1]\n",
    "# right_corn_down_tensor_should = new_tensor_should[-1,-2]\n",
    "# down_bulk_right_tensor_should = new_tensor_should[-2,-1]\n",
    "\n",
    "# print(bulk_tensor_should.shape           )\n",
    "# print(rigt_bulk_tensor_should.shape      )\n",
    "# print(down_bulk_tensor_should.shape      )\n",
    "# print(bulk_rigt_tensor_should.shape      )\n",
    "# print(bulk_down_tensor_should.shape      )\n",
    "# print(bulk_down_corn_tensor_should.shape )\n",
    "# print(corn_right_bulk_tensor_should.shape)\n",
    "# print(right_corn_down_tensor_should.shape)\n",
    "# print(down_bulk_right_tensor_should.shape)\n",
    "\n",
    "# print(torch.dist(bulk_tensor_should            ,bulk_tensor           ))\n",
    "# print(torch.dist(rigt_bulk_tensor_should       ,rigt_bulk_tensor      ))\n",
    "# print(torch.dist(down_bulk_tensor_should       ,down_bulk_tensor      ))\n",
    "# print(torch.dist(bulk_rigt_tensor_should       ,bulk_rigt_tensor      ))\n",
    "# print(torch.dist(bulk_down_tensor_should       ,bulk_down_tensor      ))\n",
    "# print(torch.dist(bulk_down_corn_tensor_should  ,bulk_down_corn_tensor ))\n",
    "# print(torch.dist(corn_right_bulk_tensor_should ,corn_right_bulk_tensor))\n",
    "# print(torch.dist(right_corn_down_tensor_should ,right_corn_down_tensor))\n",
    "# print(torch.dist(down_bulk_right_tensor_should ,down_bulk_right_tensor))\n",
    "\n",
    "# new_tensor = torch.cat(\n",
    "#     [torch.cat([bulk_tensor,bulk_rigt_tensor.unsqueeze(0),rigt_bulk_tensor.unsqueeze(0)]),\n",
    "#      torch.cat([bulk_down_tensor,bulk_down_corn_tensor.unsqueeze(0),right_corn_down_tensor.unsqueeze(0)]).unsqueeze(1),\n",
    "#      torch.cat([down_bulk_tensor,down_bulk_right_tensor.unsqueeze(0),corn_right_bulk_tensor.unsqueeze(0)]).unsqueeze(1),\n",
    "#     ],dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### odd number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #%%writefile Contractor2D/test_for_TRG_odd_number.py\n",
    "# import torch\n",
    "\n",
    "# from Contractor2D.utils import apply_SVD\n",
    "\n",
    "# tensor = torch.randn(5,5,2,2,2,2)\n",
    "# print(f\"the input tensor network store in {tensor.shape}\")\n",
    "# print(f\"the ultimate result should be {uniform_shape_tensor_contractor_tn(tensor)}\")\n",
    "\n",
    "\n",
    "# right_edge1,right_edge2 = tensor[-2:]\n",
    "# right_edge = torch.einsum(\"wabcd,wedfg->waebcfg\",right_edge1,right_edge2).flatten(1,2).flatten(-3,-2)\n",
    "# down_edge1, down_edge2 = tensor[:-2,-2:].transpose(1,0)\n",
    "# corn_tensor1,corn_tensor2= right_edge[-2:]\n",
    "# bulk_tensor= tensor[:-2,:-2]\n",
    "# right_edge = right_edge[:-2]\n",
    "# down_edge  = torch.einsum(\"wabcd,wcefg->wabefdg\",down_edge1,down_edge2).flatten(2,3).flatten(-2,-1)\n",
    "# corn_tensor= torch.einsum(\"abcd,cefg->abefdg\",corn_tensor1,corn_tensor2).flatten(1,2).flatten(-2,-1)\n",
    "\n",
    "# print(f\"the input bulk_right_left_corner tensor :\")\n",
    "# print(f\"bulk_tensor.shape = {bulk_tensor.shape}\")\n",
    "# print(f\"right_edge.shape  = {right_edge.shape }\")\n",
    "# print(f\"down_edge.shape   = {down_edge.shape  }\")\n",
    "# print(f\"corn_tensor.shape = {corn_tensor.shape}\")\n",
    "\n",
    "# print(f\"the bulk_right_left_corner_contractor result {bulk_right_left_corner_contractor_tn(bulk_tensor,right_edge,down_edge,corn_tensor)}\")\n",
    "\n",
    "# lu_lu,lu_rd = apply_SVD(bulk_tensor[0::2,0::2],left_bond=[0,1],right_bond=[2,3],truncate=None)# abk ,kcd\n",
    "# rd_lu,rd_rd = apply_SVD(bulk_tensor[1::2,1::2],left_bond=[0,1],right_bond=[2,3],truncate=None)# abk, kcd\n",
    "# ld_ld,ld_ru = apply_SVD(bulk_tensor[0::2,1::2],left_bond=[1,2],right_bond=[3,0],truncate=None)# bck, kda\n",
    "# ru_ld,ru_ru = apply_SVD(bulk_tensor[1::2,0::2],left_bond=[1,2],right_bond=[3,0],truncate=None)# bck, kda\n",
    "\n",
    "# rd_lu_r,rd_rd_r = apply_SVD(right_edge[1::2],left_bond=[0,1],right_bond=[2,3],truncate=None)# abk, kcd\n",
    "# ru_ld_r,ru_ru_r = apply_SVD(right_edge[0::2],left_bond=[1,2],right_bond=[3,0],truncate=None)# bck, kda\n",
    "# rd_lu_d,rd_rd_d = apply_SVD( down_edge[1::2],left_bond=[0,1],right_bond=[2,3],truncate=None)# abk, kcd\n",
    "# ld_ld_d,ld_ru_d = apply_SVD( down_edge[0::2],left_bond=[1,2],right_bond=[3,0],truncate=None)# bck, kda\n",
    "# rd_lu_c,rd_rd_c = apply_SVD(corn_tensor     ,left_bond=[0,1],right_bond=[2,3],truncate=None)# bck, kda\n",
    "\n",
    "# bulk_tensor1 = torch.einsum(\"whicd,whjac,whbak,whdbl->whijkl\",lu_rd[:-1,:-1],ld_ru[:-1],rd_lu,ru_ld[:,:-1])\n",
    "# rigt_tensor1 = torch.einsum(\"wicd,wjac,wbak,wdbl->wijkl\",lu_rd[-1,:-1],ld_ru[-1]   ,rd_lu_r, ru_ld_r[:-1])\n",
    "# down_tensor1 = torch.einsum(\"wicd,wjac,wbak,wdbl->wijkl\",lu_rd[:-1,-1],ld_ru_d[:-1],rd_lu_d, ru_ld[:,-1])\n",
    "# corn_tensor1 = torch.einsum(\" icd, jac, bak, dbl-> ijkl\",lu_rd[-1,-1] ,ld_ru_d[-1] ,rd_lu_c, ru_ld_r[-1])\n",
    "# bulk_tensor2 = torch.einsum(\"whicd,whjac,whbak,whdbl->whijkl\",rd_rd,ru_ru[:,1:],lu_lu[1:,1:],ld_ld[1:])\n",
    "# rigt_tensor2 = torch.einsum(\"wicd,wjac,wbak,wdbl->wijkl\",rd_rd_r, ru_ru_r[1:],lu_lu[0,1:], ld_ld[0])\n",
    "# down_tensor2 = torch.einsum(\"wicd,wjac,wbak,wdbl->wijkl\",rd_rd_d, ru_ru[:,0],lu_lu[1:,0], ld_ld_d[1:])\n",
    "# corn_tensor2 = torch.einsum(\" icd, jac, bak, dbl-> ijkl\",rd_rd_c, ru_ru_r[0],lu_lu[0,0] , ld_ld_d[0])\n",
    "\n",
    "# print(\"phase1:result\")\n",
    "# print(f\"bulk_tensor1.shape={bulk_tensor1.shape}\")\n",
    "# print(f\"rigt_tensor1.shape={rigt_tensor1.shape}\")\n",
    "# print(f\"down_tensor1.shape={down_tensor1.shape}\")\n",
    "# print(f\"corn_tensor1.shape={corn_tensor1.shape}\")\n",
    "# print()\n",
    "# print(f\"bulk_tensor2.shape={bulk_tensor2.shape}\")\n",
    "# print(f\"rigt_tensor2.shape={rigt_tensor2.shape}\")\n",
    "# print(f\"down_tensor2.shape={down_tensor2.shape}\")\n",
    "# print(f\"corn_tensor2.shape={corn_tensor2.shape}\")\n",
    "\n",
    "# # if we don't truncate at this step, the map will become too complex and can not code as unique way,\n",
    "# # so in such case, we will require truncate 16 in here and the recommend input not big than 32.\n",
    "# truncate = None\n",
    "# bulk_left ,bulk_right= apply_SVD(bulk_tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)\n",
    "# rigt_left ,rigt_right= apply_SVD(rigt_tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)\n",
    "# down_left ,down_right= apply_SVD(down_tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)\n",
    "# corn_left ,corn_right= apply_SVD(corn_tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)\n",
    "# bulk_lower,bulk_uppe = apply_SVD(bulk_tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "# rigt_lower,rigt_uppe = apply_SVD(rigt_tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "# down_lower,down_uppe = apply_SVD(down_tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "# corn_lower,corn_uppe = apply_SVD(corn_tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "\n",
    "# bulk_tensor_cent      = torch.einsum(\"whadi,whjba,whkcb,whdcl->whijkl\", bulk_lower[:-1,:-1],bulk_right[:-1,1:],bulk_uppe[:-1,1:],bulk_left[1:,1:])\n",
    "# rigt_bulk_tensor      = torch.einsum(\"hadi,hjba,hkcb,hdcl->hijkl\"     , rigt_lower[:-1]    ,rigt_right[1:]    ,rigt_uppe[1:]    ,bulk_left[0,1:])\n",
    "# down_bulk_tensor      = torch.einsum(\"hadi,hjba,hkcb,hdcl->hijkl\"     , down_lower[:-1]    ,bulk_right[:-1,0] ,bulk_uppe[:-1,0] ,bulk_left[1:,0])\n",
    "# bulk_rigt_tensor      = torch.einsum(\"hadi,hjba,hkcb,hdcl->hijkl\"     , bulk_lower[-1,:-1] ,bulk_right[-1,1:] ,bulk_uppe[-1,1:] ,rigt_left[1:])\n",
    "# bulk_down_tensor      = torch.einsum(\"hadi,hjba,hkcb,hdcl->hijkl\"     , bulk_lower[:-1,-1] ,down_right[:-1]   ,down_uppe[:-1]   ,down_left[1:])\n",
    "# bulk_down_corn_tensor = torch.einsum(\"adi,jba,kcb,dcl->ijkl\"          , bulk_lower[-1,-1]  ,down_right[-1]    ,down_uppe[-1]    ,corn_left)\n",
    "# corn_right_bulk_tensor= torch.einsum(\"adi,jba,kcb,dcl->ijkl\"          , corn_lower         ,rigt_right[0]     ,rigt_uppe[0]     ,bulk_left[0,0])\n",
    "# right_corn_down_tensor= torch.einsum(\"adi,jba,kcb,dcl->ijkl\"          , rigt_lower[-1]     ,corn_right        ,corn_uppe        ,down_left[0])\n",
    "# down_bulk_right_tensor= torch.einsum(\"adi,jba,kcb,dcl->ijkl\"          , down_lower[-1]     ,bulk_right[-1,0]  ,bulk_uppe[-1,0]  ,rigt_left[0])\n",
    "# # down_bulk_tensor       = down_bulk_tensor[None]\n",
    "# # down_bulk_right_tensor = down_bulk_right_tensor[None]\n",
    "# # corn_right_bulk_tensor = corn_right_bulk_tensor[None]\n",
    "# # bulk_down_corn_tensor  = bulk_down_corn_tensor[None]\n",
    "\n",
    "# print(\"phase2 result:\")\n",
    "# print(f\"bulk_tensor_cent.shape      ={bulk_tensor_cent.shape      }\")\n",
    "# print(f\"down_bulk_tensor.shape      ={down_bulk_tensor.shape      }\")      \n",
    "# print(f\"bulk_rigt_tensor.shape      ={bulk_rigt_tensor.shape      }\")   \n",
    "# print(f\"down_bulk_right_tensor.shape={down_bulk_right_tensor.shape}\")\n",
    "# print(f\"rigt_bulk_tensor.shape      ={rigt_bulk_tensor.shape      }\")      \n",
    "# print(f\"corn_right_bulk_tensor.shape={corn_right_bulk_tensor.shape}\")\n",
    "# print(f\"bulk_down_tensor.shape      ={bulk_down_tensor.shape      }\") \n",
    "# print(f\"bulk_down_corn_tensor.shape ={bulk_down_corn_tensor.shape }\") \n",
    "# print(f\"right_corn_down_tensor.shape={right_corn_down_tensor.shape}\")\n",
    "\n",
    "# bulk_tensor = torch.cat([\n",
    "#     torch.cat([bulk_tensor_cent,down_bulk_tensor[None]],1),\n",
    "#     torch.cat([bulk_rigt_tensor,down_bulk_right_tensor[None]])[None]\n",
    "# ])\n",
    "\n",
    "# bulk_tensor.shape\n",
    "\n",
    "# bulk_tensor = down_bulk_right_tensor[None][None]\n",
    "\n",
    "# right_edge = torch.cat([rigt_bulk_tensor,corn_right_bulk_tensor[None]])\n",
    "# down_edge  = torch.cat([bulk_down_tensor,bulk_down_corn_tensor[None]])\n",
    "# corn_tensor =right_corn_down_tensor\n",
    "\n",
    "# print(f\"next tensor shape:\")\n",
    "# print(f\"bulk_tensor.shape = {bulk_tensor.shape}\")\n",
    "# print(f\"right_edge.shape  = {right_edge.shape }\")\n",
    "# print(f\"down_edge.shape   = {down_edge.shape  }\")\n",
    "# print(f\"corn_tensor.shape = {corn_tensor.shape}\")\n",
    "\n",
    "# print(f\"next tensor contraction result:\")\n",
    "# print(bulk_right_left_corner_contractor_tn(bulk_tensor,right_edge,down_edge,corn_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### time test for different engine (only bulk $2^n$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import torch_semiring_einsum\n",
    "# def TRT_semiring(tensor,truncate=None, block_size=5):\n",
    "#     W,H = tensor.shape[:2]\n",
    "#     einsum_1 = torch_semiring_einsum.compile_equation(\"whicd,whjac,whbak,whdbl->whijkl\")\n",
    "#     einsum_2 = torch_semiring_einsum.compile_equation(\"whadi,whjba,whkcb,whdcl->whijkl\")\n",
    "#     einsum_3 = torch_semiring_einsum.compile_equation(\"abcd,ciaj,ldkb,kjli->\")\n",
    "#     while True:\n",
    "#         print(tensor.shape)\n",
    "#         W,H = tensor.shape[:2]\n",
    "#         #if W<=1 or H<=1:break\n",
    "#         lu_tensor = tensor[0::2,0::2]\n",
    "#         ld_tensor = tensor[0::2,1::2]\n",
    "#         ru_tensor = tensor[1::2,0::2]\n",
    "#         rd_tensor = tensor[1::2,1::2]\n",
    "#         if W<=2 or H<=2:break\n",
    "            \n",
    "#         lu_lu,lu_rd = apply_SVD(lu_tensor,left_bond=[0,1],right_bond=[2,3],truncate=truncate)# abk ,kcd\n",
    "#         rd_lu,rd_rd = apply_SVD(rd_tensor,left_bond=[0,1],right_bond=[2,3],truncate=truncate)# abk, kcd\n",
    "#         ld_ld,ld_ru = apply_SVD(ld_tensor,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# bck, kda\n",
    "#         ru_ld,ru_ru = apply_SVD(ru_tensor,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# bck, kda\n",
    "#         tensor1     = torch_semiring_einsum.einsum(einsum_1,\n",
    "#                                     lu_rd,\n",
    "#                                     ld_ru,\n",
    "#                                     rd_lu,\n",
    "#                                     ru_ld,block_size=block_size)\n",
    "#         tensor2     = torch_semiring_einsum.einsum(einsum_1,\n",
    "#                                    rd_rd,\n",
    "#                                    ru_ru.roll(shifts=-1,dims=1),\n",
    "#                                    lu_lu.roll(shifts=(-1, -1), dims=(0, 1)),\n",
    "#                                    ld_ld.roll(shifts=-1,dims=0),block_size=block_size)\n",
    "#         left,right  = apply_SVD(tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)# ABK,KCD\n",
    "#         lower,uppe  = apply_SVD(tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "#         tensor  = torch_semiring_einsum.einsum(einsum_2,\n",
    "#                            lower,\n",
    "#                            right.roll(-1,1),\n",
    "#                            uppe.roll(-1,1),\n",
    "#                            left.roll(shifts=(-1, -1), dims=(0, 1)),block_size=block_size\n",
    "#                            )\n",
    "#     value   = torch_semiring_einsum.einsum(einsum_3,\n",
    "#                            lu_tensor[0,0],ld_tensor[0,0],\n",
    "#                            ru_tensor[0,0],rd_tensor[0,0],block_size=block_size)\n",
    "#     #value = torch.einsum(\"abab->\",tensor[0,0])\n",
    "#     return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tensor = torch.randn(14,14,2,2,2,2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def TRT(tensor,truncate=None,einsum_engin=torch.einsum):\n",
    "    W,H = tensor.shape[:2]\n",
    "    while True:\n",
    "        print(tensor.shape)\n",
    "        W,H = tensor.shape[:2]\n",
    "        #if W<=1 or H<=1:break\n",
    "        lu_tensor = tensor[0::2,0::2]\n",
    "        ld_tensor = tensor[0::2,1::2]\n",
    "        ru_tensor = tensor[1::2,0::2]\n",
    "        rd_tensor = tensor[1::2,1::2]\n",
    "        if W<=2 or H<=2:break\n",
    "#         print(\"SVD:time\"),\n",
    "#         start_time  = time.time()\n",
    "        lu_lu,lu_rd = apply_SVD(lu_tensor,left_bond=[0,1],right_bond=[2,3],truncate=truncate)# abk ,kcd\n",
    "        rd_lu,rd_rd = apply_SVD(rd_tensor,left_bond=[0,1],right_bond=[2,3],truncate=truncate)# abk, kcd\n",
    "        ld_ld,ld_ru = apply_SVD(ld_tensor,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# bck, kda\n",
    "        ru_ld,ru_ru = apply_SVD(ru_tensor,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# bck, kda\n",
    "#         cost = time.time() - start_time\n",
    "#         print(cost)       \n",
    "#         print(\"einsum:time\"),\n",
    "#         start_time  = time.time()\n",
    "        tensor1     = einsum_engin(\"whicd,whjac,whbak,whdbl->whijkl\",\n",
    "                                    lu_rd,\n",
    "                                    ld_ru,\n",
    "                                    rd_lu,\n",
    "                                    ru_ld)\n",
    "        tensor2     = einsum_engin(\"whicd,whjac,whbak,whdbl->whijkl\",\n",
    "                                   rd_rd,\n",
    "                                   ru_ru.roll(shifts=-1,dims=1),\n",
    "                                   lu_lu.roll(shifts=(-1, -1), dims=(0, 1)),\n",
    "                                   ld_ld.roll(shifts=-1,dims=0))\n",
    "#         cost = time.time() - start_time\n",
    "#         print(cost)\n",
    "#         print(\"SVD:time\"),\n",
    "#         start_time  = time.time()\n",
    "        \n",
    "        left,right  = apply_SVD(tensor1,left_bond=[0,1],right_bond=[2,3],truncate=truncate)# ABK,KCD\n",
    "        lower,uppe  = apply_SVD(tensor2,left_bond=[1,2],right_bond=[3,0],truncate=truncate)# BCK,KDA\n",
    "#         cost = time.time() - start_time\n",
    "#         print(cost)\n",
    "#         print(\"einsum:time\"),\n",
    "#         start_time  = time.time()\n",
    "        tensor  = einsum_engin(\"whadi,whjba,whkcb,whdcl->whijkl\",\n",
    "                           lower,\n",
    "                           right.roll(-1,1),\n",
    "                           uppe.roll(-1,1),\n",
    "                           left.roll(shifts=(-1, -1), dims=(0, 1))\n",
    "                           )\n",
    "#         cost = time.time() - start_time\n",
    "#         print(cost)\n",
    "    value   = einsum_engin(\"abcd,ciaj,ldkb,kjli->\",lu_tensor[0,0],ld_tensor[0,0],ru_tensor[0,0],rd_tensor[0,0])\n",
    "    #value = torch.einsum(\"abab->\",tensor[0,0])\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tensor = torch.randn(14,14,2,2,2,2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "engine=lambda equ,*karg:torch_semiring_einsum.einsum(torch_semiring_einsum.compile_equation(equ),*karg,block_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.49 ms ± 10 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn(4,4,2,2,2,2)\n",
    "%timeit TRT(tensor,truncate=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.67 ms ± 1.43 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit TRT(tensor,truncate=None,einsum_engin=contract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Boundary MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from utils import *\n",
    "\n",
    "\n",
    "def rd_engine(*x,**kargs):\n",
    "    x =  torch.randn(*x,device='cpu',**kargs)\n",
    "    x/=  torch.norm(x).sqrt()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D=4;P=4;L=7;\n",
    "# top_mps_list    = [rd_engine(P,D)] + [rd_engine(L-2,D,P,D)]  + [rd_engine(D,P)]\n",
    "# middle_mpo_list = [[rd_engine(P,D,P)]+[rd_engine(L-2,D,P,D,P)]+ [rd_engine(D,P,P)]\n",
    "#                   for _ in range(L-2)]\n",
    "# bottom_mps_list = [rd_engine(P,D)] + [rd_engine(L-2,D,P,D)]  + [rd_engine(D,P)]\n",
    "# peps  = [top_mps_list]+middle_mpo_list+[bottom_mps_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D=4;P=4;L=7;\n",
    "top_mps_list    = [rd_engine(D,D)]     + [rd_engine(L-2,D,D,D)]  + [rd_engine(D,D)]\n",
    "middle_mpo_list = [[rd_engine(D,D,D)]  + [rd_engine(L-2,D,D,D,D)]+ [rd_engine(D,D,D)]\n",
    "                  for _ in range(L-2)]\n",
    "bottom_mps_list = [rd_engine(D,D)]     + [rd_engine(L-2,D,D,D)]  + [rd_engine(D,D)]\n",
    "peps  = [top_mps_list]+middle_mpo_list+[bottom_mps_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     3,
     64,
     94,
     127,
     131,
     159
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from engine.torch_dense import approxmate_mps_line\n",
    "import torch\n",
    "import numpy as np\n",
    "def truncated_SVD(tensor,output='RQ',max_singular_values= None,\n",
    "                  max_truncation_error= None,\n",
    "                  relative = True,\n",
    "                  normlized= True,\n",
    "                  verbose  = False,auto_check_diagonal=False):\n",
    "    # the canonocal\n",
    "    # tensor is batched\n",
    "    reduce = False\n",
    "    u=s=v = None\n",
    "    if len(tensor.shape)==2:\n",
    "        tensor = tensor.unsqueeze(0)\n",
    "        reduce = True\n",
    "    if auto_check_diagonal:\n",
    "        out = diagonal_tensor_svd_torch_dense(tensor)\n",
    "        if out is not None:u, s, v = out\n",
    "    if u is None: u, s, v = torch.svd(tensor)\n",
    "\n",
    "\n",
    "    max_singular_values = s.shape[-1] if max_singular_values is None else max_singular_values\n",
    "\n",
    "    if max_truncation_error is not None:\n",
    "        # Cumulative norms of singular values in ascending order\n",
    "        s_sorted, _ = torch.sort(s**2,-1)\n",
    "        trunc_errs  = torch.sqrt(torch.cumsum(s_sorted, -1))\n",
    "        # If relative is true, rescale max_truncation error with the largest\n",
    "        # singular value to yield the absolute maximal truncation error.\n",
    "        abs_max_truncation_error = max_truncation_error * s[:,0:1] if relative else max_truncation_error\n",
    "        # We must keep at least this many singular values to ensure the\n",
    "        # truncation error is <= abs_max_truncation_error.\n",
    "        num_sing_vals_err = torch.sum(trunc_errs > abs_max_truncation_error,-1).max()\n",
    "        if max_singular_values>num_sing_vals_err and verbose:\n",
    "            print(f\"use {num_sing_vals_err}/{max_singular_values} sing vals\")\n",
    "    else:\n",
    "        num_sing_vals_err  = max_singular_values\n",
    "\n",
    "    num_sing_vals_keep = min(max_singular_values, num_sing_vals_err)\n",
    "\n",
    "\n",
    "    #s_rest = s[...,num_sing_vals_keep:]\n",
    "    u      = u[...,:num_sing_vals_keep]\n",
    "    s      = s[...,:num_sing_vals_keep]\n",
    "    v      = v[...,:num_sing_vals_keep]\n",
    "    v      = torch.transpose(v, -1, -2)#vh\n",
    "\n",
    "    if num_sing_vals_keep == s.shape[-1] and normlized:\n",
    "        Z = 1.0*torch.ones(s.shape[0])\n",
    "    else:\n",
    "        Z = torch.sum(s**2,-1).sqrt()\n",
    "\n",
    "    if output == 'RQ':\n",
    "        R = torch.einsum('iab,ibc->iac',u ,torch.diag_embed(s))\n",
    "        Q = v\n",
    "        output = [R,Q,Z]\n",
    "    elif output == 'QR':\n",
    "        Q = u\n",
    "        R = torch.einsum('iab,ibc->iac',torch.diag_embed(s),v)\n",
    "        output = [Q,R,Z]\n",
    "    else:\n",
    "        output = [u,s,v,Z]\n",
    "    if reduce:output = [t[0] for t in output]\n",
    "    return output\n",
    "def left_canonicalize_MPS(mps_line,Decomposition_Engine=torch.qr,\n",
    "                          normlization =True):\n",
    "    # for any not canonical mps line\n",
    "    # the chain size (D,P,D)\n",
    "    new_chain = []\n",
    "    R         = None\n",
    "    #Z_list    = []# record the scale information for each unit.\n",
    "    # for a perfect MPS state, we expect the norm for each tensor is 1.\n",
    "    for i,tensor in enumerate(mps_line):\n",
    "        if len(tensor.shape)==2:\n",
    "            new_tensor = torch.einsum('ab,bd->ad',R,tensor) if R is not None else tensor\n",
    "            shape      = new_tensor.shape\n",
    "        elif len(tensor.shape)==3:\n",
    "            new_tensor = torch.einsum('ab,bcd->acd',R,tensor) if R is not None else tensor\n",
    "            shape      = new_tensor.shape\n",
    "            a,b,c = shape\n",
    "            new_tensor = new_tensor.reshape(a*b,c)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        if i == len(mps_line) - 1:\n",
    "            Z = torch.norm(new_tensor)\n",
    "            if normlization:new_tensor /= (Z)\n",
    "            new_chain.append(new_tensor.reshape(*shape[:-1],-1))\n",
    "        else:\n",
    "            Q,R = Decomposition_Engine(new_tensor)[:2]\n",
    "            Q   = Q.reshape(*shape[:-1],-1)\n",
    "            new_chain.append(Q)\n",
    "\n",
    "    return new_chain,[Z]\n",
    "def right_canonicalize_MPS(mps_line,Decomposition_Engine=truncated_SVD,\n",
    "                          #normlization =True\n",
    "                          ):\n",
    "    new_chain = []\n",
    "    R         = None\n",
    "    Z_list    = []\n",
    "    svd_Z         = torch.Tensor([1.0])#input has already been normalized\n",
    "    for i,tensor in enumerate(mps_line[::-1]):\n",
    "\n",
    "        if len(tensor.shape)==2:\n",
    "            new_tensor = torch.einsum('ab,bc->ac',tensor, R) if R is not None else tensor\n",
    "            shape      = new_tensor.shape\n",
    "        elif len(tensor.shape)==3:\n",
    "            new_tensor = torch.einsum('alb,bc->alc',tensor, R) if R is not None else tensor\n",
    "            shape      = new_tensor.shape\n",
    "            a,b,c      = shape\n",
    "            new_tensor = new_tensor.reshape(a,b*c)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        Z = torch.norm(new_tensor)\n",
    "        Z_list.append(Z)\n",
    "        new_tensor /= Z\n",
    "        # normlization is necessary; directly use the SVD_Z may cause problem due to precision\n",
    "        #print(f\"svd_Z{svd_Z.item()}<->all_Z {Z.item()} <-> after_Z{torch.norm(new_tensor).item()}\")\n",
    "        #if normlization:new_tensor /= Z\n",
    "        if i == len(mps_line) - 1:\n",
    "            new_chain.append(new_tensor.reshape(-1,*shape[1:]))\n",
    "        else:\n",
    "            R,Q,svd_Z = Decomposition_Engine(new_tensor)\n",
    "            Q   = Q.reshape(-1,*shape[1:])\n",
    "            new_chain.append(Q)\n",
    "    new_chain=new_chain[::-1]\n",
    "    return new_chain,Z_list\n",
    "def torchrq(tensor):\n",
    "    q, r = torch.qr(torch.transpose(tensor, -2, -1))\n",
    "    r, q = torch.transpose(r, -2, -1), torch.transpose(q, -2, -1)  #M=r*q at this point\n",
    "    return r,qx\n",
    "def approxmate_mps_line(mps_line,\n",
    "                        max_singular_values= None,max_truncation_error= None,relative = True,\n",
    "                        mode='full',left_method='qr'\n",
    "                       ):\n",
    "\n",
    "\n",
    "    scalar = 1\n",
    "    if mode != 'right':\n",
    "        if left_method == 'qr':\n",
    "            DCEngine = torch.linalg.qr if float(torch.__version__[:4])>1.07 else torch.qr\n",
    "        elif left_method == 'svd':\n",
    "            DCEngine = lambda x:truncated_SVD(x,output='QR')\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        mps_line,Z_list = left_canonicalize_MPS(mps_line,Decomposition_Engine=DCEngine)\n",
    "        #print(get_mps_size_list(mps_line))\n",
    "        print(f\"   left canonical scalar:{np.prod(Z_list)}\")\n",
    "        scalar *= np.prod(Z_list)\n",
    "        #print(f\"now tensor norm: {torch.norm(mps_line[-1])}\")\n",
    "    SVD_Engine = lambda x:truncated_SVD(x,max_singular_values = max_singular_values,\n",
    "                                          max_truncation_error= max_truncation_error,\n",
    "                                          relative = relative)\n",
    "    mps_line,Z_list = right_canonicalize_MPS(mps_line,Decomposition_Engine=SVD_Engine)\n",
    "    #print(get_mps_size_list(mps_line))\n",
    "    #print(f\"   right canonical Z:{[np.round(t.item(),3) for t in Z_list]}\")\n",
    "    print(f\"   right canonical scalar:{np.prod(Z_list)}\")\n",
    "    scalar *= np.prod(Z_list)\n",
    "    return mps_line,scalar\n",
    "def diagonal_tensor_svd_torch_dense(tensor):\n",
    "    # support batch tensor\n",
    "    reduce = False\n",
    "    if len(tensor.shape)==2:\n",
    "        tensor = tensor.unsqueeze(0)\n",
    "        reduce = True\n",
    "    W,H   = tensor.shape[-2:]\n",
    "    batch_shape= tensor.shape[:-2]\n",
    "    u = s = v = None\n",
    "    if W>=H:\n",
    "        batch_diag = torch.matmul(tensor.transpose(-1,-2),tensor)#auto broadcast, or can use bmm\n",
    "    else:\n",
    "        batch_diag = torch.matmul(tensor,tensor.transpose(-1,-2))#auto broadcast, or can use bmm\n",
    "    diagnol_num = torch.diagonal(a,dim1=-2,dim2=-1).nelement()\n",
    "    tensor_num  = tensor.nelement()\n",
    "    if diagnol_num != tensor_num:return None\n",
    "    A,A        = batch_diag.shape[-2:]\n",
    "    batch_diag = batch_diag[...,range(A),range(A)]\n",
    "    batch_diag,batch_order= batch_diag.sort(-1,descending=True)\n",
    "    #fast_V      = [get_sort_matrix(order).to_dense() for order in batch_order]\n",
    "    batch_order = batch_order.flatten(start_dim=0,end_dim=-2)\n",
    "    K,A         = batch_order.shape\n",
    "    s           = batch_diag.sqrt()\n",
    "    s           = s.reshape(*batch_shape,A)\n",
    "    if W>=H:\n",
    "        v = torch.sparse_coo_tensor([list(range(K*A)),batch_order.flatten().tolist()], [1.0]*K*A,(K*A,A))\n",
    "        v = v.to_dense().reshape(-1,A,A)\n",
    "        u = torch.bmm(tensor,v.transpose(-1,-2)/s.unsqueeze(-2))\n",
    "        v = v.reshape(*batch_shape,A,A)\n",
    "        u = u.reshape(*batch_shape,W,A)\n",
    "    else:\n",
    "        u = torch.sparse_coo_tensor([list(range(K*A)),batch_order.flatten().tolist()], [1.0]*K*A,(K*A,A))\n",
    "        u = u.to_dense().reshape(-1,A,A).transpose(-1,-2)\n",
    "        v = torch.bmm(u.transpose(-1,-2)/s.unsqueeze(-1),tensor)#TODO: case when s==0\n",
    "        u = u.reshape(*batch_shape,A,A)\n",
    "        v = v.reshape(*batch_shape,A,H)\n",
    "    output = [u,s,v.transpose(-1,-2)]\n",
    "    if reduce:\n",
    "        output = [t[0] for t in output]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0+cu102'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   left canonical scalar:0.5324269533157349\n",
      "   right canonical scalar:0.9999996423721313\n",
      "(4, 4)-(4, 4, 16)- 3x(16, 4, 16) -(16, 4, 4)-(4, 4)\n",
      "   left canonical scalar:0.17249836027622223\n",
      "   right canonical scalar:0.9999997615814209\n",
      "(4, 4)-(4, 4, 16)-(16, 4, 64)-(64, 4, 64)-(64, 4, 16)-(16, 4, 4)-(4, 4)\n",
      "   left canonical scalar:0.141238734126091\n",
      "   right canonical scalar:0.9999996423721313\n",
      "(4, 4)-(4, 4, 16)-(16, 4, 64)-(64, 4, 64)-(64, 4, 16)-(16, 4, 4)-(4, 4)\n",
      "   left canonical scalar:0.13460852205753326\n",
      "   right canonical scalar:0.9999997019767761\n",
      "(4, 4)-(4, 4, 16)-(16, 4, 64)-(64, 4, 64)-(64, 4, 16)-(16, 4, 4)-(4, 4)\n",
      "   left canonical scalar:0.1684599667787552\n",
      "   right canonical scalar:1.000000238418579\n",
      "(4, 4)-(4, 4, 16)-(16, 4, 64)-(64, 4, 64)-(64, 4, 16)-(16, 4, 4)-(4, 4)\n"
     ]
    }
   ],
   "source": [
    "tensor = peps[0]\n",
    "for mpo in peps[1:-1]:\n",
    "    tensor = contract_mps_mpo(tensor,mpo)\n",
    "    #print(get_mps_size_list(tensor))\n",
    "    tensor = right_mps_form(tensor)\n",
    "    tensor,scale = approxmate_mps_line(tensor,max_singular_values=100)\n",
    "    print(get_mps_size_list(tensor))\n",
    "tensor = contract_two_mps_tn(tensor,peps[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def onebyoneBMPS(tensor,truncate=None,einsum_engin=torch.einsum):\n",
    "    W,H = tensor.shape[:2]\n",
    "    while W > 1:\n",
    "            half_size = size // 2\n",
    "            nice_size = 2 * half_size\n",
    "            leftover  = tensor[nice_size:]\n",
    "            tensor    = torch.einsum(\"mbik,mbkj->mbij\",tensor[0:nice_size:2], tensor[1:nice_size:2])\n",
    "            #(k/2,NB,D,D),(k/2,NB,D,D) <-> (k/2,NB,D,D)\n",
    "            tensor   = torch.cat([tensor, leftover], axis=0)\n",
    "            size     = half_size + int(size % 2 == 1)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Batch Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from utils import *\n",
    "\n",
    "D=10\n",
    "P=4\n",
    "L=14\n",
    "def rd_engine(*x,**kargs):\n",
    "    x =  torch.randn(*x,device='cpu',**kargs)\n",
    "    x/=  torch.norm(x).sqrt()\n",
    "    return x\n",
    "def generate_test_data(L=10,num=20,k=2):\n",
    "    #images,labels = iter(train_loader).next()\n",
    "    #inputs = preprocess_sum_one(images)\n",
    "    inputs = rd_engine(L,num,k)\n",
    "    inputs = inputs.permute(1,2,0)#(B,num,k)->(num,k,B)\n",
    "    inputs = torch.diag_embed(inputs)#(num,k,B)->(num,k,B,B)\n",
    "    inputs = inputs.permute(0,2,1,3)#(num,k,B,B)->(num,B,k,B)\n",
    "    #inputs= [v for v in inputs]\n",
    "    #inputs[0]= torch.diagonal(inputs[0], dim1=0, dim2=-1)#(B,k,B) -> #(k,B)\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.935704472353725e-15\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(result_should-the_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "mnist_data = np.load('archive/tn-for-unsup-ml/data/binarized_mnist.npz')\n",
    "train_data = torch.from_numpy(mnist_data['train_data'])\n",
    "test_data  = torch.from_numpy(mnist_data['test_data'])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=(0.0,), std=(1.0,))\n",
    "])\n",
    "DATAPATH    = '/media/tianning/DATA/DATASET/MNIST/'\n",
    "mnist_train = datasets.MNIST(DATAPATH, train=True, download=False, transform=transform)\n",
    "mnist_test  = datasets.MNIST(DATAPATH, train=False,download=False, transform=transform)\n",
    "train_loader= torch.utils.data.DataLoader(dataset=mnist_train, batch_size=1000, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test , batch_size=1000, shuffle=False)\n",
    "images,labels = iter(train_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "now_result = np.einsum(\"abc,cd,de,ef,fg,gh,hi,ijk->abjk\",\n",
    "                       imps.get_tensor(len(imps) - 1), \n",
    "                       inv_sqrtl, \n",
    "                       U, \n",
    "                       np.sqrt(lam),np.sqrt(lam), \n",
    "                       V, \n",
    "                       inv_sqrtr, \n",
    "                       imps.tensors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(images1,images2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.051250619959221\n",
      "1.5940558554691758e-14\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(now_result-result_should))\n",
    "print(np.linalg.norm(now_result-the_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### torch.dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a,X,U,S,V,Y,b = canonicalize(imps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from engine.torch_dense import *\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "left  = np.einsum('ea,ab,bc->ec',X,U,np.sqrt(S)).real\n",
    "right = np.einsum('ea,ab,bc->ec',np.sqrt(S),V,Y).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.35 +0.j, -1.134+0.j,  0.117+0.j,  2.915+0.j],\n",
       "       [ 1.193+0.j,  1.376+0.j, -3.855+0.j,  0.129+0.j],\n",
       "       [-1.92 +0.j,  2.322+0.j,  0.48 +0.j,  0.344+0.j],\n",
       "       [ 2.836+0.j,  0.947+0.j,  0.577+0.j, -0.068+0.j]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('ab,ca->bc',X,Y).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### diagonal.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from engine.sparse import *\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imps = FiniteMPS.random(d=[3,3]*5,\n",
    "      D=[2]*9,\n",
    "      dtype=np.float64)\n",
    "imps.canonicalize()\n",
    "imps.position(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n",
      "(10, 20)\n"
     ]
    }
   ],
   "source": [
    "L=10\n",
    "idx1     = list(range(2*L))\n",
    "idx2     = [i for i in range(L) for j in range(2)]\n",
    "mps_unit = sparse.COO([idx1,idx2],np.random.randn(2*L),(2*L,L)).reshape((L,L*2))\n",
    "R,Q = diagonal_tensor_RQ(mps_unit)\n",
    "print(R.shape)\n",
    "print(Q.shape)\n",
    "# u0,s0,v0 = diagonal_tensor_svd_sparse_2D(mps_unit)\n",
    "# u1,s1,v1 = np.linalg.svd(mps_unit.todense(),full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a=np.random.randint(3,(100,100)).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.save(\"tttest\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "b=np.load(\"tttest.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 43], dtype=uint8)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "code_folding": [
     1,
     3,
     8,
     14,
     39
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Efficient_Sparse_Matrix_List_Saver:\n",
    "    def __init__(self,dtype = 'sparse'):\n",
    "        self.dtype = dtype\n",
    "    def save(self,sparse_matrix_list,save_dir):\n",
    "        if self.dtype == 'sparse':\n",
    "            self.save_sparse_data(sparse_matrix_list,save_dir)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    def load(self,save_dir):\n",
    "        if self.dtype == 'sparse':\n",
    "            return self.load_sparse_data(save_dir)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    @staticmethod \n",
    "    def save_sparse_data(sparse_matrix_list,save_dir):\n",
    "        max_shape_len = max([len(t.shape) for t in sparse_matrix_list])\n",
    "        save_indexes  = []\n",
    "        save_shapes   = []\n",
    "        for i in range(len(sparse_matrix_list)):\n",
    "            save_index = sparse_matrix_list[i].coords.transpose()\n",
    "            save_shape = list(sparse_matrix_list[i].shape)\n",
    "            if len(save_shape)< max_shape_len:\n",
    "                padding     = max_shape_len-len(save_shape)\n",
    "                save_index  = np.pad(save_index,[[0,0],[0,padding]])\n",
    "                save_shape  = save_shape+[1]*padding\n",
    "            save_indexes.append(save_index) \n",
    "            save_shapes.append(save_shape)\n",
    "        all_indexs  = np.concatenate(save_indexes)\n",
    "        all_values  = np.concatenate([t.data for t in sparse_matrix_list])\n",
    "        all_shape   = np.stack(save_shapes)\n",
    "        all_idx_size= np.array([len(t.shape) for t in sparse_matrix_list])\n",
    "        nnz_list    = np.array([t.nnz for t in sparse_matrix_list])\n",
    "        assert sum(nnz_list) == len(all_indexs) == len(all_values)\n",
    "        np.save(os.path.join(save_dir,\"all_indexs\"),all_indexs)\n",
    "        np.save(os.path.join(save_dir,\"all_idx_size\"),all_idx_size)\n",
    "        np.save(os.path.join(save_dir,\"all_values\"),all_values)\n",
    "        np.save(os.path.join(save_dir,\"all_shape\"),all_shape)\n",
    "        np.save(os.path.join(save_dir,\"nnz_list\"),nnz_list)\n",
    "    @staticmethod\n",
    "    def load_sparse_data(save_dir):\n",
    "        all_indexs   = np.load(os.path.join(save_dir,\"all_indexs.npy\"))\n",
    "        all_idx_size = np.load(os.path.join(save_dir,\"all_idx_size.npy\"))\n",
    "        all_values   = np.load(os.path.join(save_dir,\"all_values.npy\"))\n",
    "        all_shape    = np.load(os.path.join(save_dir,\"all_shape.npy\"))\n",
    "        nnz_list     = np.load(os.path.join(save_dir,\"nnz_list.npy\"))\n",
    "        \n",
    "        sparse_matrix_list =[]\n",
    "        start = 0 \n",
    "        for nnz,sz,shape in zip(nnz_list,all_idx_size,all_shape):\n",
    "            indexs = all_indexs[start:start+nnz][...,:sz].transpose()\n",
    "            values = all_values[start:start+nnz]\n",
    "            shape  = shape[:sz]\n",
    "            tensor = sparse.COO(indexs,values,shape.tolist())\n",
    "            start  = start+nnz\n",
    "            sparse_matrix_list.append(tensor)\n",
    "        return sparse_matrix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "L=10\n",
    "idx1     = list(range(2*L))\n",
    "idx2     = [i for i in range(L) for j in range(2)]\n",
    "#mps_unit = sparse.COO([idx1,idx2],np.random.randn(2*L),(2*L,L)).reshape((L,2,L))\n",
    "mps_line = ([sparse.as_coo(np.random.randn(2,L))]+\n",
    "            [sparse.COO([idx1,idx2],np.random.randn(2*L),(2*L,L)).reshape((L,2,L))\n",
    "               for i in range(9)])\n",
    "#mps_line[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_loader= torch.utils.data.DataLoader(dataset=mnist_train, batch_size=1000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test , batch_size=1000, shuffle=False)\n",
    "images,labels = iter(train_loader).next()\n",
    "origin_inputs = preprocess_sum_one(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "L=origin_inputs.shape[0]\n",
    "idx1     = list(range(2*L))\n",
    "idx2     = [i for i in range(L) for j in range(2)]\n",
    "mps_line=[sparse.as_coo(origin_inputs[:,0,:].transpose(1,0).numpy())]\n",
    "for tensor in origin_inputs.permute(1,0,2)[1:]:\n",
    "    #print(tensor.flatten().numpy().shape)\n",
    "    mps_line.append(sparse.COO([idx1,idx2],tensor.flatten().numpy(),(2*L,L)).reshape((L,2,L)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# next_line,z = right_canonicalize_MPS_sparse(mps_line,final_normlization =True,all_renormlization=False)\n",
    "\n",
    "# Decomposition_Engine=lambda x:truncated_SVD_sparse(x,output='QR',\n",
    "#                                                     max_truncation_error=0.00,\n",
    "#                                                     max_singular_values=100,\n",
    "#                                                    )\n",
    "# next_line_2,z_2 = left_canonicalize_MPS_sparse(next_line,final_normlization =True,\n",
    "#                                                all_renormlization=True,\n",
    "#                                                Decomposition_Engine=Decomposition_Engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.67 ms ± 33.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "u,s,v = diagonal_tensor_svd_sparse(sparse_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### diagonal.torch.dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def diagonal_tensor_svd_torch_dense(tensor):\n",
    "    reduce = False\n",
    "    if len(tensor.shape)==2:\n",
    "        tensor = tensor.unsqueeze(0)\n",
    "        reduce = True\n",
    "    W,H   = tensor.shape[-2:]\n",
    "    batch_shape= tensor.shape[:-2]\n",
    "    u = s = v = None\n",
    "    if W>=H:\n",
    "        batch_diag = torch.matmul(tensor.transpose(-1,-2),tensor)#auto broadcast, or can use bmm\n",
    "    else:\n",
    "        batch_diag = torch.matmul(tensor,tensor.transpose(-1,-2))#auto broadcast, or can use bmm\n",
    "    A,A        = batch_diag.shape[-2:]\n",
    "    batch_diag = batch_diag[...,range(A),range(A)]\n",
    "    batch_diag,batch_order= batch_diag.sort(-1,descending=True)\n",
    "    #fast_V      = [get_sort_matrix(order).to_dense() for order in batch_order]\n",
    "    batch_order = batch_order.flatten(start_dim=0,end_dim=-2)\n",
    "    K,A         = batch_order.shape\n",
    "    s           = batch_diag.sqrt()\n",
    "    s           = s.reshape(*batch_shape,A)\n",
    "    if W>=H:\n",
    "        v = torch.sparse_coo_tensor([list(range(K*A)),batch_order.flatten().tolist()], [1.0]*K*A,(K*A,A))\n",
    "        v = v.to_dense().reshape(-1,A,A)\n",
    "        u = torch.bmm(tensor,v.transpose(-1,-2)/s.unsqueeze(-2))\n",
    "        v = v.reshape(*batch_shape,A,A)\n",
    "        u = u.reshape(*batch_shape,W,A)\n",
    "    else:\n",
    "        u = torch.sparse_coo_tensor([list(range(K*A)),batch_order.flatten().tolist()], [1.0]*K*A,(K*A,A))\n",
    "        u = u.to_dense().reshape(-1,A,A).transpose(-1,-2)\n",
    "        v = torch.bmm(u.transpose(-1,-2)/s.unsqueeze(-1),tensor)#TODO: case when s==0\n",
    "        u = u.reshape(*batch_shape,A,A)\n",
    "        v = v.reshape(*batch_shape,A,H)\n",
    "    output = [u,s,v.transpose(-1,-2)]\n",
    "    if reduce:\n",
    "        output = [t[0] for t in output]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8abfe4bc2fdb4e06b505cc3e15235fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# i=0\n",
    "# for images,labels in tqdm(train_loader):\n",
    "#     #images,labels = iter(train_loader).next()\n",
    "#     inputs = preprocess_sum_one(images)\n",
    "#     #inputs= rd_engine(10,50,2)\n",
    "#     inputs= inputs.permute(1,2,0)#(B,num,k)->(num,k,B)\n",
    "#     inputs= torch.diag_embed(inputs)#(num,k,B)->(num,k,B,B)\n",
    "#     inputs= inputs.permute(0,2,1,3)#(num,k,B,B)->(num,B,k,B)\n",
    "#     inputs= [v for v in inputs]\n",
    "#     inputs[0]= torch.diagonal(inputs[0], dim1=0, dim2=-1)#(B,k,B) -> #(k,B)\n",
    "#     DCEngine = lambda x:truncated_SVD(x,output='QR',max_truncation_error=0.00,max_singular_values=100)\n",
    "#     mps_line,Z_list = left_canonicalize_MPS(inputs,Decomposition_Engine=DCEngine,normlization=False)\n",
    "#     state_dict = {}\n",
    "#     state_dict['xdata']=dict([[i,t] for i,t in enumerate(mps_line)])\n",
    "#     state_dict['ydata']=labels\n",
    "#     torch.save(state_dict,f'offline_SVD_data/preprocess_sum_one.cut100/mps_line_{i}.pt')\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use 1/2 sing vals\n"
     ]
    }
   ],
   "source": [
    "Q,R        = Decomposition_Engine(inputs[0])[:2]\n",
    "new_tensor = torch.einsum('ab,bcd->acd',R,inputs[1])\n",
    "shape      = new_tensor.shape\n",
    "a,b,c = shape\n",
    "new_tensor = new_tensor.reshape(a*b,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### diagonal.torch_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# L=10\n",
    "# idx1     = list(range(2*L))\n",
    "# idx2     = [i for i in range(L) for j in range(2)]\n",
    "# #mps_unit = sparse.COO([idx1,idx2],np.random.randn(2*L),(2*L,L)).reshape((L,2,L))\n",
    "# mps_line = ([sparse.as_coo(np.random.randn(2,L))]+\n",
    "#             [sparse.COO([idx1,idx2],np.random.randn(2*L),(2*L,L)).reshape((L,2,L))\n",
    "#                for i in range(9)])\n",
    "# #mps_line[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# L=10\n",
    "# num=1\n",
    "# k=2\n",
    "# origin_inputs = rd_engine(L,num,k)\n",
    "# inputs = origin_inputs.permute(1,2,0)#(B,num,k)->(num,k,B)\n",
    "# inputs = torch.diag_embed(inputs)#(num,k,B)->(num,k,B,B)\n",
    "# inputs = inputs.permute(0,2,1,3)#(num,k,B,B)->(num,B,k,B)\n",
    "# num,B,k,B     = inputs.shape\n",
    "# inputs        = inputs.reshape(num,B*k,B )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch_sparse import coalesce\n",
    "# idx1          = list(range(2*L))\n",
    "# idx2          = [i for i in range(L) for j in range(2)]\n",
    "# index         = torch.tensor([idx1,idx2])\n",
    "# sparse_tensor = torch.sparse_coo_tensor(index, origin_inputs.flatten(), (2*L,L)).coalesce()\n",
    "# sparse_tensor = reshape_sparse_tensor(sparse_tensor,(L,2*L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": [
     0,
     3,
     15,
     26,
     31,
     42,
     74,
     80,
     92,
     124,
     160,
     180,
     191
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def transpose_sparse_tensor(coalesce_sparse_tensor):\n",
    "    return coalesce_sparse_tensor.transpose(1,0).coalesce()\n",
    "\n",
    "def matmul_sparse_tensor(coalesce_sparse_tensor_1,coalesce_sparse_tensor_2):\n",
    "    m,k1   = coalesce_sparse_tensor_1.size()\n",
    "    k2,n   = coalesce_sparse_tensor_2.size()\n",
    "    assert k1==k2\n",
    "    indexA = coalesce_sparse_tensor_1.indices()\n",
    "    valueA = coalesce_sparse_tensor_1.values()\n",
    "    \n",
    "    indexB = coalesce_sparse_tensor_2.indices()\n",
    "    valueB = coalesce_sparse_tensor_2.values()\n",
    "\n",
    "    indexC, valueC = torch_sparse.spspmm(indexA, valueA, indexB, valueB, m, k1, n)\n",
    "    return torch.sparse_coo_tensor(indexC, valueC, (m,n)).coalesce()\n",
    "def reshape_sparse_tensor(coalesce_sparse_tensor,target_shape):\n",
    "    indices = coalesce_sparse_tensor.indices().tolist()\n",
    "    size    = coalesce_sparse_tensor.size()\n",
    "    assert np.prod(size)==np.prod(target_shape)\n",
    "    target_indices = np.stack(np.unravel_index(np.ravel_multi_index(indices,size),target_shape))\n",
    "    target_indices = torch.Tensor(target_indices)\n",
    "    target_indices = target_indices.to(coalesce_sparse_tensor.device)\n",
    "    tensor = torch.sparse_coo_tensor(target_indices, coalesce_sparse_tensor.values(), target_shape).coalesce()\n",
    "    #tensor.to(coalesce_sparse_tensor.device)\n",
    "    return tensor\n",
    "\n",
    "def sparse_diagonal(dense_matrix):\n",
    "    A = len(dense_matrix)\n",
    "    idx = torch.stack([torch.arange(A),torch.arange(A)]).to(dense_matrix.device)\n",
    "    return torch.sparse_coo_tensor(idx,dense_matrix, (A,A)).coalesce()\n",
    "\n",
    "def sparse_take_first(coalesce_sparse_tensor,row_num,axis=0):\n",
    "    size    = list(coalesce_sparse_tensor.shape)\n",
    "    if row_num > size[axis]:return coalesce_sparse_tensor\n",
    "    indexes = coalesce_sparse_tensor.indices()\n",
    "    value   = coalesce_sparse_tensor.values()\n",
    "    good_i=indexes[axis]<row_num\n",
    "    indexes = torch.stack([t[good_i] for t in indexes])\n",
    "    value   = value[good_i]\n",
    "    size[axis] = row_num\n",
    "    return torch.sparse_coo_tensor(indexes,value, size).coalesce().to(coalesce_sparse_tensor.device)\n",
    "\n",
    "def diagonal_tensor_svd_torch_sparse_2D(tensor):\n",
    "    W,H   = tensor.size()\n",
    "    if W>=H:\n",
    "        MstarM     = matmul_sparse_tensor(transpose_sparse_tensor(tensor),tensor)\n",
    "    else:\n",
    "        MstarM     = matmul_sparse_tensor(tensor,transpose_sparse_tensor(tensor))\n",
    "    diagonal_svd_flag = True\n",
    "    a,b = MstarM.indices()\n",
    "    if (a!=b).any():\n",
    "        return None\n",
    "    L,L = MstarM.shape\n",
    "    batch_diag  = torch.Tensor([MstarM[i,i] for i in range(L)]).to(tensor.device)\n",
    "    #batch_diag = MstarM.values()\n",
    "    # in sparse representation, only value > 0 takes.\n",
    "    batch_diag,batch_order = batch_diag.sort(-1,descending=True)\n",
    "    s          = batch_diag.sqrt()\n",
    "    nonzero_num= torch.sum(s>0)\n",
    "    s          = s[:nonzero_num]\n",
    "    A = len(batch_order)\n",
    "    index = torch.stack([torch.arange(A).to(tensor.device),batch_order])\n",
    "    value = torch.ones(A).to(tensor.device)\n",
    "    if W>=H: \n",
    "        v = torch.sparse_coo_tensor(index,value,(A,A)).coalesce()\n",
    "        if nonzero_num < A :v = sparse_take_first(v,nonzero_num,axis=1)\n",
    "        u = matmul_sparse_tensor(tensor,matmul_sparse_tensor(transpose_sparse_tensor(v),sparse_diagonal(1/s)))\n",
    "    else:\n",
    "        u = torch.sparse_coo_tensor(index,value,(A,A)).coalesce()\n",
    "        if nonzero_num < A :u = sparse_take_first(u,nonzero_num,axis=0)\n",
    "        v = matmul_sparse_tensor(matmul_sparse_tensor(sparse_diagonal(1/s),u),tensor)\n",
    "        u = transpose_sparse_tensor(u)\n",
    "    return u,s,v\n",
    "\n",
    "def reciprocal_sparse_tensor(coalesce_sparse_tensor):\n",
    "    size   = coalesce_sparse_tensor.size()\n",
    "    indexA = coalesce_sparse_tensor.indices()\n",
    "    valueA = coalesce_sparse_tensor.values()\n",
    "    return torch.sparse_coo_tensor(indexA, 1/valueA, size).coalesce()\n",
    "\n",
    "def diagonal_tensor_RQ_torch_sparse(tensor):\n",
    "    W,H   = tensor.shape\n",
    "    assert W<=H\n",
    "    MstarM     = matmul_sparse_tensor(tensor,transpose_sparse_tensor(tensor))\n",
    "    a,b = MstarM.indices()\n",
    "    assert (a==b).any()\n",
    "    #batch_diag = MstarM.values()\n",
    "    #s = batch_diag.sqrt()\n",
    "    R = MstarM.sqrt()\n",
    "    Q = matmul_sparse_tensor(reciprocal_sparse_tensor(R),tensor)\n",
    "    return R,Q\n",
    "\n",
    "def right_canonicalize_MPS_torch_sparse(mps_line,Decomposition_Engine=diagonal_tensor_RQ_torch_sparse,\n",
    "                          final_normlization =True,all_renormlization=False\n",
    "                          ):\n",
    "    new_chain = []\n",
    "    R         = None\n",
    "    Z_list    = []\n",
    "    # assume every mps_unit is store (kD,D)\n",
    "    for i,tensor in enumerate(mps_line[::-1]):\n",
    "        if R is not None:\n",
    "            new_tensor = matmul_sparse_tensor(tensor,R)   \n",
    "        else:\n",
    "            new_tensor = tensor\n",
    "        kD,D  = new_tensor.shape\n",
    "        if kD>D:\n",
    "            new_tensor = reshape_sparse_tensor(new_tensor,(D,kD))\n",
    "\n",
    "        if i == len(mps_line) - 1:\n",
    "            if final_normlization:\n",
    "                Z = (new_tensor**2).values().sum().sqrt()\n",
    "                new_tensor /= Z\n",
    "                Z_list.append(Z)\n",
    "            new_chain.append(new_tensor)\n",
    "        else:\n",
    "            if all_renormlization:\n",
    "                Z = (new_tensor**2).values().sum().sqrt()\n",
    "                new_tensor /= Z\n",
    "                Z_list.append(Z)\n",
    "            R,Q = Decomposition_Engine(new_tensor)[:2]\n",
    "            new_chain.append(Q)\n",
    "    new_chain=new_chain[::-1]\n",
    "    return new_chain,Z_list\n",
    "\n",
    "def left_canonicalize_MPS_torch_sparse(mps_line,Decomposition_Engine=None,\n",
    "                          final_normlization =True,all_renormlization=False):\n",
    "    # for any not canonical mps line\n",
    "    # the chain size (D,P,D)\n",
    "    new_chain = []\n",
    "    R         = None\n",
    "    Z_list    = []# record the scale information for each unit.\n",
    "    # assume every mps_unit is store (D,kD)\n",
    "    for i,tensor in enumerate(tqdm(mps_line)):\n",
    "        if R is not None:\n",
    "            D,kD       = tensor.shape\n",
    "            B,D        = R.shape\n",
    "            new_tensor = matmul_sparse_tensor(R,tensor)   \n",
    "            new_shape  = new_tensor.shape\n",
    "            new_tensor = reshape_sparse_tensor(new_tensor,(B*kD//D,D))\n",
    "        else:\n",
    "            new_tensor = tensor        \n",
    "        if i == len(mps_line) - 1:\n",
    "            if final_normlization:\n",
    "                Z = (new_tensor**2).values().sum().sqrt()\n",
    "                new_tensor /= Z\n",
    "                Z_list.append(Z)\n",
    "            new_chain.append(new_tensor)\n",
    "        else:\n",
    "            if all_renormlization:\n",
    "                Z = (new_tensor**2).values().sum().sqrt()\n",
    "                new_tensor /= Z\n",
    "                Z_list.append(Z)\n",
    "            Q,R,_,diagonal_svd_flag = Decomposition_Engine(new_tensor)\n",
    "            new_chain.append(Q)\n",
    "           # print(Q.shape)\n",
    "#         if not diagonal_svd_flag:\n",
    "#             print(f\"full matrix SVD at unit {i}\")\n",
    "\n",
    "    return new_chain,Z_list\n",
    "\n",
    "def truncated_SVD_torch_sparse(tensor,output='RQ',max_singular_values= None,\n",
    "                          max_truncation_error= None,\n",
    "                          relative = True,\n",
    "                          normlized= True,\n",
    "                          verbose  = False):\n",
    "    # the canonocal\n",
    "    # tensor is batched\n",
    "    assert len(tensor.shape)  == 2\n",
    "    diagonal_svd_flag = True\n",
    "    out = diagonal_tensor_svd_torch_sparse_2D(tensor)\n",
    "    if out is None:\n",
    "        diagonal_svd_flag=False\n",
    "        q = min(tensor.size())\n",
    "        q = min(q,max_singular_values) \n",
    "        u, s, v = torch.svd_lowrank(tensor,q=q)\n",
    "        v       = v.T\n",
    "        #print(q,s.shape)\n",
    "    else:\n",
    "        u, s, v = out\n",
    "        max_singular_values = s.shape[-1] if max_singular_values is None else max_singular_values\n",
    "        if max_truncation_error is not None and len(s)>max_singular_values:\n",
    "            # Cumulative norms of singular values in ascending order\n",
    "            s_normlized  = s**2\n",
    "            s_normlized /= torch.sum(s_normlized)\n",
    "            s_sorted,_   = torch.sort(s_normlized)# 0.1,0.2,...,0.4\n",
    "            trunc_errs   = torch.sqrt(torch.cumsum(s_sorted,0))# 0.1,0.3,....1\n",
    "            # If relative is true, rescale max_truncation error with the largest\n",
    "            # singular value to yield the absolute maximal truncation error.\n",
    "            num_sing_vals_err = torch.sum(trunc_errs > max_truncation_error)\n",
    "            if max_singular_values>num_sing_vals_err and verbose:\n",
    "                print(f\"use {num_sing_vals_err}/{max_singular_values} sing vals\")\n",
    "        else:\n",
    "            num_sing_vals_err  = max_singular_values\n",
    "\n",
    "        nk = min(max_singular_values, num_sing_vals_err)\n",
    "\n",
    "\n",
    "        #s_rest = s[...,num_sing_vals_keep:]\n",
    "\n",
    "        u  = sparse_take_first(u,nk,axis=1) if u.is_sparse else u[...,:nk]\n",
    "        s  = s[...,:nk]\n",
    "        v  = sparse_take_first(v,nk,axis=0) if v.is_sparse else v[:nk,:]\n",
    "    Z  = None #maybe add in the furture\n",
    "    if output == 'RQ':\n",
    "        R = u*s[None] if not u.is_sparse else matmul_sparse_tensor(u,sparse_diagonal(s))\n",
    "        Q = v\n",
    "        if not R.is_sparse:R = R.to_sparse() \n",
    "        if not Q.is_sparse:Q = Q.to_sparse() \n",
    "        output = [R,Q,Z,diagonal_svd_flag]\n",
    "    elif output == 'QR':\n",
    "        Q = u\n",
    "        R = s[:,None]*v if not  v.is_sparse else matmul_sparse_tensor(sparse_diagonal(s),v)\n",
    "        if not R.is_sparse:R = R.to_sparse()\n",
    "        if not Q.is_sparse:Q = Q.to_sparse()\n",
    "        output = [Q,R,Z,diagonal_svd_flag]\n",
    "    else:\n",
    "        if not u.is_sparse:u = u.to_sparse() \n",
    "        if not v.is_sparse:v = v.to_sparse() \n",
    "        output = [u,s,v,Z,diagonal_svd_flag]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_loader= torch.utils.data.DataLoader(dataset=mnist_train, batch_size=1000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test , batch_size=1000, shuffle=False)\n",
    "images,labels = iter(train_loader).next()\n",
    "origin_inputs = preprocess_sum_one(images)\n",
    "\n",
    "L=origin_inputs.shape[0]\n",
    "idx1          = list(range(2*L))\n",
    "idx2          = [i for i in range(L) for j in range(2)]\n",
    "index         = torch.tensor([idx1,idx2])\n",
    "mps_line=[(origin_inputs[:,0,:].transpose(1,0)).to_sparse()]\n",
    "for tensor in origin_inputs.permute(1,0,2)[1:]:\n",
    "    sparse_tensor = torch.sparse_coo_tensor(index, tensor.flatten(), (2*L,L)).coalesce()      \n",
    "    #sparse_tensor = reshape_sparse_tensor(sparse_tensor,(L,2*L))                              \n",
    "    mps_line.append(sparse_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mps_line=[t.cuda() for t in mps_line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mps_line,Z = right_canonicalize_MPS_torch_sparse(mps_line,final_normlization =True,all_renormlization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860f1c30906e46208b3c22b98cd2c437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/784 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Decomposition_Engine=lambda x:truncated_SVD_torch_sparse(x,output='QR',\n",
    "                                                        max_truncation_error=0.00,\n",
    "                                                        max_singular_values=1,\n",
    "                                                       )\n",
    "mps_line2,z_2 = left_canonicalize_MPS_torch_sparse(mps_line,final_normlization =True,\n",
    "                                               all_renormlization=True,\n",
    "                                               Decomposition_Engine=Decomposition_Engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### torch_sparse MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_sparse\n",
    "import numpy as np\n",
    "from utils import *\n",
    "\n",
    "def rd_engine(*x,**kargs):\n",
    "    x =  torch.randn(*x,device='cpu',**kargs)\n",
    "    x/=  torch.norm(x).sqrt()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "mnist_data = np.load('archive/tn-for-unsup-ml/data/binarized_mnist.npz')\n",
    "train_data = torch.from_numpy(mnist_data['train_data'])\n",
    "test_data  = torch.from_numpy(mnist_data['test_data'])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=(0.0,), std=(1.0,))\n",
    "])\n",
    "DATAPATH    = '/media/tianning/DATA/DATASET/MNIST/'\n",
    "mnist_train = datasets.MNIST(DATAPATH, train=True, download=False, transform=transform)\n",
    "mnist_test  = datasets.MNIST(DATAPATH, train=False,download=False, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_loader= torch.utils.data.DataLoader(dataset=mnist_train, batch_size=1000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test , batch_size=1000, shuffle=False)\n",
    "images,labels = iter(train_loader).next()\n",
    "origin_inputs = preprocess_sum_one(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 784, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "device='cpu'\n",
    "L=origin_inputs.shape[0]\n",
    "idx1  = [0]*L+[1]*L\n",
    "idx2  = [(L+1)*i for i in range(L)]\n",
    "idx2  = idx2 + idx2\n",
    "index = torch.tensor([idx2,idx1])\n",
    "input_mps=[(origin_inputs[:,0,:]).to_sparse().to(device)]\n",
    "for tensor in origin_inputs.permute(1,0,2)[1:]:\n",
    "    sparse_tensor = torch.sparse_coo_tensor(index, tensor.flatten(), (L*L,2)).coalesce()      \n",
    "    #sparse_tensor = reshape_sparse_tensor(sparse_tensor,(L,2*L))                              \n",
    "    input_mps.append(sparse_tensor.to(device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# left_tensors = [torch.einsum('cpd,apb->acbd', input_data[i]  ,self.mps_var[i]).flatten(0,1).flatten(-2,-1) for i in range(self.hn)]\n",
    "# rigt_tensors = [torch.einsum('cpd,apb->acbd', input_data[i-1]  ,self.mps_var[i]).flatten(0,1).flatten(-2,-1) for i in range(self.hn+1,len(self.mps_var))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D=2\n",
    "P=2\n",
    "L=14\n",
    "B=3\n",
    "inputs = rd_engine(B,L,P)    \n",
    "# inputs = inputs.permute(1,2,0)#(B,num,k)->(num,k,B)\n",
    "# inputs = torch.diag_embed(inputs)#(num,k,B)->(num,k,B,B)\n",
    "# inputs = inputs.flatten(-2,-1)\n",
    "#inputs = inputs.permute(0,2,1,3)#(num,k,B,B)->(num,B,k,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "B=inputs.shape[0]\n",
    "idx1  = [0]*B+[1]*B\n",
    "idx2  = [(B+1)*i for i in range(B)]\n",
    "idx2  = idx2 + idx2\n",
    "index = torch.tensor([idx2,idx1])\n",
    "input_mps=[(inputs[:,0,:]).to_sparse()]\n",
    "for tensor in inputs.permute(1,0,2)[1:]:\n",
    "    sparse_tensor = torch.sparse_coo_tensor(index, tensor.flatten(), (B*B,2)).coalesce()      \n",
    "    #sparse_tensor = reshape_sparse_tensor(sparse_tensor,(L,2*L))                              \n",
    "    input_mps.append(sparse_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def rd_engine(*x,**kargs):\n",
    "    x =  torch.randn(*x,device='cpu',**kargs)\n",
    "    x/=  torch.norm(x).sqrt()\n",
    "    return x\n",
    "Ds  = [1]+list(np.random.randint(3,10,L-1))+[1]\n",
    "mps_var    = [rd_engine(Ds[i],P,Ds[i+1]) for i in range(L)]  \n",
    "print(Ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 4, 9, 6, 4, 6, 6, 3, 6, 5, 6, 6, 3, 1]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out=[]\n",
    "for inp,mps_unit in zip(input_mps,mps_var):\n",
    "    out.append(torch.sparse.mm(inp,mps_unit.permute(1,0,2).flatten(1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 2])\n"
     ]
    }
   ],
   "source": [
    "idx=4\n",
    "print(input_mps[idx].shape)\n",
    "D1,P,D2=mps_var[idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_values= input_mps[idx].values().reshape(B,P)@mps_var[idx].permute(1,0,2).flatten(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 24])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0746, -0.0109,  0.0053,  0.0967,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0675, -0.0708,  0.1573, -0.1155,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0360,  0.2245,  0.0516,  0.1981,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.2776, -0.2080, -0.0120,  0.1236,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.1618,  0.0482,  0.0096, -0.0264,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.1465, -0.1226, -0.1381,  0.1770,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.1027, -0.0411, -0.0813,  0.1604,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.1903, -0.0082,  0.2638, -0.0855,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0499,  0.3243,  0.0474,  0.2284,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.4458, -0.2313, -0.0468,  0.2555,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.2578,  0.0307,  0.0229, -0.0274,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.1947, -0.2375, -0.2380,  0.2213,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.0436,  0.0053, -0.0069, -0.0554],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.0353,  0.0452, -0.0900,  0.0707],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0254, -0.1306, -0.0312, -0.1177],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.1596,  0.1240,  0.0057, -0.0686],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.0931, -0.0297, -0.0052,  0.0158],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.0860,  0.0687,  0.0787, -0.1045]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.block_diag(*all_values.reshape(B,D1,D2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "LDLD=out[idx].reshape(B,B,Ds[idx],Ds[idx+1]).permute(0,2,1,3).flatten(0,1).flatten(-2,-1).to_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 12])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDLD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.075 -0.011  0.005  0.097  0.     0.     0.     0.     0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.067 -0.071  0.157 -0.115  0.     0.     0.     0.     0.     0.\n",
      "   0.     0.   ]\n",
      " [-0.036  0.225  0.052  0.198  0.     0.     0.     0.     0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.278 -0.208 -0.012  0.124  0.     0.     0.     0.     0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.162  0.048  0.01  -0.026  0.     0.     0.     0.     0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.146 -0.123 -0.138  0.177  0.     0.     0.     0.     0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.     0.     0.     0.     0.103 -0.041 -0.081  0.16   0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.     0.     0.     0.     0.19  -0.008  0.264 -0.086  0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.     0.     0.     0.     0.05   0.324  0.047  0.228  0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.     0.     0.     0.     0.446 -0.231 -0.047  0.256  0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.     0.     0.     0.     0.258  0.031  0.023 -0.027  0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.     0.     0.     0.     0.195 -0.238 -0.238  0.221  0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.    -0.044  0.005\n",
      "  -0.007 -0.055]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.    -0.035  0.045\n",
      "  -0.09   0.071]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.025 -0.131\n",
      "  -0.031 -0.118]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.    -0.16   0.124\n",
      "   0.006 -0.069]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.    -0.093 -0.03\n",
      "  -0.005  0.016]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.    -0.086  0.069\n",
      "   0.079 -0.104]]\n"
     ]
    }
   ],
   "source": [
    "print(LDLD.to_dense().numpy().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###### test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "the max singular value truncation only good for hundreds dimenstion, for small dimenstion not good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "FiniteMPS canonicalize == right_canonicalize_MPS with torchrq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensornetwork.matrixproductstates.finite_mps import FiniteMPS\n",
    "from tensornetwork.matrixproductstates.infinite_mps import InfiniteMPS\n",
    "from typing import Any, List, Optional, Text, Type, Union, Dict, Sequence\n",
    "import numpy as np\n",
    "Tensor = Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# D=6\n",
    "# P=4\n",
    "# L=5\n",
    "# mps_line = [torch.randn(1,P,D)] + [torch.randn(D,P,D) for i in range(L-2)]+ [torch.randn(D,P,1)]\n",
    "# input_mps= [torch.randn(P,D)] + [torch.randn(D,P,D) for i in range(L-2)]+ [torch.randn(D,P)]\n",
    "# approx = approxmate_mps_line(mps_line,max_singular_values=2)\n",
    "# #contract_two_mps(approx,input_mps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tn.set_default_backend(\"pytorch\")\n",
    "# tn_mps_1 = FiniteMPS(mps_line,canonicalize=False)\n",
    "# tn_mps_1.canonicalize(normalize=False)\n",
    "# tn_mps_1.center_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensornetwork as tn\n",
    "from tensornetwork import contractors\n",
    "tn.set_default_backend(\"pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     3
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D=10\n",
    "P=4\n",
    "L=14\n",
    "def rd_engine(*x,**kargs):\n",
    "    x =  torch.randn(*x,device='cpu',**kargs)\n",
    "    x/=  torch.norm(x).sqrt()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": [
     1,
     36
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensornetwork.contractors.opt_einsum_paths.path_contractors import *\n",
    "def my_contracter(nodes: Iterable[AbstractNode],\n",
    "         path = None,\n",
    "         output_edge_order: Optional[Sequence[Edge]] = None,\n",
    "         ignore_edge_order: bool = False,\n",
    "         memory_limit: Optional[int] = None) -> AbstractNode:\n",
    "        \"\"\"Base method for all `opt_einsum` contractors.\n",
    "\n",
    "        Args:\n",
    "        nodes: A collection of connected nodes.\n",
    "        algorithm: `opt_einsum` contraction method to use.\n",
    "        output_edge_order: An optional list of edges. Edges of the\n",
    "        final node in `nodes_set`\n",
    "        are reordered into `output_edge_order`;\n",
    "        if final node has more than one edge,\n",
    "        `output_edge_order` must be provided.\n",
    "        ignore_edge_order: An option to ignore the output edge\n",
    "        order.\n",
    "\n",
    "        Returns:\n",
    "        Final node after full contraction.\n",
    "        \"\"\"\n",
    "        nodes_set = set(nodes)\n",
    "        edges = get_all_edges(nodes_set)\n",
    "        #output edge order has to be determinded before any contraction\n",
    "        #(edges are refreshed after contractions)\n",
    "\n",
    "        if not ignore_edge_order:\n",
    "            if output_edge_order is None:\n",
    "                output_edge_order = list(get_subgraph_dangling(nodes))\n",
    "                if len(output_edge_order) > 1:\n",
    "                    raise ValueError(\"The final node after contraction has more than \"\n",
    "                                 \"one remaining edge. In this case `output_edge_order` \"\n",
    "                                 \"has to be provided.\")\n",
    "\n",
    "            if set(output_edge_order) != get_subgraph_dangling(nodes):\n",
    "                raise ValueError(\"output edges are not equal to the remaining \"\n",
    "                       \"non-contracted edges of the final node.\")\n",
    "\n",
    "        for edge in edges:\n",
    "            if not edge.is_disabled:  #if its disabled we already contracted it\n",
    "                if edge.is_trace():\n",
    "                    nodes_set.remove(edge.node1)\n",
    "                    nodes_set.add(contract_parallel(edge))\n",
    "\n",
    "        if len(nodes_set) == 1:\n",
    "            # There's nothing to contract.\n",
    "            if ignore_edge_order:\n",
    "                return list(nodes_set)[0]\n",
    "            return list(nodes_set)[0].reorder_edges(output_edge_order)\n",
    "\n",
    "        if path is None:\n",
    "            algorithm = functools.partial(opt_einsum.paths.greedy, memory_limit=memory_limit)\n",
    "            # Then apply `opt_einsum`'s algorithm\n",
    "            path, nodes = utils.get_path(nodes_set, algorithm)\n",
    "        else:\n",
    "            nodes = list(nodes_set) \n",
    "        for a, b in path:\n",
    "            new_node = contract_between(nodes[a], nodes[b], allow_outer_product=True)\n",
    "            nodes.append(new_node)\n",
    "            nodes = utils.multi_remove(nodes, [a, b])\n",
    "\n",
    "        # if the final node has more than one edge,\n",
    "        # output_edge_order has to be specified\n",
    "        final_node = nodes[0]  # nodes were connected, we checked this\n",
    "        if not ignore_edge_order:\n",
    "            final_node.reorder_edges(output_edge_order)\n",
    "        return final_node,path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D=10;O=10;mps_core = [rd_engine(P,D)] + [rd_engine(D,P,D) for _ in range(L-1)] + [rd_engine(D,O,D)]+ [rd_engine(D,P)]\n",
    "B=20;inp_line = [rd_engine(B,P)] + [rd_engine(B,P,B) for _ in range(L-1)] + [rd_engine(B,P,B)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7, 18), (12, 28), (10, 27), (14, 17), (25, 26), (0, 25), (21, 24), (20, 23), (19, 22), (5, 21), (1, 20), (1, 19), (1, 18), (8, 17), (11, 16), (12, 15), (5, 14), (4, 13), (7, 12), (7, 11), (8, 10), (4, 9), (0, 8), (2, 7), (1, 6), (0, 5), (0, 4), (0, 3), (0, 2), (0, 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4304e-01, -1.5820e-01, -1.3586e-02, -9.4462e-04, -1.3982e-01,\n",
       "          9.9057e-02,  1.7996e-01, -1.1456e-01,  1.4263e-01, -2.4580e-03],\n",
       "        [ 3.4687e-01, -4.8310e-01,  2.2043e-01, -2.1364e-01,  4.1445e-01,\n",
       "         -2.5674e-01,  1.4035e-01,  2.4091e-01, -2.3025e-01, -1.1829e-01],\n",
       "        [ 2.0311e-01, -8.6519e-02,  3.1690e-01,  2.3554e-01,  1.1007e-02,\n",
       "         -4.1188e-01,  4.2258e-02,  3.6463e-01, -3.4286e-01, -4.0262e-01],\n",
       "        [-4.7547e-01,  3.7831e-01,  3.3061e-02,  2.4604e-01, -1.5482e-01,\n",
       "         -4.6528e-02,  4.5324e-03, -4.0088e-01,  3.5013e-01,  8.5555e-02],\n",
       "        [ 9.9050e-02, -8.2526e-02,  1.8456e-01, -1.9140e-02,  1.1645e-01,\n",
       "         -3.5684e-01, -2.0432e-01,  1.1110e-01,  9.2640e-02, -1.0480e-01],\n",
       "        [ 1.6438e-01,  2.7121e-01, -3.3816e-02, -4.1494e-03,  1.2835e-01,\n",
       "          1.2292e-01,  8.6925e-02,  3.1019e-01,  3.8543e-01,  1.7188e-01],\n",
       "        [-5.1561e-02,  1.1307e-01, -5.6854e-01,  1.4294e-01, -2.3753e-01,\n",
       "          2.2774e-01,  3.7236e-01, -3.5108e-01,  1.8630e-01,  3.9439e-02],\n",
       "        [ 5.2912e-02,  2.5094e-01, -1.9803e-01,  4.7044e-03, -1.8587e-01,\n",
       "          4.2176e-01,  1.8772e-01,  3.0565e-01,  1.2801e-01,  1.9867e-01],\n",
       "        [ 1.1517e-01,  1.0643e-01,  1.5878e-01,  5.5360e-02, -1.3950e-01,\n",
       "          5.1184e-02,  8.2136e-02, -2.4243e-01, -8.4872e-02,  1.3361e-02],\n",
       "        [ 1.4793e-01, -1.5811e-01,  5.4551e-05, -8.3154e-02, -2.5979e-01,\n",
       "         -1.9083e-01, -1.5844e-01,  1.5925e-01,  1.1895e-01,  2.1983e-02],\n",
       "        [-3.0817e-01,  2.3907e-01, -1.7756e-01,  2.8272e-01,  1.4382e-01,\n",
       "          5.0498e-01,  4.2695e-01,  3.0219e-01, -2.6779e-01, -1.2777e-01],\n",
       "        [-3.8576e-02,  9.5788e-03,  8.3571e-02, -7.7039e-02,  3.6145e-03,\n",
       "          1.6885e-01,  1.5983e-01, -2.3978e-01, -2.0942e-01,  9.6214e-02],\n",
       "        [ 4.0893e-03, -3.6139e-01,  4.0647e-01, -2.6646e-01,  1.9695e-01,\n",
       "         -1.0266e-01,  1.9087e-01,  5.0853e-01, -3.8624e-02,  1.8222e-04],\n",
       "        [-2.9511e-02,  3.1189e-01,  2.4094e-01,  1.7423e-01, -2.5471e-01,\n",
       "         -8.0931e-02, -3.8496e-02, -1.2300e-02,  6.1083e-02, -6.5881e-02],\n",
       "        [-2.3669e-01, -3.0595e-01, -1.7096e-01,  1.4025e-02,  1.4744e-01,\n",
       "         -3.6415e-02, -1.7377e-01,  2.5554e-01, -1.3301e-01, -8.9086e-02],\n",
       "        [ 1.0746e-01, -8.4043e-02,  8.2953e-02,  1.8575e-01, -1.6408e-01,\n",
       "          1.5920e-01, -7.5862e-02, -2.0506e-01, -3.0581e-01, -7.0687e-02],\n",
       "        [-8.5354e-02,  2.5426e-01,  1.8748e-01,  8.1318e-02, -2.2259e-01,\n",
       "          4.7392e-02, -3.1515e-01,  1.3632e-01, -1.4565e-01, -2.7911e-01],\n",
       "        [ 1.8653e-01, -1.3372e-01,  4.8352e-02, -1.3855e-01, -1.6892e-01,\n",
       "          2.6170e-01,  1.0761e-01, -6.7705e-02, -4.6117e-02,  1.2726e-01],\n",
       "        [-2.1083e-01, -3.7951e-02, -1.1342e-01,  4.1334e-02, -6.1075e-03,\n",
       "          2.7614e-01,  7.5191e-03, -2.2903e-01, -8.9833e-02,  2.0455e-01],\n",
       "        [ 7.3030e-02,  2.0093e-01, -2.6945e-01,  1.6580e-01, -2.3946e-02,\n",
       "          1.6530e-01, -1.5978e-01, -1.2399e-01,  1.9520e-02, -1.6731e-02]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mps_nodes  = [tn.Node(v, name=f\"t{i}\") for i,v in enumerate(mps_core)]\n",
    "for i in range(len(mps_core)-1):\n",
    "    tn.connect(mps_nodes[i][-1],mps_nodes[i+1][0],name=f\"mps:{i}<->{i+1}\")\n",
    "inp_nodes=[tn.Node(v, name=f\"i{i}\") for i,v in enumerate(inp_line)]\n",
    "tn.connect(inp_nodes[0][0],inp_nodes[1][0],name=f\"inp:{0}<->{1}\")\n",
    "for i in range(1,len(inp_nodes)-1):\n",
    "    tn.connect(inp_nodes[i][-1],inp_nodes[i+1][0],name=f\"inp:{i}<->{i+1}\")\n",
    "for i,input_node in enumerate(inp_nodes):\n",
    "    j = i if i < L else i+1\n",
    "    mps_physicd_edge = mps_nodes[j][0] if j==0 else mps_nodes[j][1]\n",
    "    inp_physics_edge = input_node[1]\n",
    "    tn.connect(mps_physicd_edge,inp_physics_edge,name=f\"phy_{i}\")\n",
    "ans,path = my_contracter(mps_nodes+inp_nodes,\n",
    "                       output_edge_order=[inp_nodes[-1][2],mps_nodes[L][1]])\n",
    "ans.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_mps_list    = [rd_engine(P,D)] + [rd_engine(L-2,D,P,D)]  + [rd_engine(D,P)]\n",
    "middle_mpo_list =[[rd_engine(P,D,P)]+[rd_engine(L-2,D,P,D,P)]+ [rd_engine(D,P,P)]\n",
    "                  for _ in range(L-2)]\n",
    "bottom_mps_list = [rd_engine(P,D)] + [rd_engine(L-2,D,P,D)]  + [rd_engine(D,P)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D=2000\n",
    "P=4\n",
    "L=14\n",
    "top_mps_list = [rd_engine(P,D)] + [rd_engine(L-2,D,P,D)]  + [rd_engine(D,P)]\n",
    "top_mps_list = right_mps_form(top_mps_list)\n",
    "bottom_mps_list= [0.005*torch.randn_like(a)+a for a in top_mps_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bottom_mps_list,Zb = left_canonicalize_MPS(right_mps_form(bottom_mps_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0166)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contract_two_mps(bottom_mps_list,top_mps_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   left canonical scalar:0.09317030757665634\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 0.999, 0.942, 0.938, 0.958, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.8452922105789185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0118)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mps_list, scalar = approxmate_mps_line(top_mps_list,max_singular_values=1000)\n",
    "contract_two_mps(bottom_mps_list,new_mps_list)*scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:0/12 (4, 6) - 12x(6, 4, 6) - (6, 4)\n",
      "start:1/12 \n",
      "get mps (4, 36) - 12x(36, 4, 36) - (36, 4)\n",
      "boundary contraction cost:0.0013422966003417969\n",
      "   left canonical scalar:3.0327204513014294e-05\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:1.0\n",
      "low rank approximation cost:0.11043429374694824 scalar:3.0327204513014294e-05\n",
      "==========================================\n",
      "start:2/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0018436908721923828\n",
      "   left canonical scalar:0.000614150136243552\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:1.0000004768371582\n",
      "low rank approximation cost:0.23517894744873047 scalar:0.0006141504272818565\n",
      "==========================================\n",
      "start:3/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1296)-(1296, 4, 1296)-(1296, 4, 1296)-(1296, 4, 1296)-(1296, 4, 1296)-(1296, 4, 1296)-(1296, 4, 1296)-(1296, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0022668838500976562\n",
      "   left canonical scalar:0.000502652779687196\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.999, 0.998, 0.999, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.9966887831687927\n",
      "low rank approximation cost:1.6759274005889893 scalar:0.0005009883898310363\n",
      "==========================================\n",
      "start:4/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0043697357177734375\n",
      "   left canonical scalar:0.0005132302176207304\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923, 0.91, 0.963, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.808193027973175\n",
      "low rank approximation cost:14.75801420211792 scalar:0.00041478907223790884\n",
      "==========================================\n",
      "start:5/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0012714862823486328\n",
      "   left canonical scalar:0.0005140540306456387\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.906, 0.887, 0.956, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.7686819434165955\n",
      "low rank approximation cost:14.943126678466797 scalar:0.0003951440448872745\n",
      "==========================================\n",
      "start:6/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0012161731719970703\n",
      "   left canonical scalar:0.000582900014705956\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.915, 0.888, 0.958, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.777186393737793\n",
      "low rank approximation cost:14.729921102523804 scalar:0.0004530219594016671\n",
      "==========================================\n",
      "start:7/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0012156963348388672\n",
      "   left canonical scalar:0.0005581201403401792\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.915, 0.88, 0.949, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.7637606859207153\n",
      "low rank approximation cost:14.766213178634644 scalar:0.00042627021321095526\n",
      "==========================================\n",
      "start:8/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.001264333724975586\n",
      "   left canonical scalar:0.0005442900583148003\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.911, 0.876, 0.946, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.7541176080703735\n",
      "low rank approximation cost:14.809579372406006 scalar:0.00041045871330425143\n",
      "==========================================\n",
      "start:9/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0011568069458007812\n",
      "   left canonical scalar:0.0005957805551588535\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 0.878, 0.948, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.7570173740386963\n",
      "low rank approximation cost:14.73672342300415 scalar:0.00045101623982191086\n",
      "==========================================\n",
      "start:10/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0012233257293701172\n",
      "   left canonical scalar:0.0006513702101074159\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 0.881, 0.951, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.7616574168205261\n",
      "low rank approximation cost:14.767654418945312 scalar:0.0004961209488101304\n",
      "==========================================\n",
      "start:11/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0015985965728759766\n",
      "   left canonical scalar:0.0004802705952897668\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 0.999, 0.905, 0.879, 0.949, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.7546309232711792\n",
      "low rank approximation cost:14.78076958656311 scalar:0.0003624270320869982\n",
      "==========================================\n",
      "start:12/12 \n",
      "get mps (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0012969970703125\n",
      "   left canonical scalar:0.0005720893968828022\n",
      "   right canonical Z:[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.912, 0.88, 0.947, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "   right canonical scalar:0.7601038813591003\n",
      "low rank approximation cost:14.883152484893799 scalar:0.0004348473739810288\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "now_mps_list = bottom_mps_list\n",
    "print(f\"start:0/{len(middle_mpo_list)} {get_mps_size_list(now_mps_list)}\")\n",
    "for i,next_mpo in enumerate(middle_mpo_list):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    now_mps_list = contract_mps_mpo(now_mps_list,next_mpo)\n",
    "    print(f\"start:{i+1}/{len(middle_mpo_list)} \")\n",
    "    print(f\"get mps {get_mps_size_list(now_mps_list)}\")\n",
    "    cost       = time.time() - start_time\n",
    "    print(f\"boundary contraction cost:{cost}\")\n",
    "    if now_mps_list[0].shape[-1]>1:\n",
    "        start_time = time.time()\n",
    "        now_mps_list,scalar = approxmate_mps_line(right_mps_form(now_mps_list),\n",
    "                                                  max_singular_values= 1000,\n",
    "                                                  mode='full',\n",
    "                                                 # mode='right' if i>3 else 'full'\n",
    "                                                 )\n",
    "        #now_mps_list = [now_mps_list[0],torch.stack(now_mps_list[1:-1],dim=0),now_mps_list[-1]]\n",
    "        cost       = time.time() - start_time\n",
    "        print(f\"low rank approximation cost:{cost} scalar:{scalar}\")\n",
    "        print(\"==========================================\")\n",
    "#     start_time = time.time()\n",
    "#     value      = contract_two_mps(now_mps_list,top_mps_list)\n",
    "#     cost       = time.time() - start_time\n",
    "#     print(f\"col contraction cost:{cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:0/10 (4, 36) - 10x(36, 4, 36) - (36, 4)\n",
      "boundary contraction cost:0.0007288455963134766\n",
      "low rank approximation cost:0.010253667831420898 scalar:5.410343841081405e-23\n",
      "start:1/10 (4, 24)-(24, 4, 96)-(96, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 216)-(216, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.0014865398406982422\n",
      "low rank approximation cost:0.038602352142333984 scalar:1.2635199960961407e-13\n",
      "start:2/10 (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1296)-(1296, 4, 1296)-(1296, 4, 1296)-(1296, 4, 1296)-(1296, 4, 1296)-(1296, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.03164219856262207\n",
      "low rank approximation cost:0.9437947273254395 scalar:1.3323970424988897e-13\n",
      "start:3/10 (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.4210662841796875\n",
      "low rank approximation cost:16.94850254058838 scalar:1.2046462453368452e-13\n",
      "start:4/10 (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.42435622215270996\n",
      "low rank approximation cost:16.967477798461914 scalar:1.1561990114818506e-13\n",
      "start:5/10 (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.4237658977508545\n",
      "low rank approximation cost:16.9342782497406 scalar:1.2458078908988426e-13\n",
      "start:6/10 (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.42182374000549316\n",
      "low rank approximation cost:16.97764825820923 scalar:1.2171254678217144e-13\n",
      "start:7/10 (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.4213716983795166\n",
      "low rank approximation cost:17.01645064353943 scalar:1.169041377770211e-13\n",
      "start:8/10 (4, 24)-(24, 4, 96)-(96, 4, 384)-(384, 4, 1536)-(1536, 4, 6000)-(6000, 4, 6000)-(6000, 4, 6000)-(6000, 4, 1536)-(1536, 4, 384)-(384, 4, 96)-(96, 4, 24)-(24, 4)\n",
      "boundary contraction cost:0.42140722274780273\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-c84427f25f0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnow_mps_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mnow_mps_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscalar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapproxmate_mps_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_mps_form\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnow_mps_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_singular_values\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m#now_mps_list = [now_mps_list[0],torch.stack(now_mps_list[1:-1],dim=0),now_mps_list[-1]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcost\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-ab53d8dcd2bf>\u001b[0m in \u001b[0;36mapproxmate_mps_line\u001b[0;34m(mps_line, max_singular_values, max_truncation_error, relative)\u001b[0m\n\u001b[1;32m    119\u001b[0m                        ):\n\u001b[1;32m    120\u001b[0m     \u001b[0mscalar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mmps_line\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft_canonicalize_MPS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmps_line\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDecomposition_Engine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     SVD_Engine = lambda x:truncated_SVD(x,max_singular_values = max_singular_values,\n\u001b[1;32m    123\u001b[0m                                           \u001b[0mmax_truncation_error\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmax_truncation_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-ab53d8dcd2bf>\u001b[0m in \u001b[0;36mleft_canonicalize_MPS\u001b[0;34m(mps_line, Decomposition_Engine, normlization)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mnew_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecomposition_Engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mQ\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mnew_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "now_mps_list = bottom_mps_list\n",
    "for i,next_mpo in enumerate(middle_mpo_list):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    now_mps_list = contract_mps_mpo(now_mps_list,next_mpo)\n",
    "    print(f\"start:{i}/{len(middle_mpo_list)} {get_mps_size_list(now_mps_list)}\")\n",
    "    cost       = time.time() - start_time\n",
    "    print(f\"boundary contraction cost:{cost}\")\n",
    "    if now_mps_list[0].shape[-1]>1:\n",
    "        start_time = time.time()\n",
    "        now_mps_list,scalar = approxmate_mps_line(right_mps_form(now_mps_list),max_singular_values= 1000)\n",
    "        #now_mps_list = [now_mps_list[0],torch.stack(now_mps_list[1:-1],dim=0),now_mps_list[-1]]\n",
    "        cost       = time.time() - start_time\n",
    "        print(f\"low rank approximation cost:{cost} scalar:{scalar}\")\n",
    "#     start_time = time.time()\n",
    "#     value      = contract_two_mps(now_mps_list,top_mps_list)\n",
    "#     cost       = time.time() - start_time\n",
    "#     print(f\"col contraction cost:{cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([4, 4, 16]),\n",
       " torch.Size([16, 4, 64]),\n",
       " torch.Size([64, 4, 256]),\n",
       " torch.Size([256, 4, 64]),\n",
       " torch.Size([64, 4, 16]),\n",
       " torch.Size([16, 4, 4])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t.shape for t in now_mps_list[1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def contraction_row(tensor1,tensor2,truncate=None,einsum_engin=einsum_engin):\n",
    "    # tensor1 <-> tensor2 :-> tensor\n",
    "    # (N,H,a,b,c,d) <-> (N,H,c,e,f,g) :-> (N,H,a,be,f,dg)\n",
    "    tensor  = einsum_engin(\"whabcd,whcefg->whabefdg\",tensor1,tensor2).flatten(3,4).flatten(-2,-1)\n",
    "    if truncate is None:return tensor \n",
    "    W,H = tensor.shape[:2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def RecursionBMPS(tensor,truncate=None,einsum_engin=torch.einsum):\n",
    "    W,H = tensor.shape[:2]\n",
    "    while W > 1:\n",
    "            half_size = size // 2\n",
    "            nice_size = 2 * half_size\n",
    "            leftover  = tensor[nice_size:]\n",
    "            tensor    = contraction_line(tensor[0:nice_size:2], tensor[1:nice_size:2],truncate=None,einsum_engin=einsum_engin)\n",
    "            #tensor    = torch.einsum(\"mbik,mbkj->mbij\",tensor[0:nice_size:2], tensor[1:nice_size:2])\n",
    "            #(k/2,NB,D,D),(k/2,NB,D,D) <-> (k/2,NB,D,D)\n",
    "            tensor   = torch.cat([tensor, leftover], axis=0)\n",
    "            size     = half_size + int(size % 2 == 1)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class PEPSLinear(nn.Module):\n",
    "    '''\n",
    "     MPSLinear(in_features: int, out_features: int, W:int,H:int\n",
    "               in_physics_bond: int, out_physics_bond: int, virtual_bond_dim:int,\n",
    "                            bias: bool = True, label_position: int or str):\n",
    "        input  (Batch, in_features , W, H,  in_physics_bond)\n",
    "        output (Batch, out_features,        out_physics_bond)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, in_features,out_features,\n",
    "                       in_physics_bond = 2, out_physics_bond=1, virtual_bond_dim=2,\n",
    "                       bias=True,label_position='center',init_std=1e-10):\n",
    "        super(MPSLinear, self).__init__()\n",
    "        if label_position is 'center':label_position = in_features//2\n",
    "        assert type(label_position) is int\n",
    "        self.in_features   = in_features\n",
    "        self.out_features  = out_features\n",
    "        self.W             = W \n",
    "        self.H             = H\n",
    "        self.vbd           = virtual_bond_dim\n",
    "        self.ipb           = in_physics_bond\n",
    "        self.opb           = out_physics_bond\n",
    "\n",
    "        self.hn            = label_position\n",
    "        left_num           = self.hn\n",
    "        right_num          = in_features - left_num\n",
    "\n",
    "        bias_mat = torch.einsum(\"ij,kl->ijkl\",torch.eye(2),torch.eye(2)).unsqueeze(-1).repeat(1,1,1,1,self.ipb)\n",
    "        self.left_tensors = nn.Parameter(init_std * torch.randn(self.W, left_num  ,self.vbd,self.vbd,self.vbd,self.vbd, self.ipb)+ bias_mat)\n",
    "        self.rigt_tensors = nn.Parameter(init_std * torch.randn(self.W, right_num ,self.vbd,self.vbd,self.vbd,self.vbd, self.ipb)+ bias_mat)\n",
    "\n",
    "        bias_mat = torch.einsum(\"ij,kl->ijkl\",torch.eye(2),torch.eye(2)).unsqueeze(-1).repeat(1,1,1,1,self.opb)\n",
    "        self.cent_tensors = nn.Parameter(init_std * torch.randn(self.W,self.out_features,self.vbd,self.vbd,self.vbd,self.vbd, self.opb)+ bias_mat)\n",
    "\n",
    "    @staticmethod\n",
    "    def TRG_contraction(tensor):\n",
    "        '''\n",
    "        Tensor renormalization group Contraction method\n",
    "                     | \n",
    "           |      —○\n",
    "        —●—\t==>    \\ \n",
    "           |           ○—\n",
    "                       | \n",
    "        input: (W[2^N], H[2^N] , D,D,D,D)\n",
    "        '''\n",
    "        W,H = tensor.shape[:2]\n",
    "        lu_tensor = tensor[0:::2,0:::2]\n",
    "        ll_tensor = tensor[0:::2,1:::2]\n",
    "        ru_tensor = tensor[1:::2,0:::2]\n",
    "        rl_tensor = tensor[1:::2,1:::2]\n",
    "        size   = int(tensor.shape[0])\n",
    "        while size > 1:\n",
    "            half_size = size // 2\n",
    "            nice_size = 2 * half_size\n",
    "            leftover  = tensor[nice_size:]\n",
    "            tensor    = torch.einsum(\"mbik,mbkj->mbij\",tensor[0:nice_size:2], tensor[1:nice_size:2])\n",
    "            #(k/2,NB,D,D),(k/2,NB,D,D) <-> (k/2,NB,D,D)\n",
    "            tensor   = torch.cat([tensor, leftover], axis=0)\n",
    "            size     = half_size + int(size % 2 == 1)\n",
    "        return tensor.squeeze(0)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_chain_contraction(tensor):\n",
    "        size   = int(tensor.shape[0])\n",
    "        while size > 1:\n",
    "            half_size = size // 2\n",
    "            nice_size = 2 * half_size\n",
    "            leftover  = tensor[nice_size:]\n",
    "            tensor    = torch.einsum(\"mbik,mbkj->mbij\",tensor[0:nice_size:2], tensor[1:nice_size:2])\n",
    "            #(k/2,NB,D,D),(k/2,NB,D,D) <-> (k/2,NB,D,D)\n",
    "            tensor   = torch.cat([tensor, leftover], axis=0)\n",
    "            size     = half_size + int(size % 2 == 1)\n",
    "        return tensor.squeeze(0)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # the input data shape is (B,L,pd)\n",
    "        # expand to convolution patch\n",
    "        embedded_data= input_data\n",
    "        left_tensors = torch.einsum('wijp,nwp->wnij',self.left_tensors,embedded_data[:,:self.hn])#i.e. (K,NB,b,b)\n",
    "        rigt_tensors = torch.einsum('wijp,nwp->wnij',self.rigt_tensors,embedded_data[:,-self.hn:])#i.e.(K,NB,b,b)\n",
    "\n",
    "        left_tensors = self.get_chain_contraction(left_tensors) #i.e. (NB,b,b)\n",
    "        rigt_tensors = self.get_chain_contraction(rigt_tensors) #i.e. (NB,b,b)\n",
    "\n",
    "        tensor  = torch.einsum('bip,oplt,bli->bot',left_tensors,self.cent_tensors,rigt_tensors)\n",
    "        # (NB,b,b) <-> (T,b,b,o) <-> (NB,b,b) ==> (NB,T,t)\n",
    "        return tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from mltool.dataaccelerate import DataSimfetcher\n",
    "from mltool.loggingsystem import LoggingSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader= torch.utils.data.DataLoader(dataset=mnist_train, batch_size=1000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test , batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06538302430059152\n"
     ]
    }
   ],
   "source": [
    "from models.extend_model import Patch2NetworkInput\n",
    "#from models.two_dim_model import PEPS_einsum_arbitrary_partition_optim\n",
    "# model = MPSLinear(28*28,10,in_physics_bond = 2, out_physics_bond=1, virtual_bond_dim=100,\n",
    "#                   bias=False,label_position='center',init_std=0)\n",
    "#model = PEPS_einsum_uniform_shape(6,6,10,in_physics_bond=16,virtual_bond_dim=3,init_std=1)\n",
    "model = nn.Sequential(Patch2NetworkInput(4),\n",
    "                      PEPS_uniform_shape_symmetry_deep_model(W=6,H=6,in_physics_bond=16,init_std=1,virtual_bond_dim=5,\n",
    "                                                                                   normlized_layer_module=nn.InstanceNorm2d,\n",
    "                                                                                   nonlinear_layer=nn.Identity(),bias=False),\n",
    "                      \n",
    "                      nn.Linear(16,10)\n",
    "                     )\n",
    "#model = PEPS_einsum_arbitrary_partition_optim(virtual_bond_dim=\"models/arbitary_shape/arbitary_shape_2.json\",seted_variation=1e-5)\n",
    "                     \n",
    "\n",
    "                    \n",
    "#model  = AMPSShare(n=28*28, bond_dim=10, phys_dim=2)\n",
    "device = 'cuda'\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _=torch.nn.init.orthogonal_(model.left_tensors)\n",
    "# _=torch.nn.init.orthogonal_(model.cent_tensors)\n",
    "# _=torch.nn.init.orthogonal_(model.rigt_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(image):\n",
    "    image = image\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "infiniter = DataSimfetcher(train_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 24, 24):(tensor(1.0214, device='cuda:0'), tensor(0.0097, device='cuda:0'))\n",
      "(1000, 1, 24, 24):(tensor(1.0214, device='cuda:0'), tensor(0.0097, device='cuda:0'))\n",
      "(1000, 6, 6, 16):(tensor(1.0214, device='cuda:0'), tensor(0.9903, device='cuda:0'))\n",
      "(1000, 16):(tensor(1.0570, device='cuda:0'), tensor(-0.0427, device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "infiniter = DataSimfetcher(train_loader, device=device)\n",
    "image,label= infiniter.next()\n",
    "bs,c,w,h = image.shape\n",
    "with torch.no_grad():\n",
    "    x = image;print(f\"{tuple(x.shape)}:{torch.std_mean(x)}\")\n",
    "    x = preprocess_images(x);print(f\"{tuple(x.shape)}:{torch.std_mean(x)}\")\n",
    "    x = model[0](x);print(f\"{tuple(x.shape)}:{torch.std_mean(x)}\")\n",
    "    x = model[1](x);print(f\"{tuple(x.shape)}:{torch.std_mean(x)}\")\n",
    "    #x = model[2](x);print(f\"{tuple(x.shape)}:{torch.std_mean(x)}\")\n",
    "    #x = model(x);print(f\"{tuple(x.shape)}:{x.norm().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log at log/test\n"
     ]
    }
   ],
   "source": [
    "# main loop\n",
    "logsys            = LoggingSystem(True,\"log/test\")\n",
    "metric_list       = ['loss','g_norm','accu']\n",
    "losses=[]\n",
    "accues=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show the statistic tracking~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "code_folding": [
     4,
     40
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='38' class='' max='300', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      12.67% [38/300 11:28<1:19:07]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='60', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      1.67% [1/60 00:00<00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 038 \t Loss: 0.8108 \t Accu: 0.6643 \t Time: 0.24 sss\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-75ee4fc012ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#nn.utils.clip_grad_norm_(model.parameters(), 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m#nn.utils.clip_grad_norm_(p, max_norm=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric_dict       = logsys.initial_metric_dict(metric_list)\n",
    "master_bar        = logsys.create_master_bar(300)\n",
    "master_bar.set_multiply_graph(figsize=(9,3),engine=[['plot','plot','plot']],labels=[metric_list])\n",
    "accu = loss = -1\n",
    "for epoch in master_bar:\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    infiniter = DataSimfetcher(train_loader, device=device)\n",
    "    inter_b   = logsys.create_progress_bar(len(train_loader))\n",
    "    while inter_b.update_step():\n",
    "        image,label= infiniter.next()\n",
    "        bs,c,w,h = image.shape\n",
    "        optimizer.zero_grad()\n",
    "        binary     = preprocess_images(image)\n",
    "        logits     = model(binary).squeeze()\n",
    "        loss       = torch.nn.CrossEntropyLoss()(logits,label)\n",
    "        loss.backward()\n",
    "        #nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        if torch.isnan(loss):raise \n",
    "        #nn.utils.clip_grad_norm_(p, max_norm=1)\n",
    "        optimizer.step()\n",
    "#        g_norm=[(p.grad.norm()/p.norm()).item() for name,p in model.named_parameters() ] \n",
    "        g_norm=[(p.grad.norm()/p.norm()).item() for name,p in model[1].named_parameters() if 'unit' in name]    \n",
    "        g_norm+=[(p.grad.norm()/p.norm()).item() for name,p in model[2].named_parameters()] \n",
    "        losses.append(loss.item())\n",
    "        #lres.append(sum([(p.grad/p).norm() for p in model.parameters()]).log().item())\n",
    "        \n",
    "        if inter_b.now%5==0:\n",
    "            #print(g_norm\n",
    "            master_bar.update_graph_multiply([[losses[-100:],g_norm,accues[-100:]\n",
    "                                               #stdes[-100:],meanes[-100:]\n",
    "                                              ]])\n",
    "        loss = loss.item()\n",
    "        master_bar.lwrite('Epoch: %.3i \\t Loss: %.4f \\t Accu: %.4f \\t Time: %.2f s' %(epoch, loss, accu,time.time() - start_time),end='\\r')\n",
    "        #master_bar.lwrite('Epoch: %.3i \\t Loss: %.4f \\t Std: %.4f Mean: %.4f \\t Time: %.2f s' %(epoch, loss, std,mean,time.time() - start_time),end='\\r')\n",
    "    model.eval()\n",
    "    prefetcher = DataSimfetcher(test_loader, device=device)\n",
    "    inter_b    = logsys.create_progress_bar(len(test_loader))\n",
    "    labels     = []\n",
    "    logits     = []\n",
    "    with torch.no_grad():\n",
    "        while inter_b.update_step():\n",
    "            image,label= prefetcher.next()\n",
    "            binary     = preprocess_images(image)\n",
    "            logit      = model(binary).squeeze()\n",
    "            loss       = torch.nn.CrossEntropyLoss()(logit ,label)\n",
    "            labels.append(label)\n",
    "            logits.append(logit)\n",
    "    labels  = torch.cat(labels)\n",
    "    logits  = torch.cat(logits)\n",
    "    pred_labels  = torch.argmax(logits,-1)\n",
    "    accu =  torch.sum(pred_labels == labels)/len(labels)\n",
    "\n",
    "    accues.append(accu)\n",
    "    master_bar.update_graph_multiply([[losses[-100:],g_norm,accues[-100:]]])\n",
    "    accu = accu.item()\n",
    "    master_bar.lwrite('Epoch: %.3i \\t Loss: %.4f \\t Accu: %.4f \\t Time: %.2f s' %(epoch, loss, accu,time.time() - start_time),end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1136, device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def sample(self, bs, random_start=False):\n",
    "    \"\"\"\n",
    "    Sample images/spin configurations\n",
    "    \"\"\"\n",
    "\n",
    "    device = self.tensors.device\n",
    "    samples = torch.empty([bs, self.n], device=device)\n",
    "\n",
    "    # if random_start = True, force s_1 = -1/+1 randomly\n",
    "    if random_start:\n",
    "        samples[:, 0] = torch.randint(2, size=(bs, ), dtype=torch.float, device=device)\n",
    "    else:\n",
    "        samples[:, 0] = 0.\n",
    "\n",
    "    for idx in range(self.n - 1):\n",
    "        if idx == 0:\n",
    "            # sample s_2 from p(s_2 | s_1)\n",
    "            embedded_data = torch.stack([samples[:, 0], 1.0 - samples[:, 0]], dim=1)  # (bs, 2)\n",
    "            mats          = torch.einsum('lri,bi->blr', self.tensors[0, :, :, :] , embedded_data)\n",
    "            left_vec      = mats[:, 0, :].unsqueeze(1)  # (bs, 1, D)\n",
    "            logits        = torch.einsum('blr, ri->bli', left_vec,(self.tensors[1, :, :, :] )[:, 0, :]).squeeze(1)\n",
    "            samples[:, 1] = torch.bernoulli(torch.softmax(logits, dim=1)[:, 0])\n",
    "        else:\n",
    "            # then sample s_3 from  p(s_3 | s_1, s_2) and so on\n",
    "            embedded_data = torch.stack([samples[:, idx], 1.0 - samples[:, idx]], dim=1)  # (bs, 2)\n",
    "            mats = torch.einsum('lri,bi->blr', self.tensors[idx, :, :, :] , embedded_data)\n",
    "            left_vec = torch.bmm(left_vec, mats)  # (bs, 1, D)\n",
    "            logits = torch.einsum('blr, ri->bli', left_vec,\n",
    "                                  (self.tensors[idx + 1, :, :, :] )[:, 0, :]).squeeze(1)\n",
    "            samples[:, idx + 1] = torch.bernoulli(torch.softmax(logits, dim=1)[:, 0])\n",
    "    return samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
